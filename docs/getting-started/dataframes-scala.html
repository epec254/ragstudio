

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to load and transform data using the Apache Spark Scala DataFrame API in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Tutorial: Work with Apache Spark Scala DataFrames">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Tutorial: Work with Apache Spark Scala DataFrames &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/getting-started/dataframes-scala.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/getting-started/dataframes-scala.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/getting-started/dataframes-scala.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/getting-started/dataframes-scala.html" class="notranslate">English</option>
    <option value="../../ja/getting-started/dataframes-scala.html" class="notranslate">日本語</option>
    <option value="../../pt/getting-started/dataframes-scala.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Tutorial: Work with Apache Spark Scala DataFrames</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="tutorial-work-with-apache-spark-scala-dataframes">
<span id="tutorial-work-with-as-scala-dataframes"></span><h1>Tutorial: Work with Apache Spark Scala DataFrames<a class="headerlink" href="#tutorial-work-with-apache-spark-scala-dataframes" title="Permalink to this headline"> </a></h1>
<p>This article shows you how to load and transform data using the Apache Spark Scala DataFrame API in Databricks.</p>
<p>See also <a class="reference external" href="https://api-docs.databricks.com/scala/spark/latest/org/apache/spark/index.html">Apache Spark Scala API reference</a>.</p>
<div class="section" id="what-is-a-dataframe">
<h2>What is a DataFrame?<a class="headerlink" href="#what-is-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>A DataFrame is a two-dimensional labeled data structure with columns of potentially different types. You can think of a DataFrame like a spreadsheet, a SQL table, or a dictionary of series objects. Apache Spark DataFrames provide a rich set of functions (select columns, filter, join, aggregate) that allow you to solve common data analysis problems efficiently.</p>
<p>Apache Spark DataFrames are an abstraction built on top of Resilient Distributed Datasets (RDDs). Spark DataFrames and Spark SQL use a unified planning and optimization engine, allowing you to get nearly identical performance across all supported languages on Databricks (Python, SQL, Scala, and R).</p>
</div>
<div class="section" id="what-is-a-spark-dataset">
<h2>What is a Spark Dataset?<a class="headerlink" href="#what-is-a-spark-dataset" title="Permalink to this headline"> </a></h2>
<p>The Apache Spark <a class="reference external" href="https://spark.apache.org/docs/latest/api/java/org/apache/spark/sql/Dataset.html">Dataset API</a> provides a type-safe, object-oriented programming interface. <code class="docutils literal notranslate"><span class="pre">DataFrame</span></code> is an alias for an untyped <code class="docutils literal notranslate"><span class="pre">Dataset</span> <span class="pre">[Row]</span></code>.</p>
<p>The Databricks documentation uses the term DataFrame for most technical references and guide, because this language is inclusive for Python, Scala, and R. See <a class="reference internal" href="#dataset-notebook"><span class="std std-ref">Notebook example: Scala Dataset aggregator</span></a>.</p>
</div>
<div class="section" id="create-a-dataframe-with-scala">
<h2>Create a DataFrame with Scala<a class="headerlink" href="#create-a-dataframe-with-scala" title="Permalink to this headline"> </a></h2>
<p>Most Apache Spark queries return a DataFrame. This includes reading from a table, loading data from files, and operations that transform data.</p>
<p>You can also create a DataFrame from a list of classes, such as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">case</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">Employee</span><span class="p">(</span><span class="n">id</span><span class="p">:</span><span class="w"> </span><span class="nc">Int</span><span class="p">,</span><span class="w"> </span><span class="n">name</span><span class="p">:</span><span class="w"> </span><span class="nc">String</span><span class="p">)</span>

<span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Seq</span><span class="p">(</span><span class="k">new</span><span class="w"> </span><span class="nc">Employee</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Elia&quot;</span><span class="p">),</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="nc">Employee</span><span class="p">(</span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Teo&quot;</span><span class="p">),</span><span class="w"> </span><span class="k">new</span><span class="w"> </span><span class="nc">Employee</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;Fang&quot;</span><span class="p">)).</span><span class="n">toDF</span>
</pre></div>
</div>
</div>
<div class="section" id="read-a-table-into-a-dataframe">
<h2>Read a table into a DataFrame<a class="headerlink" href="#read-a-table-into-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>Databricks uses Delta Lake for all tables by default. You can easily load tables to DataFrames, such as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">read</span><span class="p">.</span><span class="n">table</span><span class="p">(</span><span class="s">&quot;&lt;catalog-name&gt;.&lt;schema-name&gt;.&lt;table-name&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="load-data-into-a-dataframe-from-files">
<h2>Load data into a DataFrame from files<a class="headerlink" href="#load-data-into-a-dataframe-from-files" title="Permalink to this headline"> </a></h2>
<p>You can load data from many supported <a class="reference internal" href="../query/formats/index.html"><span class="doc">file formats</span></a>. The following example uses a dataset available in the <code class="docutils literal notranslate"><span class="pre">/databricks-datasets</span></code> directory, accessible from most workspaces. See <a class="reference internal" href="../discover/databricks-datasets.html"><span class="doc">Sample datasets</span></a>.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">read</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;csv&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;header&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;inferSchema&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;/databricks-datasets/samples/population-vs-price/data_geo.csv&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="assign-transformation-steps-to-a-dataframe">
<h2>Assign transformation steps to a DataFrame<a class="headerlink" href="#assign-transformation-steps-to-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>The results of most Spark transformations return a DataFrame. You can assign these results back to a DataFrame variable, similar to how you might use CTEs, temp views, or DataFrames in other systems.</p>
</div>
<div class="section" id="combine-dataframes-with-join-and-union">
<h2>Combine DataFrames with join and union<a class="headerlink" href="#combine-dataframes-with-join-and-union" title="Permalink to this headline"> </a></h2>
<p>DataFrames use standard SQL semantics for join operations. A join returns the combined results of two DataFrames based on the provided matching conditions and join type. The following example is an inner join, which is the default:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">joined_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df1</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">df2</span><span class="p">,</span><span class="w"> </span><span class="n">joinType</span><span class="o">=</span><span class="s">&quot;inner&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">usingColumn</span><span class="o">=</span><span class="s">&quot;id&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can add the rows of one DataFrame to another using the union operation, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">unioned_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df1</span><span class="p">.</span><span class="n">union</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="filter-rows-in-a-dataframe">
<h2>Filter rows in a DataFrame<a class="headerlink" href="#filter-rows-in-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can filter rows in a DataFrame using <code class="docutils literal notranslate"><span class="pre">.filter()</span></code> or <code class="docutils literal notranslate"><span class="pre">.where()</span></code>. There is no difference in performance or syntax, as seen in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">filtered_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="n">filter</span><span class="p">(</span><span class="s">&quot;id &gt; 1&quot;</span><span class="p">)</span>

<span class="kd">val</span><span class="w"> </span><span class="n">filtered_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="n">where</span><span class="p">(</span><span class="s">&quot;id &gt; 1&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Use filtering to select a subset of rows to return or modify in a DataFrame.</p>
</div>
<div class="section" id="select-columns-from-a-dataframe">
<h2>Select columns from a DataFrame<a class="headerlink" href="#select-columns-from-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can select columns by passing one or more column names to <code class="docutils literal notranslate"><span class="pre">.select()</span></code>, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">select_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;id&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;name&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>You can combine select and filter queries to limit rows and columns returned.</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">subset_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">.</span><span class="n">filter</span><span class="p">(</span><span class="s">&quot;id &gt; 1&quot;</span><span class="p">).</span><span class="n">select</span><span class="p">(</span><span class="s">&quot;name&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="view-the-dataframe">
<span id="view-dataframe"></span><h2>View the DataFrame<a class="headerlink" href="#view-the-dataframe" title="Permalink to this headline"> </a></h2>
<p>To view this data in a tabular format, you can use the Databricks <code class="docutils literal notranslate"><span class="pre">display()</span></code> command, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="print-the-data-schema">
<h2>Print the data schema<a class="headerlink" href="#print-the-data-schema" title="Permalink to this headline"> </a></h2>
<p>Spark uses the term <em>schema</em> to refer to the names and data types of the columns in the DataFrame.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Databricks also uses the term schema to describe a collection of tables registered to a catalog.</p>
</div>
<p>You can print the schema using the <code class="docutils literal notranslate"><span class="pre">.printSchema()</span></code> method, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="save-a-dataframe-to-a-table">
<h2>Save a DataFrame to a table<a class="headerlink" href="#save-a-dataframe-to-a-table" title="Permalink to this headline"> </a></h2>
<p>Databricks uses Delta Lake for all tables by default. You can save the contents of a DataFrame to a table using the following syntax:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s">&quot;&lt;table-name&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="write-a-dataframe-to-a-collection-of-files">
<h2>Write a DataFrame to a collection of files<a class="headerlink" href="#write-a-dataframe-to-a-collection-of-files" title="Permalink to this headline"> </a></h2>
<p>Most Spark applications are designed to work on large datasets and work in a distributed fashion, and Spark writes out a directory of files rather than a single file. Many data systems are configured to read these directories of files. Databricks recommends using tables over filepaths for most applications.</p>
<p>The following example saves a directory of JSON files:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="p">.</span><span class="n">write</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;json&quot;</span><span class="p">).</span><span class="n">save</span><span class="p">(</span><span class="s">&quot;/tmp/json_data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="run-sql-queries-in-spark">
<span id="run-sql"></span><h2>Run SQL queries in Spark<a class="headerlink" href="#run-sql-queries-in-spark" title="Permalink to this headline"> </a></h2>
<p>Spark DataFrames provide a number of options to combine SQL with Scala.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">selectExpr()</span></code> method allows you to specify each column as a SQL query, such as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s">&quot;id&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;upper(name) as big_name&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>You can import the <code class="docutils literal notranslate"><span class="pre">expr()</span></code> function from <code class="docutils literal notranslate"><span class="pre">pyspark.sql.functions</span></code> to use SQL syntax anywhere a column would be specified, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">expr</span>

<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">.</span><span class="n">select</span><span class="p">(</span><span class="ss">&#39;id</span><span class="p">,</span><span class="w"> </span><span class="n">expr</span><span class="p">(</span><span class="s">&quot;lower(name) as little_name&quot;</span><span class="p">)))</span>
</pre></div>
</div>
<p>You can also use <code class="docutils literal notranslate"><span class="pre">spark.sql()</span></code> to run arbitrary SQL queries in the Scala kernel, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">query_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">sql</span><span class="p">(</span><span class="s">&quot;SELECT * FROM &lt;table-name&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Because logic is executed in the Scala kernel and all SQL queries are passed as strings, you can use Scala formatting to parameterize SQL queries, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">table_name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;my_table&quot;</span>

<span class="kd">val</span><span class="w"> </span><span class="n">query_df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">sql</span><span class="p">(</span><span class="s">s&quot;SELECT * FROM </span><span class="si">$</span><span class="n">table_name</span><span class="s">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="notebook-example-scala-dataset-aggregator">
<span id="dataset-notebook"></span><h2>Notebook example: Scala Dataset aggregator<a class="headerlink" href="#notebook-example-scala-dataset-aggregator" title="Permalink to this headline"> </a></h2>
<p>The following notebooks shows how to work with Dataset aggregators.</p>
<div class="embedded-notebook-section section" id="dataset-aggregator-notebook">
<span id="dataset-aggregator"></span><h3>Dataset aggregator notebook<a class="headerlink" href="#dataset-aggregator-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/dataset-aggregator.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/dataset-aggregator.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/dataset-aggregator.html"            id="fd51552ffd83cf7295a9cbd4f032ca094b375693423eb9f419eea8bbe68efe6c" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>