

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to load and transform data using the Apache Spark Python (PySpark) DataFrame API in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Tutorial: Load and transform data in PySpark DataFrames">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Tutorial: Load and transform data in PySpark DataFrames &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/getting-started/dataframes-python.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/getting-started/dataframes-python.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/getting-started/dataframes-python.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/getting-started/dataframes-python.html" class="notranslate">English</option>
    <option value="../../ja/getting-started/dataframes-python.html" class="notranslate">日本語</option>
    <option value="../../pt/getting-started/dataframes-python.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Tutorial: Load and transform data in PySpark DataFrames</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="tutorial-load-and-transform-data-in-pyspark-dataframes">
<h1>Tutorial: Load and transform data in PySpark DataFrames<a class="headerlink" href="#tutorial-load-and-transform-data-in-pyspark-dataframes" title="Permalink to this headline"> </a></h1>
<p>This article shows you how to load and transform U.S. city data using the Apache Spark Python (PySpark) DataFrame API in Databricks.</p>
<p>By the end of this article, you will understand what a DataFrame is and feel comfortable with the following tasks.</p>
<ul class="simple">
<li><p><a class="reference internal" href="#create-dataframe-python"><span class="std std-ref">Creating a DataFrame with Python</span></a></p></li>
<li><p><a class="reference internal" href="#interact-with-dataframe"><span class="std std-ref">Viewing and interacting with a DataFrame</span></a></p></li>
<li><p><a class="reference internal" href="#run-sql"><span class="std std-ref">Running SQL queries in PySpark</span></a></p></li>
</ul>
<p>See also <a class="reference external" href="https://api-docs.databricks.com/python/pyspark/latest/pyspark.sql/api/pyspark.sql.DataFrame.html#pyspark-sql-dataframe">Apache Spark PySpark API reference</a>.</p>
<div class="section" id="what-is-a-dataframe">
<span id="what-is-dataframe"></span><h2>What is a DataFrame?<a class="headerlink" href="#what-is-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>A DataFrame is a two-dimensional labeled data structure with columns of potentially different types. You can think of a DataFrame like a spreadsheet, a SQL table, or a dictionary of series objects. Apache Spark DataFrames provide a rich set of functions (select columns, filter, join, aggregate) that allow you to solve common data analysis problems efficiently.</p>
<p>Apache Spark DataFrames are an abstraction built on top of Resilient Distributed Datasets (RDDs). Spark DataFrames and Spark SQL use a unified planning and optimization engine, allowing you to get nearly identical performance across all supported languages on Databricks (Python, SQL, Scala, and R).</p>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<p>To complete the following tutorial, you must meet the following requirements.</p>
<ul class="simple">
<li><p>You are logged into a Databricks workspace.</p></li>
<li><p>You have <a class="reference internal" href="../compute/clusters-manage.html#control-access-to-clusters"><span class="std std-ref">permission to create a cluster</span></a>.</p></li>
<li><p>You have access to compute.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If you do not have cluster control privileges, you can still complete most of the steps below as long as you have <a class="reference internal" href="../compute/clusters-manage.html#display-clusters"><span class="std std-ref">access to a cluster</span></a>.</p>
</div>
<p>From the left sidebar on the landing page, you access Databricks entities: the workspace browser, catalog, workflows, and compute. <strong>Workspace</strong> is the root folder that stores your Databricks assets, such as notebooks and libraries.</p>
<p>For guidance about how to navigate a Databricks notebook, see <a class="reference internal" href="../notebooks/notebook-ui.html"><span class="doc">Databricks notebook interface and controls</span></a>.</p>
</div>
<div class="section" id="step-1-create-a-dataframe-with-python">
<span id="create-dataframe-python"></span><h2>Step 1: Create a DataFrame with Python<a class="headerlink" href="#step-1-create-a-dataframe-with-python" title="Permalink to this headline"> </a></h2>
<ol class="arabic simple">
<li><p>Open a new notebook and insert a new cell by clicking the <img alt="New Icon" src="../_images/create-icon.png" /> icon.</p></li>
<li><p>Copy and paste the following code into an empty notebook cell, then press <strong>SHIFT+ENTER</strong> to run the cell. The following code example creates a DataFrame with city population data and displays the contents of the DataFrame.</p></li>
</ol>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">data</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">295</span><span class="p">,</span> <span class="s2">&quot;South Bend&quot;</span><span class="p">,</span> <span class="s2">&quot;Indiana&quot;</span><span class="p">,</span> <span class="s2">&quot;IN&quot;</span><span class="p">,</span> <span class="mi">101190</span><span class="p">,</span> <span class="mf">112.9</span><span class="p">]]</span>
<span class="n">columns</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;rank&quot;</span><span class="p">,</span> <span class="s2">&quot;city&quot;</span><span class="p">,</span> <span class="s2">&quot;state&quot;</span><span class="p">,</span> <span class="s2">&quot;code&quot;</span><span class="p">,</span> <span class="s2">&quot;population&quot;</span><span class="p">,</span> <span class="s2">&quot;price&quot;</span><span class="p">]</span>

<span class="n">df1</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">createDataFrame</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;rank LONG, city STRING, state STRING, code STRING, population LONG, price DOUBLE&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df1</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="step-2-load-data-into-a-dataframe-from-files">
<h2>Step 2: Load data into a DataFrame from files<a class="headerlink" href="#step-2-load-data-into-a-dataframe-from-files" title="Permalink to this headline"> </a></h2>
<p>Add more city population data with the <code class="docutils literal notranslate"><span class="pre">/databricks-datasets</span></code> directory into <code class="docutils literal notranslate"><span class="pre">df1</span></code> and display the output.</p>
<p>To load data into DataFrame <code class="docutils literal notranslate"><span class="pre">df1</span></code> from the <code class="docutils literal notranslate"><span class="pre">data_geo.csv</span></code> file:</p>
<ol class="arabic simple">
<li><p>In the notebook, create a new cell.</p></li>
<li><p>Copy and paste the following code into the empty notebook cell, then press <strong>SHIFT+ENTER</strong> to run the cell.</p></li>
</ol>
<p>The following example uses a data set available in the <code class="docutils literal notranslate"><span class="pre">/databricks-datasets</span></code> directory, accessible from most workspaces. For more information on file formats, see <a class="reference internal" href="../query/formats/index.html"><span class="doc">Data format options</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df2</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/samples/population-vs-price/data_geo.csv&quot;</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="step-3-view-and-interact-with-your-dataframe">
<span id="interact-with-dataframe"></span><h2>Step 3: View and interact with your DataFrame<a class="headerlink" href="#step-3-view-and-interact-with-your-dataframe" title="Permalink to this headline"> </a></h2>
<p>View and interact with your city population DataFrames with the following methods.</p>
<div class="section" id="combine-dataframes">
<h3>Combine DataFrames<a class="headerlink" href="#combine-dataframes" title="Permalink to this headline"> </a></h3>
<p>Combine the contents of your first DataFrame with the DataFrame that contains the contents of <code class="docutils literal notranslate"><span class="pre">data_geo.csv</span></code>.</p>
<p>In the notebook, use the following example code to create a new DataFrame that adds the rows of one DataFrame to another using the union operation:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Returns a DataFrame that combines the rows of df1 and df2</span>
<span class="n">df</span> <span class="o">=</span> <span class="n">df1</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="n">df2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="view-the-dataframe">
<h3>View the DataFrame<a class="headerlink" href="#view-the-dataframe" title="Permalink to this headline"> </a></h3>
<p>To view the U.S. city data in a tabular format with the Databricks <code class="docutils literal notranslate"><span class="pre">display()</span></code> command, add the following code to a notebook cell:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="print-the-data-schema">
<h3>Print the data schema<a class="headerlink" href="#print-the-data-schema" title="Permalink to this headline"> </a></h3>
<p>Spark uses the term <em>schema</em> to refer to the names and data types of the columns in the DataFrame.</p>
<p>Print the schema of your DataFrame with the following <code class="docutils literal notranslate"><span class="pre">.printSchema()</span></code> method in your notebook. Use the resulting metadata to interact with the contents of your DataFrame.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">printSchema</span><span class="p">()</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Databricks also uses the term schema to describe a collection of tables registered to a catalog.</p>
</div>
</div>
<div class="section" id="filter-rows-in-a-dataframe">
<h3>Filter rows in a DataFrame<a class="headerlink" href="#filter-rows-in-a-dataframe" title="Permalink to this headline"> </a></h3>
<p>Discover the five most populous cities in your data set by filtering rows, using <code class="docutils literal notranslate"><span class="pre">.filter()</span></code> or <code class="docutils literal notranslate"><span class="pre">.where()</span></code>. Use filtering to select a subset of rows to return or modify in a DataFrame. There is no difference in performance or syntax, as seen in the following example.</p>
<p>To select the most populous cities, continue to add new cells to your notebook and add the following code examples:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">filtered_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;rank&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span>
<span class="n">filtered_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;rank&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">6</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">filtered_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="select-columns-from-a-dataframe">
<h3>Select columns from a DataFrame<a class="headerlink" href="#select-columns-from-a-dataframe" title="Permalink to this headline"> </a></h3>
<p>Learn about which state a city is located in with the <code class="docutils literal notranslate"><span class="pre">select()</span></code> method. Select columns by passing one or more column names to <code class="docutils literal notranslate"><span class="pre">.select()</span></code>, as in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">select_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;City&quot;</span><span class="p">,</span> <span class="s2">&quot;State&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">select_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="create-a-subset-dataframe">
<h3>Create a subset DataFrame<a class="headerlink" href="#create-a-subset-dataframe" title="Permalink to this headline"> </a></h3>
<p>Create a subset DataFrame with the ten cities with the highest population and display the resulting data. Combine select and filter queries to limit rows and columns returned, using the following code in your notebook:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">subset_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s2">&quot;rank&quot;</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mi">11</span><span class="p">)</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;City&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">subset_df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="step-4-save-the-dataframe">
<span id="save-dataframe"></span><h2>Step 4: Save the DataFrame<a class="headerlink" href="#step-4-save-the-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can either save your DataFrame to a table or write the DataFrame to a file or multiple files.</p>
<div class="section" id="save-the-dataframe-to-a-table">
<h3>Save the DataFrame to a table<a class="headerlink" href="#save-the-dataframe-to-a-table" title="Permalink to this headline"> </a></h3>
<p>Databricks uses Delta Lake for all tables by default. To save your DataFrame, you must have ’CREATE’ table privileges on the catalog and schema. To save the contents of your DataFrame, use the following syntax and replace <code class="docutils literal notranslate"><span class="pre">table-name</span></code> with the table you want to save to.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="s2">&quot;&lt;table name&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Most Spark applications work on large data sets and in a distributed fashion. Spark writes out a directory of files rather than a single file. Delta Lake splits the Parquet folders and files. Many data systems can read these directories of files. Databricks recommends using tables over file paths for most applications.</p>
</div>
<div class="section" id="save-the-dataframe-to-json-files">
<h3>Save the DataFrame to JSON files<a class="headerlink" href="#save-the-dataframe-to-json-files" title="Permalink to this headline"> </a></h3>
<p>The following example saves a directory of JSON files:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Write a DataFrame to a collection of files</span>
<span class="n">df</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/tmp/json_data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="read-the-dataframe-from-a-json-file">
<h3>Read the DataFrame from a JSON file<a class="headerlink" href="#read-the-dataframe-from-a-json-file" title="Permalink to this headline"> </a></h3>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Read a DataFrame from a JSON file</span>
<span class="n">df3</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">json</span><span class="p">(</span><span class="s2">&quot;/tmp/json_data&quot;</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">df3</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="additional-tasks-run-sql-queries-in-pyspark">
<span id="run-sql"></span><h2>Additional tasks: Run SQL queries in PySpark<a class="headerlink" href="#additional-tasks-run-sql-queries-in-pyspark" title="Permalink to this headline"> </a></h2>
<p>Spark DataFrames provide the following options to combine SQL with Python. You can run the following code in the same notebook you created for this tutorial.</p>
<div class="section" id="specify-a-column-as-a-sql-query">
<h3>Specify a column as a SQL query<a class="headerlink" href="#specify-a-column-as-a-sql-query" title="Permalink to this headline"> </a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">selectExpr()</span></code> method allows you to specify each column as an SQL query, such as in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;`2014 rank`&quot;</span><span class="p">,</span> <span class="s2">&quot;upper(city) as big_name&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="import-expr">
<h3>Import <code class="docutils literal notranslate"><span class="pre">expr()</span></code><a class="headerlink" href="#import-expr" title="Permalink to this headline"> </a></h3>
<p>You can import the <code class="docutils literal notranslate"><span class="pre">expr()</span></code> function from <code class="docutils literal notranslate"><span class="pre">pyspark.sql.functions</span></code> to use SQL syntax anywhere a column would be specified, as in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">expr</span>

<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;2014 rank&quot;</span><span class="p">,</span> <span class="n">expr</span><span class="p">(</span><span class="s2">&quot;lower(city) as little_name&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="section" id="run-an-arbitrary-sql-query">
<h3>Run an arbitrary SQL query<a class="headerlink" href="#run-an-arbitrary-sql-query" title="Permalink to this headline"> </a></h3>
<p>You can use <code class="docutils literal notranslate"><span class="pre">spark.sql()</span></code> to run arbitrary SQL queries, as in the following example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">query_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM us_cities&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="parameterize-sql-queries">
<h3>Parameterize SQL queries<a class="headerlink" href="#parameterize-sql-queries" title="Permalink to this headline"> </a></h3>
<p>You can use Python formatting to parameterize SQL queries, as in the following example.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">table_name</span> <span class="o">=</span> <span class="s2">&quot;my_table&quot;</span>

<span class="n">query_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SELECT * FROM </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="additional-resources">
<h2>Additional resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="../reference/spark.html"><span class="doc">Apache Spark API reference</span></a></p></li>
<li><p><a class="reference internal" href="../pandas/pyspark-pandas-conversion.html"><span class="doc">Convert between PySpark and pandas DataFrames</span></a></p></li>
<li><p><a class="reference internal" href="../pandas/pandas-on-spark.html"><span class="doc">Pandas API on Spark</span></a></p></li>
</ul>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>