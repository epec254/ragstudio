

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn common data loading patterns leveraging Auto Loader." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Common data loading patterns">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Common data loading patterns &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/ingestion/auto-loader/patterns.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/ingestion/auto-loader/patterns.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/ingestion/auto-loader/patterns.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/ingestion/auto-loader/patterns.html" class="notranslate">English</option>
    <option value="../../../ja/ingestion/auto-loader/patterns.html" class="notranslate">日本語</option>
    <option value="../../../pt/ingestion/auto-loader/patterns.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Common data loading patterns</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="common-data-loading-patterns">
<h1>Common data loading patterns<a class="headerlink" href="#common-data-loading-patterns" title="Permalink to this headline"> </a></h1>
<p>Auto Loader simplifies a number of common data ingestion tasks. This quick reference provides examples for several popular patterns.</p>
<div class="section" id="filtering-directories-or-files-using-glob-patterns">
<h2>Filtering directories or files using glob patterns<a class="headerlink" href="#filtering-directories-or-files-using-glob-patterns" title="Permalink to this headline"> </a></h2>
<p>Glob patterns can be used for filtering directories and files when provided in the path.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 80%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Pattern</p></th>
<th class="head"><p>Description</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">?</span></code></p></td>
<td><p>Matches any single character</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">*</span></code></p></td>
<td><p>Matches zero or more characters</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">[abc]</span></code></p></td>
<td><p>Matches a single character from character set {a,b,c}.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">[a-z]</span></code></p></td>
<td><p>Matches a single character from the character range {a…z}.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">[^a]</span></code></p></td>
<td><p>Matches a single character that is not from character set or range {a}.
Note that the <code class="docutils literal notranslate"><span class="pre">^</span></code> character must occur immediately to the right of the
opening bracket.</p></td>
</tr>
<tr class="row-odd"><td><p><code class="docutils literal notranslate"><span class="pre">{ab,cd}</span></code></p></td>
<td><p>Matches a string from the string set {ab, cd}.</p></td>
</tr>
<tr class="row-even"><td><p><code class="docutils literal notranslate"><span class="pre">{ab,c{de,</span> <span class="pre">fh}}</span></code></p></td>
<td><p>Matches a string from the string set {ab, cde, cfh}.</p></td>
</tr>
</tbody>
</table>
<p>Use the <code class="docutils literal notranslate"><span class="pre">path</span></code> for providing prefix patterns, for example:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="o">&lt;</span><span class="nb">format</span><span class="o">&gt;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;base-path&gt;/*/files&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="o">&lt;</span><span class="n">format</span><span class="o">&gt;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="n">schema</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;base-path&gt;/*/files&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>You need to use the option <code class="docutils literal notranslate"><span class="pre">pathGlobFilter</span></code> for explicitly providing suffix patterns. The <code class="docutils literal notranslate"><span class="pre">path</span></code> only provides a prefix filter.</p>
</div>
<p>For example, if you would like to parse only <code class="docutils literal notranslate"><span class="pre">png</span></code> files in a directory that contains files with different suffixes, you can do:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;binaryFile&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;pathGlobfilter&quot;</span><span class="p">,</span> <span class="s2">&quot;*.png&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">base</span><span class="o">-</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;binaryFile&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;pathGlobfilter&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;*.png&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">base</span><span class="o">-</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default globbing behavior of Auto Loader is different than the default behavior of other Spark file sources. Add <code class="docutils literal notranslate"><span class="pre">.option(&quot;cloudFiles.useStrictGlobber&quot;,</span> <span class="pre">&quot;true&quot;)</span></code> to your read to use globbing that matches default Spark behavior against file sources. See the following table for more on globbing:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 30%" />
<col style="width: 22%" />
<col style="width: 21%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Pattern</p></th>
<th class="head"><p>File path</p></th>
<th class="head"><p>Default globber</p></th>
<th class="head"><p>Strict globber</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> /a/b</p></td>
<td><p> /a/b/c/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/b</p></td>
<td><p> /a/b_dir/c/file.txt</p></td>
<td><p> <em>No</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/b</p></td>
<td><p> /a/b.txt</p></td>
<td><p> <em>No</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/b/</p></td>
<td><p> /a/b.txt</p></td>
<td><p> <em>No</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/*/c/</p></td>
<td><p> /a/b/c/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/*/c/</p></td>
<td><p> /a/b/c/d/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/*/c/</p></td>
<td><p> /a/b/x/y/c/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/*/c</p></td>
<td><p> /a/b/c_file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/*/c/</p></td>
<td><p> /a/b/c_file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/*/c/</p></td>
<td><p> /a/*/cookie/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/b*</p></td>
<td><p> /a/b.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/b*</p></td>
<td><p> /a/b/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/{0.txt,1.txt}</p></td>
<td><p> /a/0.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
<tr class="row-odd"><td><p> /a/*/{0.txt,1.txt}</p></td>
<td><p> /a/0.txt</p></td>
<td><p> <em>No</em></p></td>
<td><p> <em>No</em></p></td>
</tr>
<tr class="row-even"><td><p> /a/b/[cde-h]/i/</p></td>
<td><p> /a/b/c/i/file.txt</p></td>
<td><p> <em>Yes</em></p></td>
<td><p> <em>Yes</em></p></td>
</tr>
</tbody>
</table>
</div>
</div>
<div class="section" id="enable-easy-etl">
<h2>Enable easy ETL<a class="headerlink" href="#enable-easy-etl" title="Permalink to this headline"> </a></h2>
<p>An easy way to get your data into Delta Lake without losing any data is to use the following pattern and enabling schema inference with Auto Loader. Databricks recommends running the following code in a Databricks job for it to automatically restart your stream when the schema of your source data changes. By default, the schema is inferred as string types, any parsing errors (there should be none if everything remains as a string) will go to <code class="docutils literal notranslate"><span class="pre">_rescued_data</span></code>, and any new columns will fail the stream and evolve the schema.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-schema-location&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;mergeSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;json&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-schema-location&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;mergeSchema&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;checkpointLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="s">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="prevent-data-loss-in-well-structured-data">
<h2>Prevent data loss in well-structured data<a class="headerlink" href="#prevent-data-loss-in-well-structured-data" title="Permalink to this headline"> </a></h2>
<p>When you know your schema, but want to know whenever you receive unexpected data, Databricks recommends using the <code class="docutils literal notranslate"><span class="pre">rescuedDataColumn</span></code>.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="n">expected_schema</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span> \
  <span class="c1"># will collect all new fields as well as data type mismatches in _rescued_data</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaEvolutionMode&quot;</span><span class="p">,</span> <span class="s2">&quot;rescue&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="n">expected_schema</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;json&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="c1">// will collect all new fields as well as data type mismatches in _rescued_data</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.schemaEvolutionMode&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;rescue&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;checkpointLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="s">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>If you want your stream to stop processing if a new field is introduced that doesn’t match your schema, you can add:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaEvolutionMode&quot;</span><span class="p">,</span> <span class="s2">&quot;failOnNewColumns&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="enable-flexible-semi-structured-data-pipelines">
<h2>Enable flexible semi-structured data pipelines<a class="headerlink" href="#enable-flexible-semi-structured-data-pipelines" title="Permalink to this headline"> </a></h2>
<p>When you’re receiving data from a vendor that introduces new columns to the information they provide, you may not be aware of exactly when they do it, or you may not have the bandwidth to update your data pipeline. You can now leverage schema evolution to restart the stream and let Auto Loader update the inferred schema automatically. You can also leverage <code class="docutils literal notranslate"><span class="pre">schemaHints</span></code> for some of the “schemaless” fields that the vendor may be providing.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span> \
  <span class="c1"># will ensure that the headers column gets processed as a map</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaHints&quot;</span><span class="p">,</span>
          <span class="s2">&quot;headers map&lt;string,string&gt;, statusCode SHORT&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/api/requests&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;mergeSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;json&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="c1">// will ensure that the headers column gets processed as a map</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.schemaHints&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="s">&quot;headers map&lt;string,string&gt;, statusCode SHORT&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;/api/requests&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;mergeSchema&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;checkpointLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="s">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="transform-nested-json-data">
<h2>Transform nested JSON data<a class="headerlink" href="#transform-nested-json-data" title="Permalink to this headline"> </a></h2>
<p>Because Auto Loader infers the top level JSON columns as strings, you can be left with nested JSON objects that require further transformations. You can use the <a class="reference internal" href="../../optimizations/semi-structured.html"><span class="doc">semi-structured data access APIs</span></a> to further transform complex JSON content.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span> \
  <span class="c1"># The schema location directory keeps track of your data schema over time</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;source-data-with-nested-json&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span>
    <span class="s2">&quot;*&quot;</span><span class="p">,</span>
    <span class="s2">&quot;tags:page.name&quot;</span><span class="p">,</span>    <span class="c1"># extracts {&quot;tags&quot;:{&quot;page&quot;:{&quot;name&quot;:...}}}</span>
    <span class="s2">&quot;tags:page.id::int&quot;</span><span class="p">,</span> <span class="c1"># extracts {&quot;tags&quot;:{&quot;page&quot;:{&quot;id&quot;:...}}} and casts to int</span>
    <span class="s2">&quot;tags:eventType&quot;</span>     <span class="c1"># extracts {&quot;tags&quot;:{&quot;eventType&quot;:...}}</span>
  <span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;json&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="c1">// The schema location directory keeps track of your data schema over time</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;source-data-with-nested-json&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">selectExpr</span><span class="p">(</span>
<span class="w">    </span><span class="s">&quot;*&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="s">&quot;tags:page.name&quot;</span><span class="p">,</span><span class="w">     </span><span class="c1">// extracts {&quot;tags&quot;:{&quot;page&quot;:{&quot;name&quot;:...}}}</span>
<span class="w">    </span><span class="s">&quot;tags:page.id::int&quot;</span><span class="p">,</span><span class="w">  </span><span class="c1">// extracts {&quot;tags&quot;:{&quot;page&quot;:{&quot;id&quot;:...}}} and casts to int</span>
<span class="w">    </span><span class="s">&quot;tags:eventType&quot;</span><span class="w">      </span><span class="c1">// extracts {&quot;tags&quot;:{&quot;eventType&quot;:...}}</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="infer-nested-json-data">
<h2>Infer nested JSON data<a class="headerlink" href="#infer-nested-json-data" title="Permalink to this headline"> </a></h2>
<p>When you have nested data, you can use the <code class="docutils literal notranslate"><span class="pre">cloudFiles.inferColumnTypes</span></code> option to infer the nested structure of your data and other column types.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span> \
  <span class="c1"># The schema location directory keeps track of your data schema over time</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.inferColumnTypes&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;source-data-with-nested-json&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;json&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="c1">// The schema location directory keeps track of your data schema over time</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.inferColumnTypes&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;source-data-with-nested-json&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="load-csv-files-without-headers">
<h2>Load CSV files without headers<a class="headerlink" href="#load-csv-files-without-headers" title="Permalink to this headline"> </a></h2>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;rescuedDataColumn&quot;</span><span class="p">,</span> <span class="s2">&quot;_rescued_data&quot;</span><span class="p">)</span> \ <span class="c1"># makes sure that you don&#39;t lose data</span>
  <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">&gt;</span><span class="p">)</span> \ <span class="c1"># provide a schema here for the files</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;csv&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;rescuedDataColumn&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;_rescued_data&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1">// makes sure that you don&#39;t lose data</span>
<span class="w">  </span><span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">&gt;</span><span class="p">)</span><span class="w"> </span><span class="c1">// provide a schema here for the files</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="enforce-a-schema-on-csv-files-with-headers">
<h2>Enforce a schema on CSV files with headers<a class="headerlink" href="#enforce-a-schema-on-csv-files-with-headers" title="Permalink to this headline"> </a></h2>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;rescuedDataColumn&quot;</span><span class="p">,</span> <span class="s2">&quot;_rescued_data&quot;</span><span class="p">)</span> \ <span class="c1"># makes sure that you don&#39;t lose data</span>
  <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">&gt;</span><span class="p">)</span> \ <span class="c1"># provide a schema here for the files</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;csv&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;header&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;rescuedDataColumn&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;_rescued_data&quot;</span><span class="p">)</span><span class="w"> </span><span class="c1">// makes sure that you don&#39;t lose data</span>
<span class="w">  </span><span class="p">.</span><span class="n">schema</span><span class="p">(</span><span class="o">&lt;</span><span class="n">schema</span><span class="o">&gt;</span><span class="p">)</span><span class="w"> </span><span class="c1">// provide a schema here for the files</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="o">&lt;</span><span class="n">path</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="ingest-image-or-binary-data-to-delta-lake-for-ml">
<span id="ingest-image-or-binary-data-to-delta-for-ml"></span><span id="image"></span><h2>Ingest image or binary data to Delta Lake for ML<a class="headerlink" href="#ingest-image-or-binary-data-to-delta-lake-for-ml" title="Permalink to this headline"> </a></h2>
<p>Once the data is stored in Delta Lake, you can run distributed inference on the data. See <a class="reference internal" href="../../machine-learning/reference-solutions/images-etl-inference.html#perform-distributed-inference-using-pandas-udf"><span class="std std-ref">Perform distributed inference using pandas UDF</span></a>.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;binaryFile&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">writeStream</span> \
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span> \
  <span class="o">.</span><span class="n">start</span><span class="p">(</span><span class="s2">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;cloudFiles&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;cloudFiles.format&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;binaryFile&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">(</span><span class="s">&quot;&lt;path-to-source-data&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;checkpointLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;&lt;path-to-checkpoint&gt;&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">(</span><span class="s">&quot;&lt;path_to_target&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="auto-loader-syntax-for-dlt">
<span id="al-syntax-for-dlt"></span><h2>Auto Loader syntax for DLT<a class="headerlink" href="#auto-loader-syntax-for-dlt" title="Permalink to this headline"> </a></h2>
<p>Delta Live Tables provides slightly modified Python syntax for Auto Loader adds SQL support for Auto Loader.</p>
<p>The following examples use Auto Loader to create datasets from CSV and JSON files:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;csv&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/retail-org/customers/&quot;</span><span class="p">)</span>
  <span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">sales_orders_raw</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/retail-org/sales_orders/&quot;</span><span class="p">)</span>
  <span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span><span class="ss">&quot;/databricks-datasets/retail-org/customers/&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;csv&quot;</span><span class="p">)</span>

<span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">sales_orders_raw</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span><span class="ss">&quot;/databricks-datasets/retail-org/sales_orders/&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;json&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>You can use supported <a class="reference internal" href="options.html#format-options"><span class="std std-ref">format options</span></a> with Auto Loader. Using the <code class="docutils literal notranslate"><span class="pre">map()</span></code> function, you can pass options to the <code class="docutils literal notranslate"><span class="pre">cloud_files()</span></code> method. Options are key-value pairs, where the keys and values are strings. The following describes the syntax for working with Auto Loader in SQL:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="o">&lt;</span><span class="k">table</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span>
<span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span>
<span class="w">    </span><span class="ss">&quot;&lt;file-path&gt;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="ss">&quot;&lt;file-format&gt;&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="k">map</span><span class="p">(</span>
<span class="w">      </span><span class="ss">&quot;&lt;option-key&gt;&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;&lt;option_value&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="ss">&quot;&lt;option-key&gt;&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;&lt;option_value&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="p">...</span>
<span class="w">    </span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
<p>The following example reads data from tab-delimited CSV files with a header:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">customers</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span><span class="ss">&quot;/databricks-datasets/retail-org/customers/&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;csv&quot;</span><span class="p">,</span><span class="w"> </span><span class="k">map</span><span class="p">(</span><span class="ss">&quot;delimiter&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;\t&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;header&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;true&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">schema</span></code> to specify the format manually; you must specify the <code class="docutils literal notranslate"><span class="pre">schema</span></code> for formats that do not support <a class="reference internal" href="schema.html"><span class="doc">schema inference</span></a>:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">wiki_raw</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">schema</span><span class="p">(</span><span class="s2">&quot;title STRING, id INT, revisionId INT, revisionTimestamp TIMESTAMP, revisionUsername STRING, revisionUsernameId INT, text STRING&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;parquet&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia/articles-only-parquet&quot;</span><span class="p">)</span>
  <span class="p">)</span>
</pre></div>
</div>
<div class="compound-last highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="n">REFRESH</span><span class="w"> </span><span class="n">STREAMING</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="n">wiki_raw</span>
<span class="k">AS</span><span class="w"> </span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span>
<span class="w">  </span><span class="k">FROM</span><span class="w"> </span><span class="n">cloud_files</span><span class="p">(</span>
<span class="w">    </span><span class="ss">&quot;/databricks-datasets/wikipedia-datasets/data-001/en_wikipedia/articles-only-parquet&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="ss">&quot;parquet&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="k">map</span><span class="p">(</span><span class="ss">&quot;schema&quot;</span><span class="p">,</span><span class="w"> </span><span class="ss">&quot;title STRING, id INT, revisionId INT, revisionTimestamp TIMESTAMP, revisionUsername STRING, revisionUsernameId INT, text STRING&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Delta Live Tables automatically configures and manages the schema and checkpoint directories when using Auto Loader to read files. However, if you manually configure either of these directories, performing a full refresh does not affect the contents of the configured directories. Databricks recommends using the automatically configured directories to avoid unexpected side effects during processing.</p>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>