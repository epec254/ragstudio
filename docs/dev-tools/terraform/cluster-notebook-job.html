

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to use the Databricks Terraform provider to create a cluster, a notebook, and a job in an existing Databricks workspace." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Create clusters, notebooks, and jobs with Terraform">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Create clusters, notebooks, and jobs with Terraform &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/dev-tools/terraform/cluster-notebook-job.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/dev-tools/terraform/cluster-notebook-job.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/dev-tools/terraform/cluster-notebook-job.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/dev-tools/terraform/cluster-notebook-job.html" class="notranslate">English</option>
    <option value="../../../ja/dev-tools/terraform/cluster-notebook-job.html" class="notranslate">日本語</option>
    <option value="../../../pt/dev-tools/terraform/cluster-notebook-job.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Create clusters, notebooks, and jobs with Terraform</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="create-clusters-notebooks-and-jobs-with-terraform">
<h1>Create clusters, notebooks, and jobs with Terraform<a class="headerlink" href="#create-clusters-notebooks-and-jobs-with-terraform" title="Permalink to this headline"> </a></h1>
<p>This article shows how to use the <a class="reference internal" href="index.html"><span class="doc">Databricks Terraform provider</span></a> to create a <a class="reference internal" href="../../compute/index.html"><span class="doc">cluster</span></a>, a <a class="reference internal" href="../../notebooks/index.html"><span class="doc">notebook</span></a>, and a <a class="reference internal" href="../../workflows/jobs/create-run-jobs.html"><span class="doc">job</span></a> in an existing Databricks <a class="reference internal" href="../../workspace/index.html"><span class="doc">workspace</span></a>.</p>
<p>This article is a companion to the following Databricks getting started articles:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../getting-started/etl-quick-start.html"><span class="doc">Run your first ETL workload on Databricks</span></a>, which uses a general-purpose cluster, a Python notebook, and a job to run the notebook.</p></li>
<li><p><a class="reference internal" href="../../getting-started/quick-start.html"><span class="doc">Tutorial: Query data with notebooks</span></a>, which uses a general-purpose cluster and a SQL notebook.</p></li>
</ul>
<ul class="simple">
<li><p><a class="reference internal" href="../../getting-started/lakehouse-e2e.html"><span class="doc">Tutorial: Run an end-to-end lakehouse analytics pipeline</span></a>, which uses a cluster that works with Unity Catalog, a Python notebook, and a job to run the notebook.</p></li>
</ul>
<p>You can also adapt the Terraform configurations in this article to create custom clusters, notebooks, and jobs in your workspaces.</p>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul>
<li><p>A Databricks workspace.</p></li>
<li><p>On your local development machine, you must have:</p>
<ul>
<li><p>The Terraform CLI. See <a class="reference external" href="https://www.terraform.io/downloads.html">Download Terraform</a> on the Terraform website.</p></li>
<li><p>One of the following:</p>
<ul>
<li><p>Databricks CLI version 0.205 or above, configured with your Databricks <a class="reference internal" href="../auth/pat.html"><span class="doc">personal access token</span></a> by running <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">configure</span> <span class="pre">--host</span> <span class="pre">&lt;workspace-url&gt;</span> <span class="pre">--profile</span> <span class="pre">&lt;some-unique-profile-name&gt;</span></code>. See <a class="reference internal" href="../cli/install.html"><span class="doc">Install or update the Databricks CLI</span></a> and <a class="reference internal" href="../cli/authentication.html#token-auth"><span class="std std-ref">Databricks personal access token authentication</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a security best practice when you authenticate with automated tools, systems, scripts, and apps, Databricks recommends that you use OAuth tokens.</p>
<p>If you use personal access token authentication, Databricks recommends using personal access tokens belonging to <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html"><span class="doc">service principals</span></a> instead of workspace users. To create tokens for service principals, see <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html#personal-access-tokens"><span class="std std-ref">Manage tokens for a service principal</span></a>.</p>
</div>
</li>
<li><p>The following Databricks environment variables:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATABRICKS_HOST</span></code>, set to the value of your Databricks <a class="reference internal" href="../../workspace/workspace-details.html#workspace-url"><span class="std std-ref">workspace instance URL</span></a>, for example <code class="docutils literal notranslate"><span class="pre">https://dbc-1234567890123456.cloud.databricks.com</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DATABRICKS_CLIENT_ID</span></code>, set to the value of the client ID, also known as the application ID, of the service principal. See <a class="reference internal" href="../authentication-oauth.html"><span class="doc">Authentication using OAuth for service principals</span></a>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DATABRICKS_CLIENT_SECRET</span></code>, set to the value of the client secret of the service principal. See <a class="reference internal" href="../authentication-oauth.html"><span class="doc">Authentication using OAuth for service principals</span></a>.</p></li>
</ul>
<p>Alternatively, you can use a personal access token instead of a service principal’s client ID and client secret:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">DATABRICKS_TOKEN</span></code>, set to the value of your Databricks <a class="reference internal" href="../auth/pat.html"><span class="doc">personal access token</span></a>. See also <a class="reference internal" href="../../administration-guide/access-control/tokens.html"><span class="doc">Manage personal access tokens</span></a>.</p></li>
</ul>
<p>To set these environment variables, see your operating system’s documentation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a security best practice when you authenticate with automated tools, systems, scripts, and apps, Databricks recommends that you use OAuth tokens.</p>
<p>If you use personal access token authentication, Databricks recommends using personal access tokens belonging to <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html"><span class="doc">service principals</span></a> instead of workspace users. To create tokens for service principals, see <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html#personal-access-tokens"><span class="std std-ref">Manage tokens for a service principal</span></a>.</p>
</div>
</li>
</ul>
</li>
</ul>
</li>
</ul>
</div>
<div class="section" id="step-1-set-up-the-terraform-project">
<h2>Step 1: Set up the Terraform project<a class="headerlink" href="#step-1-set-up-the-terraform-project" title="Permalink to this headline"> </a></h2>
<p>In this step, you set up a Terraform project to define the settings for Terraform to authenticate with your workspace. You also define the settings for the resources that Terraform deploys to your workspace.</p>
<ol class="arabic">
<li><p>Create an empty directory and then switch to it. This directory contains your Terraform project files. (Each separate set of Terraform project files must be in its own parent directory.) To do this, in your terminal or PowerShell, run a command like the following:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>mkdir<span class="w"> </span>terraform_cluster_notebook_job<span class="w"> </span><span class="o">&amp;&amp;</span><span class="w"> </span><span class="nb">cd</span><span class="w"> </span>terraform_cluster_notebook_job
</pre></div>
</div>
</li>
<li><p>In this empty directory, create a file named <code class="docutils literal notranslate"><span class="pre">auth.tf</span></code>, and add the following content to the file. This configuration initializes the Databricks Terraform provider and authenticates Terraform with your workspace.</p>
<p>To authenticate with a Databricks CLI configuration profile, add the following content:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">variable</span> <span class="s2">&quot;databricks_connection_profile&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;The name of the Databricks connection profile to use.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
<span class="p">}</span>

<span class="c1"># Initialize the Databricks Terraform provider.</span>
<span class="n">terraform</span> <span class="p">{</span>
  <span class="n">required_providers</span> <span class="p">{</span>
    <span class="n">databricks</span> <span class="o">=</span> <span class="p">{</span>
      <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;databricks/databricks&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Use Databricks CLI authentication.</span>
<span class="n">provider</span> <span class="s2">&quot;databricks&quot;</span> <span class="p">{</span>
  <span class="n">profile</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">databricks_connection_profile</span>
<span class="p">}</span>

<span class="c1"># Retrieve information about the current user.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_current_user&quot;</span> <span class="s2">&quot;me&quot;</span> <span class="p">{}</span>
</pre></div>
</div>
<p>To authenticate with environment variables, add the following content instead:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Initialize the Databricks Terraform provider.</span>
<span class="n">terraform</span> <span class="p">{</span>
  <span class="n">required_providers</span> <span class="p">{</span>
    <span class="n">databricks</span> <span class="o">=</span> <span class="p">{</span>
      <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;databricks/databricks&quot;</span>
    <span class="p">}</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="c1"># Use environment variables for authentication.</span>
<span class="n">provider</span> <span class="s2">&quot;databricks&quot;</span> <span class="p">{}</span>

<span class="c1"># Retrieve information about the current user.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_current_user&quot;</span> <span class="s2">&quot;me&quot;</span> <span class="p">{}</span>
</pre></div>
</div>
</li>
</ol>
<ol class="arabic" start="3">
<li><p>Create another file named <code class="docutils literal notranslate"><span class="pre">auth.auto.tfvars</span></code>, and add the following content to the file. This file contains variable values for authenticating Terraform with your workspace. Replace the placeholder values with your own values.</p>
<p>To authenticate with a Databricks CLI configuration profile, add the following content:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">databricks_connection_profile</span> <span class="o">=</span> <span class="s2">&quot;DEFAULT&quot;</span>
</pre></div>
</div>
<p>To authenticate with with environment variables, you do not need an <code class="docutils literal notranslate"><span class="pre">auth.auto.tfvars</span></code> file.</p>
</li>
</ol>
<ol class="arabic" start="4">
<li><p>Run the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">init</span></code> command. This command initializes your Terraform project by creating additional helper files and downloading the necessary Terraform modules.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>init
</pre></div>
</div>
</li>
<li><p>If you are creating a cluster, create another file named <code class="docutils literal notranslate"><span class="pre">cluster.tf</span></code>, and add the following content to the file. This content creates a cluster with the smallest amount of resources allowed. This cluster uses the lastest Databricks Runtime Long Term Support (LTS) version.</p>
<p>For a cluster that works with Unity Catalog:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">variable</span> <span class="s2">&quot;cluster_name&quot;</span> <span class="p">{}</span>
<span class="n">variable</span> <span class="s2">&quot;cluster_autotermination_minutes&quot;</span> <span class="p">{}</span>
<span class="n">variable</span> <span class="s2">&quot;cluster_num_workers&quot;</span> <span class="p">{}</span>
<span class="n">variable</span> <span class="s2">&quot;cluster_data_security_mode&quot;</span> <span class="p">{}</span>

<span class="c1"># Create the cluster with the &quot;smallest&quot; amount</span>
<span class="c1"># of resources allowed.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_node_type&quot;</span> <span class="s2">&quot;smallest&quot;</span> <span class="p">{</span>
  <span class="n">local_disk</span> <span class="o">=</span> <span class="n">true</span>
<span class="p">}</span>

<span class="c1"># Use the latest Databricks Runtime</span>
<span class="c1"># Long Term Support (LTS) version.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_spark_version&quot;</span> <span class="s2">&quot;latest_lts&quot;</span> <span class="p">{</span>
  <span class="n">long_term_support</span> <span class="o">=</span> <span class="n">true</span>
<span class="p">}</span>

<span class="n">resource</span> <span class="s2">&quot;databricks_cluster&quot;</span> <span class="s2">&quot;this&quot;</span> <span class="p">{</span>
  <span class="n">cluster_name</span>            <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_name</span>
  <span class="n">node_type_id</span>            <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_node_type</span><span class="o">.</span><span class="n">smallest</span><span class="o">.</span><span class="n">id</span>
  <span class="n">spark_version</span>           <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_spark_version</span><span class="o">.</span><span class="n">latest_lts</span><span class="o">.</span><span class="n">id</span>
  <span class="n">autotermination_minutes</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_autotermination_minutes</span>
  <span class="n">num_workers</span>             <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_num_workers</span>
  <span class="n">data_security_mode</span>      <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_data_security_mode</span>
<span class="p">}</span>

<span class="n">output</span> <span class="s2">&quot;cluster_url&quot;</span> <span class="p">{</span>
 <span class="n">value</span> <span class="o">=</span> <span class="n">databricks_cluster</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">url</span>
<span class="p">}</span>
</pre></div>
</div>
<p>For an all-purpose cluster:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">variable</span> <span class="s2">&quot;cluster_name&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;A name for the cluster.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
  <span class="n">default</span>     <span class="o">=</span> <span class="s2">&quot;My Cluster&quot;</span>
<span class="p">}</span>

<span class="n">variable</span> <span class="s2">&quot;cluster_autotermination_minutes&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;How many minutes before automatically terminating due to inactivity.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">number</span>
  <span class="n">default</span>     <span class="o">=</span> <span class="mi">60</span>
<span class="p">}</span>

<span class="n">variable</span> <span class="s2">&quot;cluster_num_workers&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;The number of workers.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">number</span>
  <span class="n">default</span>     <span class="o">=</span> <span class="mi">1</span>
<span class="p">}</span>

<span class="c1"># Create the cluster with the &quot;smallest&quot; amount</span>
<span class="c1"># of resources allowed.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_node_type&quot;</span> <span class="s2">&quot;smallest&quot;</span> <span class="p">{</span>
  <span class="n">local_disk</span> <span class="o">=</span> <span class="n">true</span>
<span class="p">}</span>

<span class="c1"># Use the latest Databricks Runtime</span>
<span class="c1"># Long Term Support (LTS) version.</span>
<span class="n">data</span> <span class="s2">&quot;databricks_spark_version&quot;</span> <span class="s2">&quot;latest_lts&quot;</span> <span class="p">{</span>
  <span class="n">long_term_support</span> <span class="o">=</span> <span class="n">true</span>
<span class="p">}</span>

<span class="n">resource</span> <span class="s2">&quot;databricks_cluster&quot;</span> <span class="s2">&quot;this&quot;</span> <span class="p">{</span>
  <span class="n">cluster_name</span>            <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_name</span>
  <span class="n">node_type_id</span>            <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_node_type</span><span class="o">.</span><span class="n">smallest</span><span class="o">.</span><span class="n">id</span>
  <span class="n">spark_version</span>           <span class="o">=</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_spark_version</span><span class="o">.</span><span class="n">latest_lts</span><span class="o">.</span><span class="n">id</span>
  <span class="n">autotermination_minutes</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_autotermination_minutes</span>
  <span class="n">num_workers</span>             <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">cluster_num_workers</span>
<span class="p">}</span>

<span class="n">output</span> <span class="s2">&quot;cluster_url&quot;</span> <span class="p">{</span>
 <span class="n">value</span> <span class="o">=</span> <span class="n">databricks_cluster</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">url</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>If you are creating the cluster, create another file named <code class="docutils literal notranslate"><span class="pre">cluster.auto.tfvars</span></code>, and add the following content to the file. This file contains variable values for customizing the cluster. Replace the placeholder values with your own values.</p>
<p>For a cluster that works with Unity Catalog:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_name</span>                    <span class="o">=</span> <span class="s2">&quot;My Cluster&quot;</span>
<span class="n">cluster_autotermination_minutes</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">cluster_num_workers</span>             <span class="o">=</span> <span class="mi">1</span>
<span class="n">cluster_data_security_mode</span>      <span class="o">=</span> <span class="s2">&quot;SINGLE_USER&quot;</span>
</pre></div>
</div>
<p>For an all-purpose cluster:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">cluster_name</span>                    <span class="o">=</span> <span class="s2">&quot;My Cluster&quot;</span>
<span class="n">cluster_autotermination_minutes</span> <span class="o">=</span> <span class="mi">60</span>
<span class="n">cluster_num_workers</span>             <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</li>
<li><p>If you are creating a notebook, create another file named <code class="docutils literal notranslate"><span class="pre">notebook.tf</span></code>, and add the following content to the file:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">variable</span> <span class="s2">&quot;notebook_subdirectory&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;A name for the subdirectory to store the notebook.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
  <span class="n">default</span>     <span class="o">=</span> <span class="s2">&quot;Terraform&quot;</span>
<span class="p">}</span>

<span class="n">variable</span> <span class="s2">&quot;notebook_filename&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;The notebook&#39;s filename.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
<span class="p">}</span>

<span class="n">variable</span> <span class="s2">&quot;notebook_language&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;The language of the notebook.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
<span class="p">}</span>

<span class="n">resource</span> <span class="s2">&quot;databricks_notebook&quot;</span> <span class="s2">&quot;this&quot;</span> <span class="p">{</span>
  <span class="n">path</span>     <span class="o">=</span> <span class="s2">&quot;$</span><span class="si">{data.databricks_current_user.me.home}</span><span class="s2">/$</span><span class="si">{var.notebook_subdirectory}</span><span class="s2">/$</span><span class="si">{var.notebook_filename}</span><span class="s2">&quot;</span>
  <span class="n">language</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">notebook_language</span>
  <span class="n">source</span>   <span class="o">=</span> <span class="s2">&quot;./$</span><span class="si">{var.notebook_filename}</span><span class="s2">&quot;</span>
<span class="p">}</span>

<span class="n">output</span> <span class="s2">&quot;notebook_url&quot;</span> <span class="p">{</span>
 <span class="n">value</span> <span class="o">=</span> <span class="n">databricks_notebook</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">url</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>Save the following notebook code to a file in the same directory as the <code class="docutils literal notranslate"><span class="pre">notebook.tf</span></code> file:</p>
<p>For the Python notebook for <a class="reference internal" href="../../getting-started/etl-quick-start.html"><span class="doc">Run your first ETL workload on Databricks</span></a>, a file named <code class="docutils literal notranslate"><span class="pre">notebook-getting-started-etl-quick-start.py</span></code> with the following contents:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Databricks notebook source</span>
<span class="c1"># Import functions</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">current_timestamp</span>

<span class="c1"># Define variables used in code below</span>
<span class="n">file_path</span> <span class="o">=</span> <span class="s2">&quot;/databricks-datasets/structured-streaming/events&quot;</span>
<span class="n">username</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT regexp_replace(current_user(), &#39;[^a-zA-Z0-9]&#39;, &#39;_&#39;)&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">table_name</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s2">_etl_quickstart&quot;</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;/tmp/</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s2">/_checkpoint/etl_quickstart&quot;</span>

<span class="c1"># Clear out data from previous demo execution</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;DROP TABLE IF EXISTS </span><span class="si">{</span><span class="n">table_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>

<span class="c1"># Configure Auto Loader to ingest JSON data to a Delta table</span>
<span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;_metadata.file_path&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;source_file&quot;</span><span class="p">),</span> <span class="n">current_timestamp</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;processing_time&quot;</span><span class="p">))</span>
  <span class="o">.</span><span class="n">writeStream</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">trigger</span><span class="p">(</span><span class="n">availableNow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="o">.</span><span class="n">toTable</span><span class="p">(</span><span class="n">table_name</span><span class="p">))</span>

<span class="c1"># COMMAND ----------</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>

<span class="c1"># COMMAND ----------</span>

<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
<p>For the SQL notebook for <a class="reference internal" href="../../getting-started/quick-start.html"><span class="doc">Tutorial: Query data with notebooks</span></a>, a file named <code class="docutils literal notranslate"><span class="pre">notebook-getting-started-quick-start.sql</span></code> with the following contents:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">--</span> <span class="n">Databricks</span> <span class="n">notebook</span> <span class="n">source</span>
<span class="o">--</span> <span class="n">MAGIC</span> <span class="o">%</span><span class="n">python</span>
<span class="o">--</span> <span class="n">MAGIC</span> <span class="n">diamonds</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">read</span>
<span class="o">--</span> <span class="n">MAGIC</span>   <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span>
<span class="o">--</span> <span class="n">MAGIC</span>   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
<span class="o">--</span> <span class="n">MAGIC</span>   <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
<span class="o">--</span> <span class="n">MAGIC</span>   <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv&quot;</span><span class="p">)</span>
<span class="o">--</span> <span class="n">MAGIC</span> <span class="p">)</span>
<span class="o">--</span> <span class="n">MAGIC</span> 
<span class="o">--</span> <span class="n">MAGIC</span> <span class="n">diamonds</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;delta&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="s2">&quot;/mnt/delta/diamonds&quot;</span><span class="p">)</span>

<span class="o">--</span> <span class="n">COMMAND</span> <span class="o">----------</span>

<span class="n">DROP</span> <span class="n">TABLE</span> <span class="n">IF</span> <span class="n">EXISTS</span> <span class="n">diamonds</span><span class="p">;</span>

<span class="n">CREATE</span> <span class="n">TABLE</span> <span class="n">diamonds</span> <span class="n">USING</span> <span class="n">DELTA</span> <span class="n">LOCATION</span> <span class="s1">&#39;/mnt/delta/diamonds/&#39;</span>

<span class="o">--</span> <span class="n">COMMAND</span> <span class="o">----------</span>

<span class="n">SELECT</span> <span class="n">color</span><span class="p">,</span> <span class="n">avg</span><span class="p">(</span><span class="n">price</span><span class="p">)</span> <span class="n">AS</span> <span class="n">price</span> <span class="n">FROM</span> <span class="n">diamonds</span> <span class="n">GROUP</span> <span class="n">BY</span> <span class="n">color</span> <span class="n">ORDER</span> <span class="n">BY</span> <span class="n">COLOR</span>
</pre></div>
</div>
<p>For the Python notebook for <a class="reference internal" href="../../getting-started/lakehouse-e2e.html"><span class="doc">Tutorial: Run an end-to-end lakehouse analytics pipeline</span></a>, a file named <code class="docutils literal notranslate"><span class="pre">notebook-getting-started-lakehouse-e2e.py</span></code> with the following contents:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="c1"># Databricks notebook source</span>
<span class="n">external_location</span> <span class="o">=</span> <span class="s2">&quot;&lt;your_external_location&gt;&quot;</span>
<span class="n">catalog</span> <span class="o">=</span> <span class="s2">&quot;&lt;your_catalog&gt;&quot;</span>

<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">external_location</span><span class="si">}</span><span class="s2">/foobar.txt&quot;</span><span class="p">,</span> <span class="s2">&quot;Hello world!&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">display</span><span class="p">(</span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">head</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">external_location</span><span class="si">}</span><span class="s2">/foobar.txt&quot;</span><span class="p">))</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">external_location</span><span class="si">}</span><span class="s2">/foobar.txt&quot;</span><span class="p">)</span>

<span class="n">display</span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SHOW SCHEMAS IN </span><span class="si">{</span><span class="n">catalog</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">))</span>

<span class="c1"># COMMAND ----------</span>

<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span>

<span class="c1"># Set parameters for isolation in workspace and reset demo</span>
<span class="n">username</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT regexp_replace(current_user(), &#39;[^a-zA-Z0-9]&#39;, &#39;_&#39;)&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">database</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">catalog</span><span class="si">}</span><span class="s2">.e2e_lakehouse_</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s2">_db&quot;</span>
<span class="n">source</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">external_location</span><span class="si">}</span><span class="s2">/e2e-lakehouse-source&quot;</span>
<span class="n">table</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">database</span><span class="si">}</span><span class="s2">.target_table&quot;</span>
<span class="n">checkpoint_path</span> <span class="o">=</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">external_location</span><span class="si">}</span><span class="s2">/_checkpoint/e2e-lakehouse-demo&quot;</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SET c.username=&#39;</span><span class="si">{</span><span class="n">username</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SET c.database=</span><span class="si">{</span><span class="n">database</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;SET c.source=&#39;</span><span class="si">{</span><span class="n">source</span><span class="si">}</span><span class="s2">&#39;&quot;</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;DROP DATABASE IF EXISTS $</span><span class="si">{c.database}</span><span class="s2"> CASCADE&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;CREATE DATABASE $</span><span class="si">{c.database}</span><span class="s2">&quot;</span><span class="p">)</span>
<span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;USE $</span><span class="si">{c.database}</span><span class="s2">&quot;</span><span class="p">)</span>

<span class="c1"># Clear out data from previous demo execution</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="n">source</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">rm</span><span class="p">(</span><span class="n">checkpoint_path</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>


<span class="c1"># Define a class to load batches of data to source</span>
<span class="k">class</span> <span class="nc">LoadData</span><span class="p">:</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">source</span> <span class="o">=</span> <span class="n">source</span>

  <span class="k">def</span> <span class="nf">get_date</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="s2">&quot;2016-01-01&quot;</span>
    <span class="n">batch_date</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">selectExpr</span><span class="p">(</span><span class="s2">&quot;max(distinct(date(tpep_pickup_datetime))) + 1 day&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">first</span><span class="p">()[</span><span class="mi">0</span><span class="p">]</span>
    <span class="k">if</span> <span class="n">batch_date</span><span class="o">.</span><span class="n">month</span> <span class="o">==</span> <span class="mi">3</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="s2">&quot;Source data exhausted&quot;</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">batch_date</span>

  <span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch_date</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span>
      <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;samples.nyctaxi.trips&quot;</span><span class="p">)</span>
        <span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;tpep_pickup_datetime&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">cast</span><span class="p">(</span><span class="s2">&quot;date&quot;</span><span class="p">)</span> <span class="o">==</span> <span class="n">batch_date</span><span class="p">)</span>
    <span class="p">)</span>

  <span class="k">def</span> <span class="nf">write_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">batch</span><span class="p">):</span>
    <span class="n">batch</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">save</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">source</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">land_batch</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">batch_date</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_date</span><span class="p">()</span>
    <span class="n">batch</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">get_batch</span><span class="p">(</span><span class="n">batch_date</span><span class="p">)</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">write_batch</span><span class="p">(</span><span class="n">batch</span><span class="p">)</span>

<span class="n">RawData</span> <span class="o">=</span> <span class="n">LoadData</span><span class="p">(</span><span class="n">source</span><span class="p">)</span>

<span class="c1"># COMMAND ----------</span>

<span class="n">RawData</span><span class="o">.</span><span class="n">land_batch</span><span class="p">()</span>

<span class="c1"># COMMAND ----------</span>

<span class="c1"># Import functions</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">current_timestamp</span>

<span class="c1"># Configure Auto Loader to ingest JSON data to a Delta table</span>
<span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;json&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="s2">&quot;*&quot;</span><span class="p">,</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;_metadata.file_path&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;source_file&quot;</span><span class="p">),</span> <span class="n">current_timestamp</span><span class="p">()</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;processing_time&quot;</span><span class="p">))</span>
  <span class="o">.</span><span class="n">writeStream</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">trigger</span><span class="p">(</span><span class="n">availableNow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;mergeSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">toTable</span><span class="p">(</span><span class="n">table</span><span class="p">))</span>

<span class="c1"># COMMAND ----------</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>

<span class="c1"># COMMAND ----------</span>

<span class="n">display</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>If you are creating the notebook, create another file named <code class="docutils literal notranslate"><span class="pre">notebook.auto.tfvars</span></code>, and add the following content to the file. This file contains variable values for customizing the notebook configuration.</p>
<p>For the Python notebook for <a class="reference internal" href="../../getting-started/etl-quick-start.html"><span class="doc">Run your first ETL workload on Databricks</span></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">notebook_subdirectory</span> <span class="o">=</span> <span class="s2">&quot;Terraform&quot;</span>
<span class="n">notebook_filename</span>     <span class="o">=</span> <span class="s2">&quot;notebook-getting-started-etl-quick-start.py&quot;</span>
<span class="n">notebook_language</span>     <span class="o">=</span> <span class="s2">&quot;PYTHON&quot;</span>
</pre></div>
</div>
<p>For the SQL notebook for <a class="reference internal" href="../../getting-started/quick-start.html"><span class="doc">Tutorial: Query data with notebooks</span></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">notebook_subdirectory</span> <span class="o">=</span> <span class="s2">&quot;Terraform&quot;</span>
<span class="n">notebook_filename</span>     <span class="o">=</span> <span class="s2">&quot;notebook-getting-started-quickstart.sql&quot;</span>
<span class="n">notebook_language</span>     <span class="o">=</span> <span class="s2">&quot;SQL&quot;</span>
</pre></div>
</div>
<p>For the Python notebook for <a class="reference internal" href="../../getting-started/lakehouse-e2e.html"><span class="doc">Tutorial: Run an end-to-end lakehouse analytics pipeline</span></a>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">notebook_subdirectory</span> <span class="o">=</span> <span class="s2">&quot;Terraform&quot;</span>
<span class="n">notebook_filename</span>     <span class="o">=</span> <span class="s2">&quot;notebook-getting-started-lakehouse-e2e.py&quot;</span>
<span class="n">notebook_language</span>     <span class="o">=</span> <span class="s2">&quot;PYTHON&quot;</span>
</pre></div>
</div>
</li>
<li><p>If you are creating a notebook, in your Databricks workspace, be sure to set up any requirements for the notebook to run successfully, by referring to the following instructions for:</p>
<ul class="simple">
<li><p>The Python notebook for <a class="reference internal" href="../../getting-started/etl-quick-start.html"><span class="doc">Run your first ETL workload on Databricks</span></a></p></li>
<li><p>The SQL notebook for <a class="reference internal" href="../../getting-started/quick-start.html"><span class="doc">Tutorial: Query data with notebooks</span></a></p></li>
</ul>
<ul class="simple">
<li><p>The Python notebook for <a class="reference internal" href="../../getting-started/lakehouse-e2e.html"><span class="doc">Tutorial: Run an end-to-end lakehouse analytics pipeline</span></a></p></li>
</ul>
</li>
<li><p>If you are creating a job, create another file named <code class="docutils literal notranslate"><span class="pre">job.tf</span></code>, and add the following content to the file. This content creates a job to run the notebook.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">variable</span> <span class="s2">&quot;job_name&quot;</span> <span class="p">{</span>
  <span class="n">description</span> <span class="o">=</span> <span class="s2">&quot;A name for the job.&quot;</span>
  <span class="nb">type</span>        <span class="o">=</span> <span class="n">string</span>
  <span class="n">default</span>     <span class="o">=</span> <span class="s2">&quot;My Job&quot;</span>
<span class="p">}</span>

<span class="n">resource</span> <span class="s2">&quot;databricks_job&quot;</span> <span class="s2">&quot;this&quot;</span> <span class="p">{</span>
  <span class="n">name</span> <span class="o">=</span> <span class="n">var</span><span class="o">.</span><span class="n">job_name</span>
  <span class="n">existing_cluster_id</span> <span class="o">=</span> <span class="n">databricks_cluster</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">cluster_id</span>
  <span class="n">notebook_task</span> <span class="p">{</span>
    <span class="n">notebook_path</span> <span class="o">=</span> <span class="n">databricks_notebook</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">path</span>
  <span class="p">}</span>
  <span class="n">email_notifications</span> <span class="p">{</span>
    <span class="n">on_success</span> <span class="o">=</span> <span class="p">[</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_current_user</span><span class="o">.</span><span class="n">me</span><span class="o">.</span><span class="n">user_name</span> <span class="p">]</span>
    <span class="n">on_failure</span> <span class="o">=</span> <span class="p">[</span> <span class="n">data</span><span class="o">.</span><span class="n">databricks_current_user</span><span class="o">.</span><span class="n">me</span><span class="o">.</span><span class="n">user_name</span> <span class="p">]</span>
  <span class="p">}</span>
<span class="p">}</span>

<span class="n">output</span> <span class="s2">&quot;job_url&quot;</span> <span class="p">{</span>
  <span class="n">value</span> <span class="o">=</span> <span class="n">databricks_job</span><span class="o">.</span><span class="n">this</span><span class="o">.</span><span class="n">url</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>If you are creating the job, create another file named <code class="docutils literal notranslate"><span class="pre">job.auto.tfvars</span></code>, and add the following content to the file. This file contains a variable value for customizing the job configuration.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">job_name</span> <span class="o">=</span> <span class="s2">&quot;My Job&quot;</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="step-2-run-the-configurations">
<h2>Step 2: Run the configurations<a class="headerlink" href="#step-2-run-the-configurations" title="Permalink to this headline"> </a></h2>
<p>In this step, you run the Terraform configurations to deploy the cluster, the notebook, and the job into your Databricks workspace.</p>
<ol class="arabic">
<li><p>Check to see whether your Terraform configurations are valid by running the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">validate</span></code> command. If any errors are reported, fix them, and run the command again.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>validate
</pre></div>
</div>
</li>
<li><p>Check to see what Terraform will do in your workspace, before Terraform actually does it, by running the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">plan</span></code> command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>plan
</pre></div>
</div>
</li>
<li><p>Deploy the cluster, the notebook, and the job into your workspace by running the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">apply</span></code> command. When prompted to deploy, type <code class="docutils literal notranslate"><span class="pre">yes</span></code> and press <strong>Enter</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>apply
</pre></div>
</div>
<p>Terraform deploys the resources that are specified in your project. Deploying these resources (especially a cluster) can take several minutes.</p>
</li>
</ol>
</div>
<div class="section" id="step-3-explore-the-results">
<h2>Step 3: Explore the results<a class="headerlink" href="#step-3-explore-the-results" title="Permalink to this headline"> </a></h2>
<ol class="arabic">
<li><p>If you created a cluster, in the output of the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">apply</span></code> command, copy the link next to <code class="docutils literal notranslate"><span class="pre">cluster_url</span></code>, and paste it into your web browser’s address bar.</p></li>
<li><p>If you created a notebook, in the output of the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">apply</span></code> command, copy the link next to <code class="docutils literal notranslate"><span class="pre">notebook_url</span></code>, and paste it into your web browser’s address bar.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before you use the notebook, you might need to customize its contents. See the related documentation about how to customize the notebook.</p>
</div>
</li>
<li><p>If you created a job, in the output of the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">apply</span></code> command, copy the link next to <code class="docutils literal notranslate"><span class="pre">job_url</span></code>, and paste it into your web browser’s address bar.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Before you run the notebook, you might need to customize its contents. See the links at the beginning of this article for related documentation about how to customize the notebook.</p>
</div>
</li>
<li><p>If you created a job, run the job as follows:</p>
<ol class="loweralpha simple">
<li><p>Click <strong>Run now</strong> on the job page.</p></li>
<li><p>After the job finishes running, to view the job run’s results, in the <strong>Completed runs (past 60 days)</strong> list on the job page, click the most recent time entry in the <strong>Start time</strong> column. The <strong>Output</strong> pane shows the result of running the notebook’s code.</p></li>
</ol>
</li>
</ol>
</div>
<div class="section" id="step-4-clean-up">
<h2>Step 4: Clean up<a class="headerlink" href="#step-4-clean-up" title="Permalink to this headline"> </a></h2>
<p>In this step, you delete the preceding resources from your workspace.</p>
<ol class="arabic">
<li><p>Check to see what Terraform will do in your workspace, before Terraform actually does it, by running the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">plan</span></code> command.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>plan
</pre></div>
</div>
</li>
<li><p>Delete the cluster, the notebook, and the job from your workspace by running the <code class="docutils literal notranslate"><span class="pre">terraform</span> <span class="pre">destroy</span></code> command. When prompted to delete, type <code class="docutils literal notranslate"><span class="pre">yes</span></code> and press <strong>Enter</strong>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>terraform<span class="w"> </span>destroy
</pre></div>
</div>
<p>Terraform deletes the resources that are specified in your project.</p>
</li>
</ol>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>