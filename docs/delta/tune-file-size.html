

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Control target file size manually or configure file size autotuning with Delta Lake." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Configure Delta Lake to control data file size">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Configure Delta Lake to control data file size &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/delta/tune-file-size.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/delta/tune-file-size.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/delta/tune-file-size.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/delta/tune-file-size.html" class="notranslate">English</option>
    <option value="../../ja/delta/tune-file-size.html" class="notranslate">日本語</option>
    <option value="../../pt/delta/tune-file-size.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Configure Delta Lake to control data file size</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="configure-delta-lake-to-control-data-file-size">
<span id="configure-delta-to-control-data-file-size"></span><h1>Configure Delta Lake to control data file size<a class="headerlink" href="#configure-delta-lake-to-control-data-file-size" title="Permalink to this headline"> </a></h1>
<p>Delta Lake provides options for manually or automatically configuring the target file size for writes and for <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> operations. Databricks automatically tunes many of these settings, and enables features that automatically improve table performance by seeking to right-size files.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In Databricks Runtime 13.3 and above, Databricks recommends using clustering for Delta table layout. See <a class="reference internal" href="clustering.html"><span class="doc">Use liquid clustering for Delta tables</span></a>.</p>
<p>Databricks recommends using predictive optimization to automatically run <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> and <code class="docutils literal notranslate"><span class="pre">VACUUM</span></code> for Delta tables. See <a class="reference internal" href="../optimizations/predictive-optimization.html"><span class="doc">Predictive optimization for Delta Lake</span></a>.</p>
<p>In Databricks Runtime 10.4 LTS and above, auto compaction and optimized writes are always enabled for <code class="docutils literal notranslate"><span class="pre">MERGE</span></code>, <code class="docutils literal notranslate"><span class="pre">UPDATE</span></code>, and <code class="docutils literal notranslate"><span class="pre">DELETE</span></code> operations. You cannot disable this functionality.</p>
<p>Unless otherwise specified, all recommendations in this article do not apply to Unity Catalog managed tables running the latest runtimes.</p>
</div>
<p>For Unity Catalog managed tables, Databricks tunes most of these configurations automatically if you’re using a SQL warehouse or Databricks Runtime 11.3 LTS or above.</p>
<p>If you’re upgrading a workload from Databricks Runtime 11.0 or below, see <a class="reference internal" href="#upgrade"><span class="std std-ref">Upgrade to background auto compaction</span></a>.</p>
<div class="section" id="when-to-run-optimize">
<h2>When to run <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code><a class="headerlink" href="#when-to-run-optimize" title="Permalink to this headline"> </a></h2>
<p>Auto compaction and optimized writes each reduce small file problems, but are not a full replacement for <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code>. Especially for tables larger than 1 TB, Databricks recommends running <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> on a schedule to further consolidate files. Databricks does not automatically run <code class="docutils literal notranslate"><span class="pre">ZORDER</span></code> on tables, so you must run <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> with <code class="docutils literal notranslate"><span class="pre">ZORDER</span></code> to enable enhanced data skipping. See <a class="reference internal" href="data-skipping.html"><span class="doc">Data skipping with Z-order indexes for Delta Lake</span></a>.</p>
<p></p>
</div>
<div class="section" id="what-is-auto-optimize-on-databricks">
<span id="auto-optimize"></span><h2>What is auto optimize on Databricks?<a class="headerlink" href="#what-is-auto-optimize-on-databricks" title="Permalink to this headline"> </a></h2>
<p>The term <em>auto optimize</em> is sometimes used to describe functionality controlled by the settings <code class="docutils literal notranslate"><span class="pre">delta.autoOptimize.autoCompact</span></code> and <code class="docutils literal notranslate"><span class="pre">delta.autoOptimize.optimizeWrite</span></code>. This term has been retired in favor of describing each setting individually. See <a class="reference internal" href="#auto-compact"><span class="std std-ref">Auto compaction for Delta Lake on Databricks</span></a> and <a class="reference internal" href="#optimized-writes"><span class="std std-ref">Optimized writes for Delta Lake on Databricks</span></a>.</p>
</div>
<div class="section" id="auto-compaction-for-delta-lake-on-databricks">
<span id="auto-compaction-for-delta-on-databricks"></span><span id="auto-compact"></span><h2>Auto compaction for Delta Lake on Databricks<a class="headerlink" href="#auto-compaction-for-delta-lake-on-databricks" title="Permalink to this headline"> </a></h2>
<p>Auto compaction combines small files within Delta table partitions to automatically reduce small file problems. Auto compaction occurs after a write to a table has succeeded and runs synchronously on the cluster that has performed the write. Auto compaction only compacts files that haven’t been compacted previously.</p>
<p>You can control the output file size by setting the <a class="reference internal" href="../compute/configure.html#spark-configuration"><span class="std std-ref">Spark configuration</span></a> <code class="docutils literal notranslate"><span class="pre">spark.databricks.delta.autoCompact.maxFileSize</span></code>. Databricks recommends using autotuning based on workload or table size. See <a class="reference internal" href="#autotune-workload"><span class="std std-ref">Autotune file size based on workload</span></a> and <a class="reference internal" href="#autotune-table"><span class="std std-ref">Autotune file size based on table size</span></a>.</p>
<p>Auto compaction is only triggered for partitions or tables that have at least a certain number of small files. You can optionally change the minimum number of files required to trigger auto compaction by setting <code class="docutils literal notranslate"><span class="pre">spark.databricks.delta.autoCompact.minNumFiles</span></code>.</p>
<p>Auto compaction can be enabled at the table or session level using the following settings:</p>
<ul class="simple">
<li><p>Table property: <code class="docutils literal notranslate"><span class="pre">delta.autoOptimize.autoCompact</span></code></p></li>
<li><p>SparkSession setting: <code class="docutils literal notranslate"><span class="pre">spark.databricks.delta.autoCompact.enabled</span></code></p></li>
</ul>
<p>These settings accept the following options:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 13%" />
<col style="width: 87%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Options</p></th>
<th class="head"><p>Behavior</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">auto</span></code> (recommended)</p></td>
<td><p> Tunes target file size while respecting other autotuning functionality. Requires Databricks Runtime 10.1 or above.</p></td>
</tr>
<tr class="row-odd"><td><p> <code class="docutils literal notranslate"><span class="pre">legacy</span></code></p></td>
<td><p> Alias for <code class="docutils literal notranslate"><span class="pre">true</span></code>. Requires Databricks Runtime 10.1 or above.</p></td>
</tr>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p> Use 128 MB as the target file size. No dynamic sizing.</p></td>
</tr>
<tr class="row-odd"><td><p> <code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
<td><p> Turns off auto compaction. Can be set at the session level to override auto compaction for all Delta tables modified in the workload.</p></td>
</tr>
</tbody>
</table>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>In Databricks Runtime 10.3 and below, when other writers perform operations like <code class="docutils literal notranslate"><span class="pre">DELETE</span></code>, <code class="docutils literal notranslate"><span class="pre">MERGE</span></code>, <code class="docutils literal notranslate"><span class="pre">UPDATE</span></code>, or <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> concurrently, auto compaction can cause those other jobs to fail with a transaction conflict. This is not an issue in Databricks Runtime 10.4 and above.</p>
</div>
</div>
<div class="section" id="optimized-writes-for-delta-lake-on-databricks">
<span id="optimized-writes-for-delta-on-databricks"></span><span id="optimized-writes"></span><h2>Optimized writes for Delta Lake on Databricks<a class="headerlink" href="#optimized-writes-for-delta-lake-on-databricks" title="Permalink to this headline"> </a></h2>
<p>Optimized writes improve file size as data is written and benefit subsequent reads on the table.</p>
<p>Optimized writes are most effective for partitioned tables, as they reduce the number of small files written to each partition. Writing fewer large files is more efficient than writing many small files, but you might still see an increase in write latency because data is shuffled before being written.</p>
<p>The following image demonstrates how optimized writes works:</p>
<div class="figure align-default">
<img alt="Optimized writes" src="../_images/optimized-writes.png" />
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You might have code that runs <code class="docutils literal notranslate"><span class="pre">coalesce(n)</span></code> or <code class="docutils literal notranslate"><span class="pre">repartition(n)</span></code> just before you write out your data to control the number of files written. Optimized writes eliminates the need to use this pattern.</p>
</div>
<p>Optimized writes are enabled by default for the following operations in Databricks Runtime 9.1 LTS and above:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">MERGE</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">UPDATE</span></code> with subqueries</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">DELETE</span></code> with subqueries</p></li>
</ul>
<p>Optimized writes are also enabled for <code class="docutils literal notranslate"><span class="pre">CTAS</span></code> statements and <code class="docutils literal notranslate"><span class="pre">INSERT</span></code> operations when using SQL warehouses. In Databricks Runtime 13.1 and above, all Delta tables registered in Unity Catalog have optimized writes enabled for <code class="docutils literal notranslate"><span class="pre">CTAS</span></code> statements and <code class="docutils literal notranslate"><span class="pre">INSERT</span></code> operations for partitioned tables.</p>
<p>Optimized writes can be enabled at the table or session level using the following settings:</p>
<ul class="simple">
<li><p>Table setting: <code class="docutils literal notranslate"><span class="pre">delta.autoOptimize.optimizeWrite</span></code></p></li>
<li><p>SparkSession setting: <code class="docutils literal notranslate"><span class="pre">spark.databricks.delta.optimizeWrite.enabled</span></code></p></li>
</ul>
<p>These settings accept the following options:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 5%" />
<col style="width: 95%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Options</p></th>
<th class="head"><p>Behavior</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">true</span></code></p></td>
<td><p> Use 128 MB as the target file size.</p></td>
</tr>
<tr class="row-odd"><td><p> <code class="docutils literal notranslate"><span class="pre">false</span></code></p></td>
<td><p> Turns off optimized writes. Can be set at the session level to override auto compaction for all Delta tables modified in the workload.</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="set-a-target-file-size">
<span id="set-target-size"></span><h2>Set a target file size<a class="headerlink" href="#set-a-target-file-size" title="Permalink to this headline"> </a></h2>
<p>If you want to tune the size of files in your Delta table, set the <a class="reference internal" href="table-properties.html"><span class="doc">table property</span></a> <code class="docutils literal notranslate"><span class="pre">delta.targetFileSize</span></code> to the desired size. If this property is set, all data layout optimization operations will make a best-effort attempt to generate files of the specified size. Examples here include <a class="reference internal" href="optimize.html"><span class="doc">optimize</span></a> or <a class="reference internal" href="data-skipping.html"><span class="doc">Z-order</span></a>, <a class="reference internal" href="#auto-compact"><span class="std std-ref">auto compaction</span></a>, and <a class="reference internal" href="#optimized-writes"><span class="std std-ref">optimized writes</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When using Unity Catalog managed tables and SQL warehouses or Databricks Runtime 11.3 LTS and above, only <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> commands respect the <code class="docutils literal notranslate"><span class="pre">targetFileSize</span></code> setting.</p>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Table property</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>delta.targetFileSize</strong></p>
<p>Type: Size in bytes or higher units.</p>
<p>The target file size. For example, <code class="docutils literal notranslate"><span class="pre">104857600</span></code> (bytes) or <code class="docutils literal notranslate"><span class="pre">100mb</span></code>.</p>
<p>Default value: None</p>
</td>
</tr>
</tbody>
</table>
<p>For existing tables, you can set and unset properties using the SQL command <a class="reference internal" href="../sql/language-manual/sql-ref-syntax-ddl-alter-table.html"><span class="doc">ALTER TABLE SET TBL PROPERTIES</span></a>. You can also set these properties automatically when creating new tables using Spark session configurations. See <a class="reference internal" href="table-properties.html"><span class="doc">Delta table properties reference</span></a> for details.</p>
</div>
<div class="section" id="autotune-file-size-based-on-workload">
<span id="autotune-workload"></span><h2>Autotune file size based on workload<a class="headerlink" href="#autotune-file-size-based-on-workload" title="Permalink to this headline"> </a></h2>
<p>Databricks recommends setting the table property <code class="docutils literal notranslate"><span class="pre">delta.tuneFileSizesForRewrites</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code> for all tables that are targeted by many <code class="docutils literal notranslate"><span class="pre">MERGE</span></code> or DML operations, regardless of Databricks Runtime, Unity Catalog, or other optimizations. When set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, the target file size for the table is set to a much lower threshold, which accelerates write-intensive operations.</p>
<p>If not explicitly set, Databricks automatically detects if 9 out of last 10 previous operations on a Delta table were <code class="docutils literal notranslate"><span class="pre">MERGE</span></code> operations and sets this table property to <code class="docutils literal notranslate"><span class="pre">true</span></code>. You must explicitly set this property to <code class="docutils literal notranslate"><span class="pre">false</span></code> to avoid this behavior.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Table property</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong>delta.tuneFileSizesForRewrites</strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">Boolean</span></code></p>
<p>Whether to tune file sizes for data layout optimization.</p>
<p>Default value: None</p>
</td>
</tr>
</tbody>
</table>
<p>For existing tables, you can set and unset properties using the SQL command <a class="reference internal" href="../sql/language-manual/sql-ref-syntax-ddl-alter-table.html"><span class="doc">ALTER TABLE SET TBL PROPERTIES</span></a>. You can also set these properties automatically when creating new tables using Spark session configurations. See <a class="reference internal" href="table-properties.html"><span class="doc">Delta table properties reference</span></a> for details.</p>
</div>
<div class="section" id="autotune-file-size-based-on-table-size">
<span id="autotune-table"></span><h2>Autotune file size based on table size<a class="headerlink" href="#autotune-file-size-based-on-table-size" title="Permalink to this headline"> </a></h2>
<p>To minimize the need for manual tuning, Databricks automatically tunes the file size of Delta tables based on the size of the table. Databricks will use smaller file sizes for smaller tables and larger file sizes for larger tables so that the number of files in the table does not grow too large. Databricks does not autotune tables that you have tuned with a <a class="reference internal" href="#set-target-size"><span class="std std-ref">specific target size</span></a> or based on a workload with frequent rewrites.</p>
<p>The target file size is based on the current size of the Delta table. For tables smaller than 2.56 TB, the autotuned target file size is 256 MB. For tables with a size between 2.56 TB and 10 TB, the target size will grow linearly from 256 MB to 1 GB. For tables larger than 10 TB, the target file size is 1 GB.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When the target file size for a table grows, existing files are not re-optimized into larger files by the <code class="docutils literal notranslate"><span class="pre">OPTIMIZE</span></code> command. A large table can therefore always have some files that are smaller than the target size. If it is required to optimize those smaller files into larger files as well, you can configure a fixed target file size for the table using the <code class="docutils literal notranslate"><span class="pre">delta.targetFileSize</span></code> table property.</p>
</div>
<p>When a table is written incrementally, the target file sizes and file counts will be close to the following numbers, based on table size. The file counts in this table are only an example. The actual results will be different depending on many factors.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 18%" />
<col style="width: 26%" />
<col style="width: 56%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Table size</p></th>
<th class="head"><p>Target file size</p></th>
<th class="head"><p>Approximate number of files in table</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>10 GB</p></td>
<td><p>256 MB</p></td>
<td><p>40</p></td>
</tr>
<tr class="row-odd"><td><p>1 TB</p></td>
<td><p>256 MB</p></td>
<td><p>4096</p></td>
</tr>
<tr class="row-even"><td><p>2.56 TB</p></td>
<td><p>256 MB</p></td>
<td><p>10240</p></td>
</tr>
<tr class="row-odd"><td><p>3 TB</p></td>
<td><p>307 MB</p></td>
<td><p>12108</p></td>
</tr>
<tr class="row-even"><td><p>5 TB</p></td>
<td><p>512 MB</p></td>
<td><p>17339</p></td>
</tr>
<tr class="row-odd"><td><p>7 TB</p></td>
<td><p>716 MB</p></td>
<td><p>20784</p></td>
</tr>
<tr class="row-even"><td><p>10 TB</p></td>
<td><p>1 GB</p></td>
<td><p>24437</p></td>
</tr>
<tr class="row-odd"><td><p>20 TB</p></td>
<td><p>1 GB</p></td>
<td><p>34437</p></td>
</tr>
<tr class="row-even"><td><p>50 TB</p></td>
<td><p>1 GB</p></td>
<td><p>64437</p></td>
</tr>
<tr class="row-odd"><td><p>100 TB</p></td>
<td><p>1 GB</p></td>
<td><p>114437</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="limit-rows-written-in-a-data-file">
<h2>Limit rows written in a data file<a class="headerlink" href="#limit-rows-written-in-a-data-file" title="Permalink to this headline"> </a></h2>
<p>Occasionally, tables with narrow data might encounter an error where the number of rows in a given data file exceeds the support limits of the Parquet format. To avoid this error, you can use the SQL session configuration <code class="docutils literal notranslate"><span class="pre">spark.sql.files.maxRecordsPerFile</span></code> to specify the maximum number of records to write to a single file for a Delta Lake table. Specifying a value of zero or a negative value represents no limit.</p>
<p>In Databricks Runtime 10.5 and above, you can also use the DataFrameWriter option <code class="docutils literal notranslate"><span class="pre">maxRecordsPerFile</span></code> when using the DataFrame APIs to write to a Delta Lake table. When <code class="docutils literal notranslate"><span class="pre">maxRecordsPerFile</span></code> is specified, the value of the SQL session configuration <code class="docutils literal notranslate"><span class="pre">spark.sql.files.maxRecordsPerFile</span></code> is ignored.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Databricks does not recommend using this option unless it is necessary to avoid the aforementioned error. This setting might still be necessary for some Unity Catalog managed tables with very narrow data.</p>
</div>
</div>
<div class="section" id="upgrade-to-background-auto-compaction">
<span id="upgrade"></span><h2>Upgrade to background auto compaction<a class="headerlink" href="#upgrade-to-background-auto-compaction" title="Permalink to this headline"> </a></h2>
<p>Background auto compaction is available for Unity Catalog managed tables in Databricks Runtime 11.3 LTS and above. When migrating a legacy workload or table, do the following:</p>
<ul class="simple">
<li><p>Remove the Spark config <code class="docutils literal notranslate"><span class="pre">spark.databricks.delta.autoCompact.enabled</span></code> from cluster or notebook configuration settings.</p></li>
<li><p>For each table, run <code class="docutils literal notranslate"><span class="pre">ALTER</span> <span class="pre">TABLE</span> <span class="pre">&lt;table_name&gt;</span> <span class="pre">UNSET</span> <span class="pre">TBLPROPERTIES</span> <span class="pre">(delta.autoOptimize.autoCompact)</span></code> to remove any legacy auto compaction settings.</p></li>
</ul>
<p>After removing these legacy configurations, you should see background auto compaction triggered automatically for all Unity Catalog managed tables.</p>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>