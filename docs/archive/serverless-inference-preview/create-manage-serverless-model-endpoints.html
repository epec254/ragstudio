

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to create and manage your MLflow models as REST API endpoints with Databricks Serverless Real-Time Inference for model deployment and model serving." name="description" />
<meta content="noindex" name="robots" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Create and manage Serverless Real-Time Inference endpoints">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Create and manage Serverless Real-Time Inference endpoints &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html" class="notranslate">English</option>
    <option value="../../../ja/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html" class="notranslate">日本語</option>
    <option value="../../../pt/archive/serverless-inference-preview/create-manage-serverless-model-endpoints.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Create and manage Serverless Real-Time Inference endpoints</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="create-and-manage-serverless-real-time-inference-endpoints">
<h1>Create and manage Serverless Real-Time Inference endpoints<a class="headerlink" href="#create-and-manage-serverless-real-time-inference-endpoints" title="Permalink to this headline"> </a></h1>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>This documentation has been retired and might not be updated. The products, services, or technologies mentioned in this content are no longer supported.</p></li>
<li><p>The guidance in this article is for the preview version of the Model Serving functionality, formerly Serverless Real-Time Inference. Databricks recommends you migrate your model serving workflows to the generally available functionality. See <a class="reference internal" href="../../machine-learning/model-serving/index.html"><span class="doc">Model serving with Databricks</span></a>.</p></li>
</ul>
</div>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>This feature is in <a class="reference internal" href="../../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<p>This article describes how to create and manage endpoints that use Databricks <a class="reference internal" href="serverless-real-time-inference.html"><span class="doc">Serverless Real-Time Inference</span></a>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>API definitions and workflows are subject to change during the public preview.</p></li>
<li><p>If you’re relying on Anaconda, review the <a class="reference internal" href="#anaconda-notice"><span class="std std-ref">terms of service</span></a> notice for additional information.</p></li>
</ul>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Serverless Real-Time Inference is only available for Python-based MLflow models registered in the MLflow Model Registry. You must declare all model dependencies in the conda environment or requirements file.</p>
<ul>
<li><p>If you don’t have a registered model, see the <a class="reference internal" href="#example-notebooks"><span class="std std-ref">notebook examples</span></a> for pre-packaged models you can use to get up and running with Serverless Real-Time Inference endpoints.</p></li>
</ul>
</li>
<li><p>Your workspace must be enabled for Serverless Real-Time Inference. To enable model serving with Serverless Real-Time Inference, you must have <a class="reference internal" href="../../security/auth-authz/access-control/cluster-acl.html#cluster-create-permission"><span class="std std-ref">cluster creation permission</span></a>.</p></li>
<li><p>If you use custom libraries or libraries from a private mirror server with your model, see <a class="reference internal" href="../../machine-learning/model-serving/private-libraries-model-serving.html"><span class="doc">Use custom Python libraries with Model Serving</span></a> before you create the model endpoint.</p></li>
</ul>
</div>
<div class="section" id="create-a-model-serving-endpoint">
<h2>Create a model serving endpoint<a class="headerlink" href="#create-a-model-serving-endpoint" title="Permalink to this headline"> </a></h2>
<p>You can create Serverless Real-Time Inference endpoints for model serving with the Databricks Machine Learning API or the Databricks Machine Learning UI. An endpoint can serve any registered Python MLflow model registered in the Model Registry.</p>
<div class="section" id="use-the-api">
<h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>You can use the Enable Serving API to create an endpoint for model serving. In the following example, <code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code> is the name of the registered model.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>POST<span class="w"> </span>https://&lt;databricks-instance&gt;/api/2.0/preview/mlflow/endpoints-v2/enable

<span class="o">{</span>
<span class="w">   </span><span class="s2">&quot;registered_model_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="model-serving-ui"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>You enable a model for serving from its <a class="reference internal" href="../../mlflow/model-registry.html#registered-model-page"><span class="std std-ref">registered model page</span></a> in the Databricks Machine Learning UI.</p>
<ol class="arabic simple">
<li><p>Click the <strong>Serving</strong> tab. If the model is not already enabled for serving, the <strong>Enable Serverless Real-Time Inference</strong> button appears.</p></li>
<li><p>Click <strong>Enable Serverless Real-Time Inference</strong>. The Serving tab appears with <strong>Status</strong> shown as Pending. After a few minutes, <strong>Status</strong> changes to Ready.</p></li>
</ol>
</div>
</div>
<div class="section" id="modify-the-compute-configuration-of-an-endpoint">
<h2>Modify the compute configuration of an endpoint<a class="headerlink" href="#modify-the-compute-configuration-of-an-endpoint" title="Permalink to this headline"> </a></h2>
<p>After enabling a model endpoint, you can set the compute configuration as desired with the API or the UI. This configuration is particularly helpful if you need additional resources for your model. Workload size and compute configuration play a key role in what resources are allocated for serving your model. Learn more about <a class="reference internal" href="#workload-configuration"><span class="std std-ref">WorkloadConfigSpec objects</span></a>.</p>
<div class="section" id="use-the-api">
<span id="use-the-api-1"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>The status of the configuration update can be tracked in the <code class="docutils literal notranslate"><span class="pre">config_update_status</span></code> field of the <a class="reference internal" href="#endpoint-version-status"><span class="std std-ref">Endpoint Version status</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>PUT<span class="w"> </span>/preview/model-serving-api/endpoints-v2/update-compute-config
</pre></div>
</div>
<p>In the following, populate <code class="docutils literal notranslate"><span class="pre">desired_workload_config_spec</span></code> with <code class="docutils literal notranslate"><span class="pre">WorkloadConfigSpec</span></code> properties.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Staging|Production&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;desired_workload_config_spec&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;WorkloadConfigSpec&quot;</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-1"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>After you enable a model endpoint, you can set the desired compute configuration on the <strong>Compute Settings</strong> tab. You can set separate configurations for Staging and Production model versions.</p>
<p>You can choose from a few workload sizes, and autoscaling is automatically configured within the workload size. If you’d like your endpoint to scale down to zero, you can check the checkbox titled “Scale to zero”.</p>
</div>
</div>
<div class="section" id="scoring-a-model-endpoint">
<span id="score"></span><h2>Scoring a model endpoint<a class="headerlink" href="#scoring-a-model-endpoint" title="Permalink to this headline"> </a></h2>
<p>To score a deployed model, you can send a REST API request to the model URL or use the UI.</p>
<p>You should call a model by calling the API for its stage. For example, if version 1 is in the <strong>Production</strong> stage, it can be scored using this UR:</p>
<blockquote>
<div><p><code class="docutils literal notranslate"><span class="pre">https://&lt;databricks-instance&gt;/model-endpoint/iris-classifier/Production/invocations</span></code></p>
</div></blockquote>
<p>The list of available model URIs appears at the top of the <strong>Model Versions</strong> tab on the <strong>Serving</strong> tab.</p>
<div class="section" id="request-format">
<h3>Request format<a class="headerlink" href="#request-format" title="Permalink to this headline"> </a></h3>
<p>Requests should be sent by constructing a JSON with one of the below keys and a JSON object corresponding to the input format.</p>
<p>There are four formats for the input JSON depending on your use case:</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">dataframe_split</span></code> is JSON-serialized Pandas Dataframe in the <code class="docutils literal notranslate"><span class="pre">split</span></code> orientation.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;dataframe_split&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;columns&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;sepal length (cm)&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;sepal width (cm)&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;petal length (cm)&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;petal width (cm)&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;data&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mf">5.1</span><span class="p">,</span><span class="w"> </span><span class="mf">3.5</span><span class="p">,</span><span class="w"> </span><span class="mf">1.4</span><span class="p">,</span><span class="w"> </span><span class="mf">0.2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mf">4.9</span><span class="p">,</span><span class="w"> </span><span class="mf">3.0</span><span class="p">,</span><span class="w"> </span><span class="mf">1.4</span><span class="p">,</span><span class="w"> </span><span class="mf">0.2</span><span class="p">]]</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataframe_records</span></code> is JSON-serialized Pandas Dataframe in the <code class="docutils literal notranslate"><span class="pre">records</span></code> orientation.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This format does not guarantee the preservation of column ordering, and the <code class="docutils literal notranslate"><span class="pre">split</span></code> format is preferred over the <code class="docutils literal notranslate"><span class="pre">records</span></code> format.</p>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;dataframe_records&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;sepal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">5.1</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;sepal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3.5</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.4</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.2</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;sepal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">4.9</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;sepal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.4</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.2</span>
<span class="w">   </span><span class="p">},</span>
<span class="w">   </span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;sepal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">4.7</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;sepal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">3.2</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal length (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">1.3</span><span class="p">,</span>
<span class="w">     </span><span class="nt">&quot;petal width (cm)&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.2</span>
<span class="w">   </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">instances</span></code> is a tensors-based format that accepts tensors in row format. Use this format if all the input tensors have the same 0-th dimension. Conceptually, each tensor in the instances list could be joined with the other tensors of the same name in the rest of the list to construct the full input tensor for the model, which would only be possible if all of the tensors have the same 0-th dimension.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="p">{</span><span class="nt">&quot;instances&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w"> </span><span class="s2">&quot;a&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;b&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;c&quot;</span><span class="w"> </span><span class="p">]}</span>
</pre></div>
</div>
<p>or</p>
<p>In the following example, there are three dimensions, so you have exactly three of each input tensor.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w"> </span><span class="nt">&quot;instances&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;t1&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;a&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;t2&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">],</span>
<span class="w">   </span><span class="nt">&quot;t3&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]]</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;t1&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;b&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;t2&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">],</span>
<span class="w">   </span><span class="nt">&quot;t3&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="p">]]</span>
<span class="w">  </span><span class="p">}</span>
<span class="w"> </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">inputs</span></code> send queries with tensors in columnar format. This request is different because there are actually a different number of tensor instances of <code class="docutils literal notranslate"><span class="pre">t2</span></code> (3) than <code class="docutils literal notranslate"><span class="pre">t1</span></code> and <code class="docutils literal notranslate"><span class="pre">t3</span></code>, so it is not possible to represent this input in the <code class="docutils literal notranslate"><span class="pre">instances</span></code> format.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w"> </span><span class="nt">&quot;inputs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;t1&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;a&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;b&quot;</span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;t2&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">,</span><span class="w"> </span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">,</span><span class="w"> </span><span class="mi">5</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">6</span><span class="p">,</span><span class="w"> </span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">,</span><span class="w"> </span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="p">,</span><span class="w"> </span><span class="mi">13</span><span class="p">,</span><span class="w"> </span><span class="mi">14</span><span class="p">,</span><span class="w"> </span><span class="mi">15</span><span class="p">]],</span>
<span class="w">  </span><span class="nt">&quot;t3&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[[[</span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">2</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">3</span><span class="p">,</span><span class="w"> </span><span class="mi">4</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">5</span><span class="p">,</span><span class="w"> </span><span class="mi">6</span><span class="p">]],</span><span class="w"> </span><span class="p">[[</span><span class="mi">7</span><span class="p">,</span><span class="w"> </span><span class="mi">8</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">9</span><span class="p">,</span><span class="w"> </span><span class="mi">10</span><span class="p">],</span><span class="w"> </span><span class="p">[</span><span class="mi">11</span><span class="p">,</span><span class="w"> </span><span class="mi">12</span><span class="p">]]]</span>
<span class="w"> </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="response-format">
<h3>Response Format<a class="headerlink" href="#response-format" title="Permalink to this headline"> </a></h3>
<p>The response from the endpoint is in the following format. The output from your model is wrapped in a “predictions” key.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;predictions&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;&lt;JSON output from model&gt;&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-2"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>Sending requests using the UI is the easiest and fastest way to test the model. You can insert the model input data in JSON format and click <strong>Send Request</strong>. If the model has been logged with an input example (as shown in the graphic above), click <strong>Show Example</strong> to load the input example.</p>
</div>
<div class="section" id="use-the-api">
<span id="use-the-api-2"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>You can send a scoring request through the REST API using <a class="reference external" href="https://docs.databricks.com/api/workspace/tokenmanagement">standard Databricks authentication</a>. The following examples demonstrate authentication using a personal access token.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>As a security best practice when you authenticate with automated tools, systems, scripts, and apps, Databricks recommends that you use OAuth tokens.</p>
<p>If you use personal access token authentication, Databricks recommends using personal access tokens belonging to <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html"><span class="doc">service principals</span></a> instead of workspace users. To create tokens for service principals, see <a class="reference internal" href="../../administration-guide/users-groups/service-principals.html#personal-access-tokens"><span class="std std-ref">Manage tokens for a service principal</span></a>.</p>
</div>
<p>Given a <code class="docutils literal notranslate"><span class="pre">MODEL_VERSION_URI</span></code> like <code class="docutils literal notranslate"><span class="pre">https://&lt;databricks-instance&gt;/model/iris-classifier/Production/invocations</span></code>, where <code class="docutils literal notranslate"><span class="pre">&lt;databricks-instance&gt;</span></code> is the <a class="reference internal" href="../../workspace/workspace-details.html#workspace-instance-names-urls-and-ids"><span class="std std-ref">name of your Databricks instance</span></a>, and a Databricks REST API token called <code class="docutils literal notranslate"><span class="pre">DATABRICKS_API_TOKEN</span></code>, the following are example snippets of how to score a served model.</p>
<div class="js-code-language-tabs compound">
<div class="compound-first compound" lang="bash">
<p class="compound-first">Score a model accepting dataframe records input format.</p>
<div class="compound-middle highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_API_TOKEN</span><span class="w"> </span><span class="nv">$MODEL_VERSION_URI</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-H<span class="w"> </span><span class="s1">&#39;Content-Type: application/json&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">  </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;dataframe_records&quot;: [</span>
<span class="s1">    {</span>
<span class="s1">      &quot;sepal_length&quot;: 5.1,</span>
<span class="s1">      &quot;sepal_width&quot;: 3.5,</span>
<span class="s1">      &quot;petal_length&quot;: 1.4,</span>
<span class="s1">      &quot;petal_width&quot;: 0.2</span>
<span class="s1">    }</span>
<span class="s1">  ]}&#39;</span>
</pre></div>
</div>
<p class="compound-middle">Score a model accepting tensor inputs. Tensor inputs should be formatted as described in <a class="reference external" href="https://www.tensorflow.org/tfx/serving/api_rest#request_format_2">TensorFlow Serving’s API docs</a>.</p>
<div class="compound-last highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span>-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_API_TOKEN</span><span class="w"> </span><span class="nv">$MODEL_VERSION_URI</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-H<span class="w"> </span><span class="s1">&#39;Content-Type: application/json&#39;</span><span class="w"> </span><span class="se">\</span>
<span class="w">   </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;inputs&quot;: [[5.1, 3.5, 1.4, 0.2]]}&#39;</span>
</pre></div>
</div>
</div>
<div class="compound-middle compound" lang="python">
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="k">def</span> <span class="nf">create_tf_serving_json</span><span class="p">(</span><span class="n">data</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">{</span><span class="s1">&#39;inputs&#39;</span><span class="p">:</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">data</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">data</span><span class="o">.</span><span class="n">keys</span><span class="p">()}</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="nb">dict</span><span class="p">)</span> <span class="k">else</span> <span class="n">data</span><span class="o">.</span><span class="n">tolist</span><span class="p">()}</span>

<span class="k">def</span> <span class="nf">score_model</span><span class="p">(</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">databricks_token</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
  <span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;Authorization&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Bearer </span><span class="si">{</span><span class="n">databricks_token</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
    <span class="s2">&quot;Content-Type&quot;</span><span class="p">:</span> <span class="s2">&quot;application/json&quot;</span><span class="p">,</span>
  <span class="p">}</span>
  <span class="n">data_json</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">({</span><span class="s1">&#39;dataframe_records&#39;</span><span class="p">:</span> <span class="n">data</span><span class="o">.</span><span class="n">to_dict</span><span class="p">(</span><span class="n">orient</span><span class="o">=</span><span class="s1">&#39;records&#39;</span><span class="p">)})</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">)</span> <span class="k">else</span> <span class="n">create_tf_serving_json</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>
  <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;POST&#39;</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">url</span><span class="o">=</span><span class="n">model_uri</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data_json</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">response</span><span class="o">.</span><span class="n">status_code</span> <span class="o">!=</span> <span class="mi">200</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">Exception</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Request failed with status </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">status_code</span><span class="si">}</span><span class="s2">, </span><span class="si">{</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()</span>


<span class="c1"># Scoring a model that accepts pandas DataFrames</span>
<span class="n">data</span> <span class="o">=</span>  <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">([{</span>
  <span class="s2">&quot;sepal_length&quot;</span><span class="p">:</span> <span class="mf">5.1</span><span class="p">,</span>
  <span class="s2">&quot;sepal_width&quot;</span><span class="p">:</span> <span class="mf">3.5</span><span class="p">,</span>
  <span class="s2">&quot;petal_length&quot;</span><span class="p">:</span> <span class="mf">1.4</span><span class="p">,</span>
  <span class="s2">&quot;petal_width&quot;</span><span class="p">:</span> <span class="mf">0.2</span>
<span class="p">}])</span>
<span class="n">score_model</span><span class="p">(</span><span class="n">MODEL_VERSION_URI</span><span class="p">,</span> <span class="n">DATABRICKS_API_TOKEN</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>

<span class="c1"># Scoring a model that accepts tensors</span>
<span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">([[</span><span class="mf">5.1</span><span class="p">,</span> <span class="mf">3.5</span><span class="p">,</span> <span class="mf">1.4</span><span class="p">,</span> <span class="mf">0.2</span><span class="p">]])</span>
<span class="n">score_model</span><span class="p">(</span><span class="n">MODEL_VERSION_URI</span><span class="p">,</span> <span class="n">DATABRICKS_API_TOKEN</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="compound-last compound" lang="PowerBI">
<p class="compound-first">You can score a dataset in Power BI Desktop using the following steps:</p>
<ol class="compound-last arabic">
<li><p>Open dataset you want to score.</p></li>
<li><p>Go to Transform Data.</p></li>
<li><p>Right-click in the left panel and select <strong>Create New Query</strong>.</p></li>
<li><p>Go to <strong>View &gt; Advanced Editor</strong>.</p></li>
<li><p>Replace the query body with the code snippet below, after filling in an appropriate <code class="docutils literal notranslate"><span class="pre">DATABRICKS_API_TOKEN</span></code> and <code class="docutils literal notranslate"><span class="pre">MODEL_VERSION_URI</span></code>.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">dataset</span> <span class="k">as</span> <span class="n">table</span> <span class="p">)</span> <span class="k">as</span> <span class="n">table</span> <span class="o">=&gt;</span>
<span class="n">let</span>
  <span class="n">call_predict</span> <span class="o">=</span> <span class="p">(</span><span class="n">dataset</span> <span class="k">as</span> <span class="n">table</span> <span class="p">)</span> <span class="k">as</span> <span class="nb">list</span> <span class="o">=&gt;</span>
  <span class="n">let</span>
    <span class="n">apiToken</span> <span class="o">=</span> <span class="n">DATABRICKS_API_TOKEN</span><span class="p">,</span>
    <span class="n">modelUri</span> <span class="o">=</span> <span class="n">MODEL_VERSION_URI</span><span class="p">,</span>
    <span class="n">responseList</span> <span class="o">=</span> <span class="n">Json</span><span class="o">.</span><span class="n">Document</span><span class="p">(</span><span class="n">Web</span><span class="o">.</span><span class="n">Contents</span><span class="p">(</span><span class="n">modelUri</span><span class="p">,</span>
      <span class="p">[</span>
        <span class="n">Headers</span> <span class="o">=</span> <span class="p">[</span>
          <span class="c1">#&quot;Content-Type&quot; = &quot;application/json&quot;,</span>
          <span class="c1">#&quot;Authorization&quot; = Text.Format(&quot;Bearer #{0}&quot;, {apiToken})</span>
        <span class="p">],</span>
        <span class="n">Content</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;dataframe_records&quot;</span><span class="p">:</span> <span class="n">Json</span><span class="o">.</span><span class="n">FromValue</span><span class="p">(</span><span class="n">dataset</span><span class="p">)}</span>
      <span class="p">]</span>
    <span class="p">))</span>
  <span class="ow">in</span>
    <span class="n">responseList</span><span class="p">,</span>
  <span class="n">predictionList</span> <span class="o">=</span> <span class="n">List</span><span class="o">.</span><span class="n">Combine</span><span class="p">(</span><span class="n">List</span><span class="o">.</span><span class="n">Transform</span><span class="p">(</span><span class="n">Table</span><span class="o">.</span><span class="n">Split</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="mi">256</span><span class="p">),</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="n">call_predict</span><span class="p">(</span><span class="n">x</span><span class="p">))),</span>
  <span class="n">predictionsTable</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">FromList</span><span class="p">(</span><span class="n">predictionList</span><span class="p">,</span> <span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">=&gt;</span> <span class="p">{</span><span class="n">x</span><span class="p">},</span> <span class="p">{</span><span class="s2">&quot;Prediction&quot;</span><span class="p">}),</span>
  <span class="n">datasetWithPrediction</span> <span class="o">=</span> <span class="n">Table</span><span class="o">.</span><span class="n">Join</span><span class="p">(</span>
    <span class="n">Table</span><span class="o">.</span><span class="n">AddIndexColumn</span><span class="p">(</span><span class="n">predictionsTable</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">),</span> <span class="s2">&quot;index&quot;</span><span class="p">,</span>
    <span class="n">Table</span><span class="o">.</span><span class="n">AddIndexColumn</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="s2">&quot;index&quot;</span><span class="p">),</span> <span class="s2">&quot;index&quot;</span><span class="p">)</span>
<span class="ow">in</span>
  <span class="n">datasetWithPrediction</span>
</pre></div>
</div>
</li>
<li><p>Name the query with your desired model name.</p></li>
<li><p>Open the advanced query editor for your dataset and apply the model function.</p></li>
</ol>
</div>
</div>
<p>See the following notebook for an example of how to test your Serverless Real-Time Inference endpoint with a Python model:</p>
<div class="embedded-notebook-section section" id="test-serverless-real-time-inference-endpoint-notebook">
<span id="test-serverless-endpoint-example"></span><h4>Test Serverless Real-Time Inference endpoint notebook<a class="headerlink" href="#test-serverless-real-time-inference-endpoint-notebook" title="Permalink to this headline"> </a></h4>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/test-serverless-endpoint-example.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/test-serverless-endpoint-example.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/test-serverless-endpoint-example.html"            id="491f95fe54eea0a8d46f96ef7f1cae79de610da29becd3318d6b06757aaf7cbc" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
</div>
<div class="section" id="update-the-model-version-served-by-a-model-endpoint">
<h2>Update the model version served by a model endpoint<a class="headerlink" href="#update-the-model-version-served-by-a-model-endpoint" title="Permalink to this headline"> </a></h2>
<p>A model version must either be in Staging or Production in the Model Registry before it can be served to the endpoint.</p>
<div class="section" id="use-the-api">
<span id="use-the-api-3"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>To transition a new model version into Serving, you can use the Model Registry to transition the model version you want to serve into its appropriate stage.</p>
<p>The following code example transitions version 2 of the model <code class="docutils literal notranslate"><span class="pre">ElasticNet</span></code> into Staging. By setting <code class="docutils literal notranslate"><span class="pre">archive_existing_versions</span></code> to <code class="docutils literal notranslate"><span class="pre">true</span></code>, any existing model versions are archived, which causes the Staging URL to point to the new model version after it’s ready for serving. Before the new version is ready, the Staging endpoint serves the old model version, so the transition is made with zero downtime.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>POST<span class="w"> </span>/mlflow/databricks/model-versions/transition-stage

<span class="o">{</span>
<span class="w">   </span><span class="s2">&quot;name&quot;</span>:<span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>,
<span class="w">   </span><span class="s2">&quot;version&quot;</span>:<span class="w"> </span><span class="s2">&quot;2&quot;</span>,
<span class="w">   </span><span class="s2">&quot;stage&quot;</span>:<span class="w"> </span><span class="s2">&quot;Staging&quot;</span>,
<span class="w">   </span><span class="s2">&quot;archive_existing_versions&quot;</span>:<span class="w"> </span>true,
<span class="w">   </span><span class="s2">&quot;comment&quot;</span>:<span class="w"> </span><span class="s2">&quot;Deploying version 1 to Staging endpoint!&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
<div class="section" id="keep-multiple-versions-in-a-single-stage">
<h4>Keep multiple versions in a single stage<a class="headerlink" href="#keep-multiple-versions-in-a-single-stage" title="Permalink to this headline"> </a></h4>
<p>You can also choose to keep the previous Staging version in Staging. Multiple versions of a model can be in the same stage. In this scenario, both versions are served, but the Staging URL points only to the <strong>newest</strong> version. The older version is still accessible by its version URL.</p>
<p>If you want to try out a new version behind your staging endpoint, you can do the same as above, but set <code class="docutils literal notranslate"><span class="pre">archive_existing_versions</span></code> to <code class="docutils literal notranslate"><span class="pre">false</span></code> to ensure the previous Staging version doesn’t get archived.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>POST<span class="w"> </span>/mlflow/databricks/model-versions/transition-stage

<span class="o">{</span>
...
<span class="w">   </span><span class="s2">&quot;archive_existing_versions&quot;</span>:<span class="w"> </span>false,
...
<span class="o">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-3"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>To transition model versions to Staging or Production using the Databricks Machine Learning UI:</p>
<ol class="arabic simple">
<li><p>Select <img alt="models icon" src="../../_images/models-icon.png" /> <strong>Models</strong> in the sidebar.</p></li>
<li><p>Identify and select the registered model you want to update.</p></li>
<li><p>Select the model version you want to transition to <strong>Staging</strong> or <strong>Production</strong>. The link opens that model version’s detail page.</p></li>
<li><p>Use the <strong>Stage</strong> dropdown menu at the top right to transition the model version to Staging or Production.</p></li>
</ol>
</div>
</div>
<div class="section" id="get-the-status-of-the-model-endpoint">
<h2>Get the status of the model endpoint<a class="headerlink" href="#get-the-status-of-the-model-endpoint" title="Permalink to this headline"> </a></h2>
<div class="section" id="use-the-api">
<span id="use-the-api-4"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>Databricks provides the following to check the status of an endpoint. Learn more about <a class="reference internal" href="#endpoint-status"><span class="std std-ref">EndpointStatus objects</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>GET<span class="w"> </span>/preview/mlflow/endpoints-v2/get-status
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This returns the <code class="docutils literal notranslate"><span class="pre">EndpointStatus</span></code> object properties:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;endpoint_status&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;EndpointStatus&quot;</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-4"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>In the UI, you can check the status of an endpoint from the <strong>Status</strong> indicator at the top of the <strong>Serving</strong> tab.</p>
</div>
</div>
<div class="section" id="get-the-status-of-model-endpoint-versions">
<h2>Get the status of model endpoint versions<a class="headerlink" href="#get-the-status-of-model-endpoint-versions" title="Permalink to this headline"> </a></h2>
<p>You can get the status of a particular endpoint version that has been deployed. This lets you:</p>
<ul class="simple">
<li><p>Track which versions are being served.</p></li>
<li><p>Track the status of those versions.</p></li>
<li><p>Verify whether a particular model version is ready for use.</p></li>
</ul>
<div class="section" id="use-the-api">
<span id="use-the-api-5"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>Databricks provide two APIs to check the status of endpoint versions. To check the status for all endpoint versions for a particular registered model, you can use <code class="docutils literal notranslate"><span class="pre">ListVersions</span></code>. Learn more about <a class="reference internal" href="#endpoint-version-status"><span class="std std-ref">EndpointVersionStatus objects</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>GET<span class="w"> </span>/preview/mlflow/endpoints-v2/list-versions
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This returns <code class="docutils literal notranslate"><span class="pre">EndpointVersionStatus</span></code> object properties:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;endpoint_statuses&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;EndpointVersionStatus&quot;</span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>Alternatively, if you already know the specific version whose status you want to know, you can use <code class="docutils literal notranslate"><span class="pre">GetVersions</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>GET<span class="w"> </span>/preview/mlflow/endpoints-v2/get-version-status
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;endpoint_version_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This returns <code class="docutils literal notranslate"><span class="pre">EndpointVersionStatus</span></code> object properties:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;endpoint_status&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;EndpointVersionStatus&quot;</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<div class="section" id="getting-the-status-for-a-stage">
<h4>Getting the status for a stage<a class="headerlink" href="#getting-the-status-for-a-stage" title="Permalink to this headline"> </a></h4>
<p>You can also get the status for a particular stage. To do so, you first need to determine which endpoint version is currently serving the <strong>Stage</strong>. To retrieve that information, you can use <code class="docutils literal notranslate"><span class="pre">ListVersionAliases</span></code>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>GET<span class="w"> </span>/preview/mlflow/endpoints-v2/list-version-aliases
</pre></div>
</div>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>
<span class="p">}</span>
</pre></div>
</div>
<p>This returns:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;aliases&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">   </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;alias&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Staging&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;endpoint_version_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;2&quot;</span>
<span class="w">   </span><span class="p">},</span>
<span class="w">   </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;alias&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Production&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;endpoint_version_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span>
<span class="w">   </span><span class="p">}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>From there, you can use the above to get the status of the particular endpoint version.</p>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-5"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>In the <strong>Serving</strong> tab of the UI, you can see each endpoint version with its own tab on the left. When you select each tab, detailed information about a particular version appears. The version that is currently serving a stage can be seen from the <strong>Staging</strong> or <strong>Production</strong> label on the endpoint version.</p>
</div>
</div>
<div class="section" id="disable-model-serving">
<h2>Disable model serving<a class="headerlink" href="#disable-model-serving" title="Permalink to this headline"> </a></h2>
<div class="section" id="use-the-api">
<span id="use-the-api-6"></span><h3>Use the API<a class="headerlink" href="#use-the-api" title="Permalink to this headline"> </a></h3>
<p>You can use the API to disable model serving for any registered model present in the Model Registry.</p>
<p>To disable model serving for a model use the Disable Serving API:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>POST<span class="w"> </span>/preview/mlflow/endpoints-v2/disable

<span class="o">{</span>
<span class="w">   </span><span class="s2">&quot;registered_model_name&quot;</span>:<span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span>
<span class="o">}</span>
</pre></div>
</div>
</div>
<div class="section" id="use-the-ui">
<span id="use-the-ui-6"></span><h3>Use the UI<a class="headerlink" href="#use-the-ui" title="Permalink to this headline"> </a></h3>
<p>You can disable a model for serving from its <a class="reference internal" href="../../mlflow/model-registry.html#registered-model-page"><span class="std std-ref">registered model page</span></a>.</p>
<ol class="arabic simple">
<li><p>Click the <strong>Serving</strong> tab. If the model is not already enabled for serving, the <strong>Enable Serverless Real-Time Inference</strong> button appears.</p></li>
<li><p>Click <strong>Disable Serving</strong>.</p></li>
</ol>
</div>
</div>
<div class="section" id="debug-your-model-endpoint">
<h2>Debug your model endpoint<a class="headerlink" href="#debug-your-model-endpoint" title="Permalink to this headline"> </a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can only debug your model endpoint through the UI.</p>
</div>
<p>You can debug and troubleshoot your endpoint by viewing the model logs on the endpoint version’s tab in the Databricks Machine Learning UI. Logs for all replicas of the model are merged in the <strong>All Replicas</strong> tab.</p>
<p>In addition to the model’s logs, you can view significant serving events pertaining to the model in the <strong>Model Events</strong> tab.</p>
</div>
<div class="section" id="core-api-objects">
<h2>Core API objects<a class="headerlink" href="#core-api-objects" title="Permalink to this headline"> </a></h2>
<p>This section contains design patterns and syntax for Serverless Real-Time Inference’s core API objects.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>API definitions are subject to change during the public preview.</p>
</div>
<div class="section" id="workload-configuration">
<h3>Workload configuration<a class="headerlink" href="#workload-configuration" title="Permalink to this headline"> </a></h3>
<p><code class="docutils literal notranslate"><span class="pre">WorkloadConfigSpec</span></code> describes the configuration used to scale the compute for a particular stage.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="nt">&quot;WorkloadConfigSpec&quot;</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;workload_size_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Small|Medium|Large&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;scale_to_zero_enabled&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">false</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">ComputeConfig</span></code> represents the configuration used to scale the compute for a particular stage along with accompanying metadata.</p>
<p>In the following, populate <code class="docutils literal notranslate"><span class="pre">workload_spec</span></code> by replacing <code class="docutils literal notranslate"><span class="pre">&quot;WorkloadConfigSpec&quot;</span></code> with the previously defined properties of your <code class="docutils literal notranslate"><span class="pre">WorkloadConfigSpec</span></code> object.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="nt">&quot;ComputeConfig&quot;</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;stage&quot;</span><span class="p">:</span><span class="w">  </span><span class="s2">&quot;Staging|Production&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;creation_timestamp&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">12345678</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;user_id&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;first.last@databricks.com&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;workload_spec&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;WorkloadConfigSpec&quot;</span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="endpoint-status">
<h3>Endpoint status<a class="headerlink" href="#endpoint-status" title="Permalink to this headline"> </a></h3>
<p>The health of an endpoint reflects whether any of the stages can be scored or have resources generated for particular versions for the model.</p>
<p>In the following <code class="docutils literal notranslate"><span class="pre">EndpointStatus</span></code> object, populate <code class="docutils literal notranslate"><span class="pre">compute_config</span></code> by reusing the previously defined properties of your <code class="docutils literal notranslate"><span class="pre">ComputeConfig</span></code> object and any other properties as an array.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="nt">&quot;EndpointStatus&quot;</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;state&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;PENDING|READY|FAILED&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;state_message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;State message&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;compute_config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;ComputeConfig and additional properties as an array&quot;</span><span class="p">]</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
</div>
<div class="section" id="endpoint-version-status">
<h3>Endpoint version status<a class="headerlink" href="#endpoint-version-status" title="Permalink to this headline"> </a></h3>
<p>An endpoint version has a particular URI that can be queried. The URI represents a single model version which is being served and whose compute is configured by the compute configurations set for its stage.</p>
<p>In the following <code class="docutils literal notranslate"><span class="pre">EndpointVersionStatus</span></code> object, populate both <code class="docutils literal notranslate"><span class="pre">config</span></code> fields –<code class="docutils literal notranslate"><span class="pre">service_status</span></code> and <code class="docutils literal notranslate"><span class="pre">config_update_status</span></code>–  by replacing <code class="docutils literal notranslate"><span class="pre">&quot;ComputeConfig&quot;</span></code> with the previously defined properties of your <code class="docutils literal notranslate"><span class="pre">ComputeConfig</span></code> object.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="w">  </span><span class="nt">&quot;EndpointVersionStatus&quot;</span><span class="p">:</span>
<span class="w">  </span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;registered_model_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;ElasticNet&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;endpoint_version_name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;1&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;service_status&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;state&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SERVICE_STATE_UNKNOWN|SERVICE_STATE_PENDING|SERVICE_STATE_READY|SERVICE_STATE_UNKNOWN&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Ready&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;ComputeConfig&quot;</span><span class="p">}</span>
<span class="w">   </span><span class="p">},</span>
<span class="w">   </span><span class="nt">&quot;config_update_status&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">      </span><span class="nt">&quot;state&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;SERVICE_STATE_UNKNOWN|SERVICE_STATE_PENDING|SERVICE_STATE_READY|SERVICE_STATE_UNKNOWN&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;message&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Pending&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;config&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="s2">&quot;ComputeConfig&quot;</span><span class="p">}</span>
<span class="w">    </span><span class="p">}</span>
<span class="w">  </span><span class="p">}</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="notebook-examples">
<span id="example-notebooks"></span><h2>Notebook examples<a class="headerlink" href="#notebook-examples" title="Permalink to this headline"> </a></h2>
<p>The following notebooks include different models that you can use to get up and running with Serverless Real-Time Inference endpoints. The model examples can be imported into the workspace by following the directions in <a class="reference internal" href="../../notebooks/notebook-export-import.html#import-notebook"><span class="std std-ref">Import a notebook</span></a>. After you choose and create a model from one of the examples, <a class="reference internal" href="../../machine-learning/manage-model-lifecycle/workspace-model-registry.html#register-existing-model"><span class="std std-ref">register it in the MLflow Model Registry</span></a>, and then follow the <a class="reference internal" href="#model-serving-ui"><span class="std std-ref">UI workflow</span></a> steps for model serving.</p>
<div class="embedded-notebook-section section" id="train-and-register-a-scikit-learn-model-for-model-serving-notebook">
<span id="train-register-scikit-model-serving"></span><h3>Train and register a scikit-learn model for model serving notebook<a class="headerlink" href="#train-and-register-a-scikit-learn-model-for-model-serving-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/train-register-scikit-model-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/train-register-scikit-model-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/train-register-scikit-model-serving.html"            id="e198a21f40dd3e25d8bf5f67524af46d97123c7b010f901a89ad3b60b5f2984e" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
<div class="embedded-notebook-section section" id="train-and-register-a-pytorch-model-for-model-serving-notebook">
<span id="train-register-pytorch-model-serving"></span><h3>Train and register a Pytorch model for model serving notebook<a class="headerlink" href="#train-and-register-a-pytorch-model-for-model-serving-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/train-register-pytorch-model-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/train-register-pytorch-model-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/train-register-pytorch-model-serving.html"            id="1759e1c8862922259dec7fd7e26c42dda18ae8ae9c67a5423f27704ec7406730" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
<div class="embedded-notebook-section section" id="train-and-register-a-huggingface-model-for-model-serving-notebook">
<span id="train-register-hugging-face-model-serving"></span><h3>Train and register a HuggingFace model for model serving notebook<a class="headerlink" href="#train-and-register-a-huggingface-model-for-model-serving-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/train-register-hugging-face-model-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/train-register-hugging-face-model-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/train-register-hugging-face-model-serving.html"            id="d02a972474941f1946bb807d086f22398b6aaf7a6a48bfbdeff98872830bebae" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
<div class="embedded-notebook-section section" id="host-multiple-models-in-an-endpoint-notebook">
<span id="package-multiple-models-model-serving"></span><h3>Host multiple models in an endpoint notebook<a class="headerlink" href="#host-multiple-models-in-an-endpoint-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/package-multiple-models-model-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/package-multiple-models-model-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/package-multiple-models-model-serving.html"            id="dd223611797199a9c9edc5f8ff7b1525b1644e61f7d6c15f2cd45c5cb7333c1b" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
<div class="section" id="anaconda-licensing-update">
<span id="anaconda-notice"></span><h2>Anaconda licensing update<a class="headerlink" href="#anaconda-licensing-update" title="Permalink to this headline"> </a></h2>
<p>The following notice is for customers relying on Anaconda.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Anaconda Inc. updated their <a class="reference external" href="https://www.anaconda.com/terms-of-service">terms of service</a> for anaconda.org channels. Based on the new terms of service you may require a commercial license if you rely on Anaconda’s packaging and distribution. See <a class="reference external" href="https://www.anaconda.com/blog/anaconda-commercial-edition-faq">Anaconda Commercial Edition FAQ</a> for more information. Your use of any Anaconda channels is governed by their terms of service.</p>
<p>MLflow models logged before <a class="reference external" href="https://mlflow.org/news/2021/06/18/1.18.0-release/index.html">v1.18</a> (Databricks Runtime 8.3 ML or earlier) were by default logged with the conda <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel (<a class="reference external" href="https://repo.anaconda.com/pkgs/">https://repo.anaconda.com/pkgs/</a>) as a dependency. Because of this license change, Databricks has stopped the use of the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel for models logged using MLflow v1.18 and above. The default channel logged is now <code class="docutils literal notranslate"><span class="pre">conda-forge</span></code>, which points at the community managed <a class="reference external" href="https://conda-forge.org/">https://conda-forge.org/</a>.</p>
<p>If you logged a model before MLflow v1.18 without excluding the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel from the conda environment for the model, that model may have a dependency on the <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel that you may not have intended.
To manually confirm whether a model has this dependency, you can examine <code class="docutils literal notranslate"><span class="pre">channel</span></code> value in the <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> file that is packaged with the logged model. For example, a model’s <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> with a <code class="docutils literal notranslate"><span class="pre">defaults</span></code> channel dependency may look like this:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">channels</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">defaults</span>
<span class="nt">dependencies</span><span class="p">:</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">python=3.8.8</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">pip</span>
<span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">pip</span><span class="p">:</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">scikit-learn==0.23.2</span>
<span class="w">    </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">cloudpickle==1.6.0</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">name</span><span class="p p-Indicator">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">mlflow-env</span>
</pre></div>
</div>
<p>Because Databricks can not determine whether your use of the Anaconda repository to interact with your models is permitted under your relationship with Anaconda, Databricks is not forcing its customers to make any changes. If your use of the Anaconda.com repo through the use of Databricks is permitted under Anaconda’s terms, you do not need to take any action.</p>
<p>If you would like to change the channel used in a model’s environment, you can re-register the model to the model registry with a new <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code>. You can do this by specifying the channel in the <code class="docutils literal notranslate"><span class="pre">conda_env</span></code> parameter of <code class="docutils literal notranslate"><span class="pre">log_model()</span></code>.</p>
<p>For more information on the <code class="docutils literal notranslate"><span class="pre">log_model()</span></code> API, see the MLflow documentation for the model flavor you are working with, for example, <a class="reference external" href="https://www.mlflow.org/docs/latest/python_api/mlflow.sklearn.html#mlflow.sklearn.log_model">log_model for scikit-learn</a>.</p>
<p>For more information on <code class="docutils literal notranslate"><span class="pre">conda.yaml</span></code> files, see the <a class="reference external" href="https://www.mlflow.org/docs/latest/models.html#additional-logged-files">MLflow documentation</a>.</p>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>