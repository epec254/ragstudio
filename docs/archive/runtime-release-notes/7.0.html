

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="false" name="lint" />
<meta content="Release notes about Databricks Runtime 7.0, powered by Apache Spark." name="description" />
<meta content="noindex" name="robots" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Databricks Runtime 7.0 (unsupported)">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Databricks Runtime 7.0 (unsupported) &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/archive/runtime-release-notes/7.0.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/archive/runtime-release-notes/7.0.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/archive/runtime-release-notes/7.0.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/archive/runtime-release-notes/7.0.html" class="notranslate">English</option>
    <option value="../../../ja/archive/runtime-release-notes/7.0.html" class="notranslate">日本語</option>
    <option value="../../../pt/archive/runtime-release-notes/7.0.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Databricks Runtime 7.0 (unsupported)</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="databricks-runtime-70-unsupported">
<span id="dbr-70-unsupported"></span><h1>Databricks Runtime 7.0 (unsupported)<a class="headerlink" href="#databricks-runtime-70-unsupported" title="Permalink to this headline"> </a></h1>
<p>Databricks released this image in June 2020.</p>
<p>The following release notes provide information about Databricks Runtime 7.0, powered by Apache Spark 3.0.</p>
<div class="section" id="new-features">
<h2>New features<a class="headerlink" href="#new-features" title="Permalink to this headline"> </a></h2>
<p>Databricks Runtime 7.0 includes the following new features:</p>
<ul>
<li><p><strong>Scala 2.12</strong></p>
<p>Databricks Runtime 7.0 upgrades Scala from 2.11.12 to 2.12.10. The change list between Scala 2.12 and 2.11 is in the <a class="reference external" href="https://github.com/scala/scala/releases/tag/v2.12.0">Scala 2.12.0 release notes</a>.</p>
</li>
<li><p><strong>Auto Loader (Public Preview)</strong>, released in Databricks Runtime 6.4, has been improved in Databricks Runtime 7.0</p>
<p>Auto Loader gives you a more efficient way to process new data files incrementally as they arrive on a cloud blob store during ETL. This is an improvement over file-based structured streaming, which identifies new files by repeatedly listing the cloud directory and tracking the files that have been seen, and can be very inefficient as the directory grows. Auto Loader is also more convenient and effective than file-notification-based structured streaming, which requires that you manually configure file-notification services on the cloud and doesn’t let you backfill existing files. For details, see <a class="reference internal" href="../../ingestion/auto-loader/index.html"><span class="doc">What is Auto Loader?</span></a>.</p>
</li>
</ul>
<ul>
<li><p><strong><code class="docutils literal notranslate"><span class="pre">COPY</span> <span class="pre">INTO</span></code> (Public Preview)</strong>, which lets you load data into Delta Lake with idempotent retries, has been improved in Databricks Runtime 7.0</p>
<p>Released as a Public Preview in Databricks Runtime 6.4, the <code class="docutils literal notranslate"><span class="pre">COPY</span> <span class="pre">INTO</span></code> SQL command lets you load data into Delta Lake with idempotent retries. To load data into Delta Lake today you have to use Apache Spark DataFrame APIs. If there are failures during loads, you have to handle them effectively. The new <code class="docutils literal notranslate"><span class="pre">COPY</span> <span class="pre">INTO</span></code> command provides a familiar declarative interface to load data in SQL. The command keeps track of previously loaded files and you safely re-run it in case of failures. For details, see <a class="reference internal" href="../../sql/language-manual/delta-copy-into.html"><span class="doc">COPY INTO</span></a>.</p>
</li>
</ul>
</div>
<div class="section" id="improvements">
<h2>Improvements<a class="headerlink" href="#improvements" title="Permalink to this headline"> </a></h2>
<ul>
<li><p>More Amazon Kinesis concurrent streams:</p>
<p>The Amazon Kinesis Structured Streaming source uses <code class="docutils literal notranslate"><span class="pre">ListShards</span></code> by default to get the list of shards in a Kinesis stream. This requires additional IAM permissions to successfully run your stream. In previous versions of Databricks Runtime, <code class="docutils literal notranslate"><span class="pre">DescribeStream</span></code> was used by default. <code class="docutils literal notranslate"><span class="pre">ListShards</span></code> has a significantly higher API limit than <code class="docutils literal notranslate"><span class="pre">DescribeStream</span></code> (100 requests per second per stream for <code class="docutils literal notranslate"><span class="pre">ListShards</span></code> versus 10 requests per second across your entire AWS account for <code class="docutils literal notranslate"><span class="pre">DescribeStream</span></code>). This change will allow users to run more than 10 concurrent Kinesis streams with Structured Streaming in Databricks.</p>
</li>
</ul>
<ul>
<li><p>Azure Synapse (formerly SQL Data Warehouse) connector supports the <code class="docutils literal notranslate"><span class="pre">COPY</span></code> statement.</p>
<p>The main benefit of <code class="docutils literal notranslate"><span class="pre">COPY</span></code> is that lower privileged users can write data to Azure Synapse without needing strict <code class="docutils literal notranslate"><span class="pre">CONTROL</span></code> permissions on Azure Synapse.</p>
</li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">%matplotlib</span> <span class="pre">inline</span></code> magic command is no longer required to <a class="reference internal" href="../../visualizations/matplotlib.html"><span class="doc">display Matplolib</span></a> objects inline in notebook cells. They are always displayed inline by default.</p></li>
<li><p><a class="reference internal" href="../../visualizations/matplotlib.html"><span class="doc">Matplolib</span></a> figures are now rendered with <code class="docutils literal notranslate"><span class="pre">transparent=False</span></code>, so that user-specified backgrounds are not lost. This behavior can be overridden by setting Spark configuration <code class="docutils literal notranslate"><span class="pre">spark.databricks.workspace.matplotlib.transparent</span> <span class="pre">true</span></code>.</p></li>
<li><p>When running Structured Streaming production jobs on High Concurrency mode clusters, restarts of a job would occasionally fail, because the previously running job wasn’t terminated properly. Databricks Runtime 6.3 introduced the ability to set the SQL configuration <code class="docutils literal notranslate"><span class="pre">spark.sql.streaming.stopActiveRunOnRestart</span> <span class="pre">true</span></code> on your cluster to ensure that the previous run stops. This configuration is set by default in Databricks Runtime 7.0.</p></li>
</ul>
<div class="section" id="major-library-changes">
<h3>Major library changes<a class="headerlink" href="#major-library-changes" title="Permalink to this headline"> </a></h3>
<div class="section" id="python-packages">
<h4>Python packages<a class="headerlink" href="#python-packages" title="Permalink to this headline"> </a></h4>
<p>Major Python packages upgraded:</p>
<ul class="simple">
<li><p>boto3 1.9.162 -&gt; 1.12.0</p></li>
<li><p>matplotlib 3.0.3 -&gt; 3.1.3</p></li>
<li><p>numpy 1.16.2 -&gt; 1.18.1</p></li>
<li><p>pandas 0.24.2 -&gt; 1.0.1</p></li>
<li><p>pip 19.0.3 -&gt; 20.0.2</p></li>
<li><p>pyarrow 0.13.0 -&gt; 0.15.1</p></li>
<li><p>psycopg2 2.7.6 -&gt; 2.8.4</p></li>
<li><p>scikit-learn 0.20.3 -&gt; 0.22.1</p></li>
<li><p>scipy 1.2.1 -&gt; 1.4.1</p></li>
<li><p>seaborn 0.9.0 -&gt; 0.10.0</p></li>
</ul>
<p>Python packages removed:</p>
<ul class="simple">
<li><p>boto (use boto3)</p></li>
<li><p>pycurl</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The Python environment in Databricks Runtime 7.0 uses Python 3.7, which is different from the installed Ubuntu system Python:
<code class="docutils literal notranslate"><span class="pre">/usr/bin/python</span></code> and <code class="docutils literal notranslate"><span class="pre">/usr/bin/python2</span></code> are linked to Python 2.7 and <code class="docutils literal notranslate"><span class="pre">/usr/bin/python3</span></code> is linked to Python 3.6.</p>
</div>
</div>
<div class="section" id="r-packages">
<h4>R packages<a class="headerlink" href="#r-packages" title="Permalink to this headline"> </a></h4>
<p>R packages added:</p>
<ul class="simple">
<li><p>broom</p></li>
<li><p>highr</p></li>
<li><p>isoband</p></li>
<li><p>knitr</p></li>
<li><p>markdown</p></li>
<li><p>modelr</p></li>
<li><p>reprex</p></li>
<li><p>rmarkdown</p></li>
<li><p>rvest</p></li>
<li><p>selectr</p></li>
<li><p>tidyverse</p></li>
<li><p>tinytex</p></li>
<li><p>xfun</p></li>
</ul>
<p>R packages removed:</p>
<ul class="simple">
<li><p>abind</p></li>
<li><p>bitops</p></li>
<li><p>car</p></li>
<li><p>carData</p></li>
<li><p>doMC</p></li>
<li><p>gbm</p></li>
<li><p>h2o</p></li>
<li><p>littler</p></li>
<li><p>lme4</p></li>
<li><p>mapproj</p></li>
<li><p>maps</p></li>
<li><p>maptools</p></li>
<li><p>MatrixModels</p></li>
<li><p>minqa</p></li>
<li><p>mvtnorm</p></li>
<li><p>nloptr</p></li>
<li><p>openxlsx</p></li>
<li><p>pbkrtest</p></li>
<li><p>pkgKitten</p></li>
<li><p>quantreg</p></li>
<li><p>R.methodsS3</p></li>
<li><p>R.oo</p></li>
<li><p>R.utils</p></li>
<li><p>RcppEigen</p></li>
<li><p>RCurl</p></li>
<li><p>rio</p></li>
<li><p>sp</p></li>
<li><p>SparseM</p></li>
<li><p>statmod</p></li>
<li><p>zip</p></li>
</ul>
</div>
<div class="section" id="java-and-scala-libraries">
<h4>Java and Scala libraries<a class="headerlink" href="#java-and-scala-libraries" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>AWS SDK (aws-java-sdk) upgraded to 1.11.655.</p></li>
<li><p>Amazon Kinesis Client upgraded to 1.12.0</p></li>
</ul>
<ul class="simple">
<li><p>Apache Hive version used for handling Hive user-defined functions and Hive SerDes upgraded to 2.3.</p></li>
<li><p>Previously Azure Storage and Key Vault jars were packaged as part of Databricks Runtime, which would prevent you from using different versions of those libraries attached to clusters. Classes under <code class="docutils literal notranslate"><span class="pre">com.microsoft.azure.storage</span></code> and <code class="docutils literal notranslate"><span class="pre">com.microsoft.azure.keyvault</span></code> are no longer on the class path in Databricks Runtime. If you depend on either of those class paths, you must now attach Azure Storage SDK or Azure Key Vault SDK to your clusters.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="behavior-changes">
<h2>Behavior changes<a class="headerlink" href="#behavior-changes" title="Permalink to this headline"> </a></h2>
<p>This section lists behavior changes from Databricks Runtime 6.6 to Databricks Runtime 7.0. You should be aware of these as you migrate workloads from lower Databricks Runtime releases to Databricks Runtime 7.0 and above.</p>
<div class="section" id="spark-behavior-changes">
<h3>Spark behavior changes<a class="headerlink" href="#spark-behavior-changes" title="Permalink to this headline"> </a></h3>
<p>Because Databricks Runtime 7.0 is the first Databricks Runtime built on Spark 3.0, there are many changes that you should be aware of when you migrate workloads from Databricks Runtime 5.5 LTS or 6.x, which are built on Spark 2.4. These changes are listed in the “Behavior changes” section of each functional area in the <a class="reference internal" href="#spark"><span class="std std-ref">Apache Spark</span></a> section of this release notes article:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#behavior-changes-for-spark-core-spark-sql-and-structured-streaming"><span class="std std-ref">Behavior changes for Spark core, Spark SQL, and Structured Streaming</span></a></p></li>
<li><p><a class="reference internal" href="#behavior-changes-for-mllib"><span class="std std-ref">Behavior changes for MLlib</span></a></p></li>
<li><p><a class="reference internal" href="#behavior-changes-for-sparkr"><span class="std std-ref">Behavior changes for SparkR</span></a></p></li>
</ul>
</div>
<div class="section" id="other-behavior-changes">
<h3>Other behavior changes<a class="headerlink" href="#other-behavior-changes" title="Permalink to this headline"> </a></h3>
<ul>
<li><p>The upgrade to Scala 2.12 involves the following changes:</p>
<ul>
<li><p>Package cell serialization is handled differently. The following example illustrates the behavior change and how to handle it.</p>
<p>Running <code class="docutils literal notranslate"><span class="pre">foo.bar.MyObjectInPackageCell.run()</span></code> as defined in the following package cell will trigger the error <code class="docutils literal notranslate"><span class="pre">java.lang.NoClassDefFoundError:</span> <span class="pre">Could</span> <span class="pre">not</span> <span class="pre">initialize</span> <span class="pre">class</span> <span class="pre">foo.bar.MyObjectInPackageCell$</span></code></p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">package</span><span class="w"> </span><span class="nn">foo</span><span class="p">.</span><span class="n">bar</span>

<span class="k">case</span><span class="w"> </span><span class="k">class</span><span class="w"> </span><span class="nc">MyIntStruct</span><span class="p">(</span><span class="n">int</span><span class="p">:</span><span class="w"> </span><span class="nc">Int</span><span class="p">)</span>

<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nc">SparkSession</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nc">Column</span>

<span class="k">object</span><span class="w"> </span><span class="nc">MyObjectInPackageCell</span><span class="w"> </span><span class="k">extends</span><span class="w"> </span><span class="nc">Serializable</span><span class="w"> </span><span class="p">{</span>

<span class="w">  </span><span class="c1">// Because SparkSession cannot be created in Spark executors,</span>
<span class="w">  </span><span class="c1">// the following line triggers the error</span>
<span class="w">  </span><span class="c1">// Could not initialize class foo.bar.MyObjectInPackageCell$</span>
<span class="w">  </span><span class="kd">val</span><span class="w"> </span><span class="n">spark</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">SparkSession</span><span class="p">.</span><span class="n">builder</span><span class="p">.</span><span class="n">getOrCreate</span><span class="p">()</span>

<span class="w">  </span><span class="k">def</span><span class="w"> </span><span class="nf">foo</span><span class="p">:</span><span class="w"> </span><span class="nc">Int</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nc">Option</span><span class="p">[</span><span class="nc">MyIntStruct</span><span class="p">]</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">(</span><span class="n">x</span><span class="p">:</span><span class="w"> </span><span class="nc">Int</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="nc">Some</span><span class="p">(</span><span class="nc">MyIntStruct</span><span class="p">(</span><span class="mi">100</span><span class="p">))</span>

<span class="w">  </span><span class="kd">val</span><span class="w"> </span><span class="n">theUDF</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">udf</span><span class="p">(</span><span class="n">foo</span><span class="p">)</span>

<span class="w">  </span><span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="kd">val</span><span class="w"> </span><span class="n">myUDFInstance</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">theUDF</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s">&quot;id&quot;</span><span class="p">))</span>
<span class="w">    </span><span class="n">spark</span><span class="p">.</span><span class="n">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">,</span><span class="w"> </span><span class="mi">1</span><span class="p">).</span><span class="n">withColumn</span><span class="p">(</span><span class="s">&quot;u&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">myUDFInstance</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>

<span class="w">  </span><span class="k">def</span><span class="w"> </span><span class="nf">run</span><span class="p">():</span><span class="w"> </span><span class="nc">Unit</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="n">df</span><span class="p">.</span><span class="n">collect</span><span class="p">().</span><span class="n">foreach</span><span class="p">(</span><span class="n">println</span><span class="p">)</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>To work around this error, you can wrap <code class="docutils literal notranslate"><span class="pre">MyObjectInPackageCell</span></code> inside a serializable class.</p>
</li>
<li><p>Certain cases using <code class="docutils literal notranslate"><span class="pre">DataStreamWriter.foreachBatch</span></code> will require a source code update.
This change is due to the fact that Scala 2.12 has automatic conversion from lambda expressions to SAM types and can cause ambiguity.</p>
<p>For example, the following Scala code can’t compile:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">streams</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">foreachBatch</span><span class="w"> </span><span class="p">{</span><span class="w"> </span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="o">=&gt;</span><span class="w"> </span><span class="n">myFunc</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">id</span><span class="p">)</span><span class="w"> </span><span class="p">}</span>
</pre></div>
</div>
<p>To fix the compilation error, change <code class="docutils literal notranslate"><span class="pre">foreachBatch</span> <span class="pre">{</span> <span class="pre">(df,</span> <span class="pre">id)</span> <span class="pre">=&gt;</span> <span class="pre">myFunc(df,</span> <span class="pre">id)</span> <span class="pre">}</span></code> to <code class="docutils literal notranslate"><span class="pre">foreachBatch(myFunc</span> <span class="pre">_)</span></code> or use the Java API explicitly: <code class="docutils literal notranslate"><span class="pre">foreachBatch(new</span> <span class="pre">VoidFunction2</span> <span class="pre">...)</span></code>.</p>
</li>
</ul>
</li>
</ul>
<ul class="simple">
<li><p>With the AWS SDK upgrade to 1.11.655, the use of <code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.fs.s3native.NativeS3FileSystem</span></code> requires AWS Signature v4 and bucket endpoint setup. A 403 Forbidden error may be thrown if a user has configured AWS Signature v2 to sign requests to S3 with the S3N file system or a user accesses an S3 path that contains “+” characters and uses the legacy S3N file system (for example s3n://bucket/path/+file).</p></li>
</ul>
<ul class="simple">
<li><p>Because the Apache Hive version used for handling Hive user-defined functions and Hive SerDes is upgraded to 2.3, two changes are required:</p>
<ul>
<li><p>Hive’s <code class="docutils literal notranslate"><span class="pre">SerDe</span></code> interface is replaced by an abstract class <code class="docutils literal notranslate"><span class="pre">AbstractSerDe</span></code>.
For any custom Hive <code class="docutils literal notranslate"><span class="pre">SerDe</span></code> implementation, migrating to <code class="docutils literal notranslate"><span class="pre">AbstractSerDe</span></code> is required.</p></li>
<li><p>Setting <code class="docutils literal notranslate"><span class="pre">spark.sql.hive.metastore.jars</span></code> to <code class="docutils literal notranslate"><span class="pre">builtin</span></code> means that the Hive 2.3 metastore client will be used to access metastores for Databricks Runtime 7.0. If you need to access Hive 1.2 based external metastores, set <code class="docutils literal notranslate"><span class="pre">spark.sql.hive.metastore.jars</span></code> to the folder that contains Hive 1.2 jars.</p></li>
</ul>
</li>
</ul>
</div>
</div>
<div class="section" id="deprecations-and-removals">
<h2>Deprecations and removals<a class="headerlink" href="#deprecations-and-removals" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Data skipping index was deprecated in Databricks Runtime 4.3 and removed in Databricks Runtime 7.0. We recommend that you use Delta tables instead, which offer <a class="reference internal" href="../../delta/data-skipping.html"><span class="doc">improved data skipping capabilities</span></a>.</p></li>
<li><p>In Databricks Runtime 7.0, the underlying version of Apache Spark uses Scala 2.12. Since libraries compiled against Scala 2.11 can disable Databricks Runtime 7.0 clusters in unexpected ways, clusters running Databricks Runtime 7.0 and above do not install <a class="reference internal" href="../../libraries/workspace-libraries.html#install-workspace-libraries"><span class="std std-ref">libraries configured to be installed on all clusters</span></a>. The cluster <a class="reference internal" href="../../libraries/cluster-libraries.html#view-the-libraries-installed-on-a-cluster"><span class="std std-ref">Libraries tab</span></a> shows a status <code class="docutils literal notranslate"><span class="pre">Skipped</span></code> and a deprecation message that explains the changes in library handling. However, if you have a cluster that was created on an earlier version of Databricks Runtime <em>before Databricks platform version 3.20 was released to your workspace</em>, and you now edit that cluster to use Databricks Runtime 7.0, any libraries that were configured to be installed on all clusters will be installed on that cluster. In this case, any incompatible JARs in the installed libraries can cause the cluster to be disabled. The workaround is either to clone the cluster or to create a new cluster.</p></li>
</ul>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.fs.s3native.NativeS3FileSystem</span></code> and <code class="docutils literal notranslate"><span class="pre">org.apache.hadoop.fs.s3.S3FileSystem</span></code> are no longer supported for accessing S3.</p>
<p>We strongly encourage you to use <code class="docutils literal notranslate"><span class="pre">com.databricks.s3a.S3AFileSystem</span></code>, which is the default for <code class="docutils literal notranslate"><span class="pre">s3a://</span></code>, <code class="docutils literal notranslate"><span class="pre">s3://</span></code>, and <code class="docutils literal notranslate"><span class="pre">s3n://</span></code> file system schemes in Databricks Runtime. If you need assistance with migration to <code class="docutils literal notranslate"><span class="pre">com.databricks.s3a.S3AFileSystem</span></code>, contact Databricks support or your Databricks account team.</p>
</li>
<li><p>The ability to use <a class="reference internal" href="../../dbfs/index.html"><span class="doc">What is the Databricks File System (DBFS)?</span></a> was removed in Databricks Runtime 7.0 on Community Edition. We recommend that you use <code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">cp</span></code> to copy your data to and from a local directory instead.</p></li>
</ul>
</div>
<div class="section" id="apache-spark">
<span id="as"></span><span id="spark"></span><h2>Apache Spark<a class="headerlink" href="#apache-spark" title="Permalink to this headline"> </a></h2>
<p>Databricks Runtime 7.0 includes Apache Spark 3.0.</p>
<div class="contents local topic" id="in-this-section">
<p class="topic-title first">In this section:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#core-spark-sql-structured-streaming" id="id3">Core, Spark SQL, Structured Streaming</a></p></li>
<li><p><a class="reference internal" href="#mllib" id="id4">MLlib</a></p></li>
<li><p><a class="reference internal" href="#sparkr" id="id5">SparkR</a></p></li>
<li><p><a class="reference internal" href="#graphx" id="id6">GraphX</a></p></li>
<li><p><a class="reference internal" href="#deprecations" id="id7">Deprecations</a></p></li>
<li><p><a class="reference internal" href="#known-issues" id="id8">Known issues</a></p></li>
</ul>
</div>
<div class="section" id="core-spark-sql-structured-streaming">
<h3><a class="toc-backref" href="#id3">Core, Spark SQL, Structured Streaming</a><a class="headerlink" href="#core-spark-sql-structured-streaming" title="Permalink to this headline"> </a></h3>
<div class="section" id="highlights">
<h4>Highlights<a class="headerlink" href="#highlights" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>(Project Hydrogen) Accelerator-aware Scheduler (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24615">SPARK-24615</a>)</p></li>
<li><p>Adaptive Query Execution (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31412">SPARK-31412</a>)</p></li>
<li><p>Dynamic Partition Pruning (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-11150">SPARK-11150</a>)</p></li>
<li><p>Redesigned pandas UDF API with type hints (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28264">SPARK-28264</a>)</p></li>
<li><p>Structured Streaming UI (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29543">SPARK-29543</a>)</p></li>
<li><p>Catalog plugin API (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31121">SPARK-31121</a>)</p></li>
<li><p>Better ANSI SQL compatibility</p></li>
</ul>
</div>
<div class="section" id="performance-enhancements">
<h4>Performance enhancements<a class="headerlink" href="#performance-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Adaptive Query Execution (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31412">SPARK-31412</a>)</p>
<ul>
<li><p>Basic framework (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23128">SPARK-23128</a>)</p></li>
<li><p>Post shuffle partition number adjustment (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28177">SPARK-28177</a>)</p></li>
<li><p>Dynamic subquery reuse (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28753">SPARK-28753</a>)</p></li>
<li><p>Local shuffle reader (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28560">SPARK-28560</a>)</p></li>
<li><p>Skew join optimization (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29544">SPARK-29544</a>)</p></li>
<li><p>Optimize reading contiguous shuffle blocks (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-9853">SPARK-9853</a>)</p></li>
</ul>
</li>
<li><p>Dynamic Partition Pruning (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-11150">SPARK-11150</a>)</p></li>
<li><p>Other optimizer rules</p>
<ul>
<li><p>Rule ReuseSubquery (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27279">SPARK-27279</a>)</p></li>
<li><p>Rule PushDownLeftSemiAntiJoin (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19712">SPARK-19712</a>)</p></li>
<li><p>Rule PushLeftSemiLeftAntiThroughJoin (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19712">SPARK-19712</a>)</p></li>
<li><p>Rule ReplaceNullWithFalse (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25860">SPARK-25860</a>)</p></li>
<li><p>Rule Eliminate sorts without limit in the subquery of Join/Aggregation (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29343">SPARK-29343</a>)</p></li>
<li><p>Rule PruneHiveTablePartitions (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-15616">SPARK-15616</a>)</p></li>
<li><p>Pruning unnecessary nested fields from Generate (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27707">SPARK-27707</a>)</p></li>
<li><p>Rule RewriteNonCorrelatedExists (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29800">SPARK-29800</a>)</p></li>
</ul>
</li>
<li><p>Minimize table cache synchronization costs (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26917">SPARK-26917</a>), (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26617">SPARK-26617</a>), (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26548">SPARK-26548</a>)</p></li>
<li><p>Split aggregation code into small functions (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-21870">SPARK-21870</a>)</p></li>
<li><p>Add batching in INSERT and ALTER TABLE ADD PARTITION command (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29938">SPARK-29938</a>)</p></li>
</ul>
</div>
<div class="section" id="extensibility-enhancements">
<h4>Extensibility enhancements<a class="headerlink" href="#extensibility-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Catalog plugin API (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31121">SPARK-31121</a>)</p></li>
<li><p>Data source V2 API refactoring (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25390">SPARK-25390</a>)</p></li>
<li><p>Hive 3.0 and 3.1 metastore support (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27970">SPARK-27970</a>),(<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24360">SPARK-24360</a>)</p></li>
<li><p>Extend Spark plugin interface to driver (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29396">SPARK-29396</a>)</p></li>
<li><p>Extend Spark metrics system with user-defined metrics using executor plugins (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28091">SPARK-28091</a>)</p></li>
<li><p>Developer APIs for extended Columnar Processing Support (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27396">SPARK-27396</a>)</p></li>
<li><p>Built-in source migration using DSV2: parquet, ORC, CSV, JSON, Kafka, Text, Avro (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27589">SPARK-27589</a>)</p></li>
<li><p>Allow FunctionInjection in SparkExtensions (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25560">SPARK-25560</a>)</p></li>
<li><p>Allows Aggregator to be registered as a UDAF (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27296">SPARK-27296</a>)</p></li>
</ul>
</div>
<div class="section" id="connector-enhancements">
<h4>Connector enhancements<a class="headerlink" href="#connector-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Support High Performance S3A committers (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23977">SPARK-23977</a>)</p></li>
</ul>
<ul class="simple">
<li><p>Column pruning through nondeterministic expressions (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29768">SPARK-29768</a>)</p></li>
<li><p>Support <code class="docutils literal notranslate"><span class="pre">spark.sql.statistics.fallBackToHdfs</span></code> in data source tables (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25474">SPARK-25474</a>)</p></li>
<li><p>Allow partition pruning with subquery filters on file source (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26893">SPARK-26893</a>)</p></li>
<li><p>Avoid pushdown of subqueries in data source filters (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25482">SPARK-25482</a>)</p></li>
<li><p>Recursive data loading from file sources (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27990">SPARK-27990</a>)</p></li>
<li><p>Parquet/ORC</p>
<ul>
<li><p>Pushdown of disjunctive predicates (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27699">SPARK-27699</a>)</p></li>
<li><p>Generalize Nested Column Pruning (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25603">SPARK-25603</a>) and turned on by default (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29805">SPARK-29805</a>)</p></li>
<li><p>Parquet only</p>
<ul>
<li><p>Parquet predicate pushdown for nested fields (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-17636">SPARK-17636</a>)</p></li>
</ul>
</li>
<li><p>ORC only</p>
<ul>
<li><p>Support merge schema for ORC (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-11412">SPARK-11412</a>)</p></li>
<li><p>Nested schema pruning for ORC (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27034">SPARK-27034</a>)</p></li>
<li><p>Predicate conversion complexity reduction for ORC (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27105">SPARK-27105</a>, <a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28108">SPARK-28108</a>)</p></li>
<li><p>Upgrade Apache ORC to 1.5.9 (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30695">SPARK-30695</a>)</p></li>
</ul>
</li>
</ul>
</li>
<li><p>CSV</p>
<ul>
<li><p>Support filters pushdown in CSV datasource (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30323">SPARK-30323</a>)</p></li>
</ul>
</li>
<li><p>Hive SerDe</p>
<ul>
<li><p>No schema inference when reading Hive serde table with native data source (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27119">SPARK-27119</a>)</p></li>
<li><p>Hive CTAS commands should use data source if it is convertible (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25271">SPARK-25271</a>)</p></li>
<li><p>Use native data source to optimize inserting partitioned Hive table (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28573">SPARK-28573</a>)</p></li>
</ul>
</li>
<li><p>Apache Kafka</p>
<ul>
<li><p>Add support for Kafka headers (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23539">SPARK-23539</a>)</p></li>
<li><p>Add Kafka delegation token support (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25501">SPARK-25501</a>)</p></li>
<li><p>Introduce new option to Kafka source: offset by timestamp (starting/ending) (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26848">SPARK-26848</a>)</p></li>
<li><p>Support the <code class="docutils literal notranslate"><span class="pre">minPartitions</span></code> option in Kafka batch source and streaming source v1 (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30656">SPARK-30656</a>)</p></li>
<li><p>Upgrade Kafka to 2.4.1 (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31126">SPARK-31126</a>)</p></li>
</ul>
</li>
<li><p>New built-in data sources</p>
<ul>
<li><p>New built-in binary file data sources (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25348">SPARK-25348</a>)</p></li>
<li><p>New no-op batch data sources (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26550">SPARK-26550</a>) and no-op streaming sink (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26649">SPARK-26649</a>)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="feature-enhancements">
<h4>Feature enhancements<a class="headerlink" href="#feature-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>[Hydrogen] Accelerator-aware Scheduler (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24615">SPARK-24615</a>)</p></li>
<li><p>Introduce a complete set of Join Hints (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27225">SPARK-27225</a>)</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">PARTITION</span> <span class="pre">BY</span></code> hint for SQL queries (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28746">SPARK-28746</a>)</p></li>
<li><p>Metadata Handling in Thrift Server (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28426">SPARK-28426</a>)</p></li>
<li><p>Add higher order functions to scala API (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27297">SPARK-27297</a>)</p></li>
<li><p>Support simple all gather in barrier task context (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30667">SPARK-30667</a>)</p></li>
<li><p>Hive UDFs supports the UDT type (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28158">SPARK-28158</a>)</p></li>
<li><p>Support DELETE/UPDATE/MERGE Operators in Catalyst (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28351">SPARK-28351</a>, <a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28892">SPARK-28892</a>, <a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28893">SPARK-28893</a>)</p></li>
<li><p>Implement DataFrame.tail (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30185">SPARK-30185</a>)</p></li>
<li><p>New built-in functions</p>
<ul>
<li><p>sinh, cosh, tanh, asinh, acosh, atanh (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28133">SPARK-28133</a>)</p></li>
<li><p>any, every, some (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19851">SPARK-19851</a>)</p></li>
<li><p>bit_and, bit_or (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27879">SPARK-27879</a>)</p></li>
<li><p>bit_count (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29491">SPARK-29491</a>)</p></li>
<li><p>bit_xor (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29545">SPARK-29545</a>)</p></li>
<li><p>bool_and, bool_or (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30184">SPARK-30184</a>)</p></li>
<li><p>count_if (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27425">SPARK-27425</a>)</p></li>
<li><p>date_part (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28690">SPARK-28690</a>)</p></li>
<li><p>extract (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23903">SPARK-23903</a>)</p></li>
<li><p>forall (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27905">SPARK-27905</a>)</p></li>
<li><p>from_csv (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25393">SPARK-25393</a>)</p></li>
<li><p>make_date (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28432">SPARK-28432</a>)</p></li>
<li><p>make_interval (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29393">SPARK-29393</a>)</p></li>
<li><p>make_timestamp (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28459">SPARK-28459</a>)</p></li>
<li><p>map_entries (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23935">SPARK-23935</a>)</p></li>
<li><p>map_filter (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23937">SPARK-23937</a>)</p></li>
<li><p>map_zip_with (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23938">SPARK-23938</a>)</p></li>
<li><p>max_by, min_by (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27653">SPARK-27653</a>)</p></li>
<li><p>schema_of_csv (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25672">SPARK-25672</a>)</p></li>
<li><p>to_csv (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25638">SPARK-25638</a>)</p></li>
<li><p>transform_keys (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23939">SPARK-23939</a>)</p></li>
<li><p>transform_values (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23940">SPARK-23940</a>)</p></li>
<li><p>typeof (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29961">SPARK-29961</a>)</p></li>
<li><p>version (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29554">SPARK-29554</a>)</p></li>
<li><p>xxhash64 (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27099">SPARK-27099</a>)</p></li>
</ul>
</li>
<li><p>Improvements on existing built-in functions</p>
<ul>
<li><p>Built-in date-time functions/operations improvement (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31415">SPARK-31415</a>)</p></li>
<li><p>Support <code class="docutils literal notranslate"><span class="pre">FAILFAST</span></code> mode for <code class="docutils literal notranslate"><span class="pre">from_json</span></code> (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25243">SPARK-25243</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">array_sort</span></code> adds a new comparator parameter (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29020">SPARK-29020</a>)</p></li>
<li><p>Filter can now take the index as input as well as the element (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28962">SPARK-28962</a>)</p></li>
</ul>
</li>
</ul>
</div>
<div class="section" id="sql-compatibility-enhancements">
<h4>SQL compatibility enhancements<a class="headerlink" href="#sql-compatibility-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Switch to Proleptic Gregorian calendar (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26651">SPARK-26651</a>)</p></li>
<li><p>Build Spark’s own datetime pattern definition (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31408">SPARK-31408</a>)</p></li>
<li><p>Introduce ANSI store assignment policy for table insertion (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28495">SPARK-28495</a>)</p></li>
<li><p>Follow ANSI store assignment rule in table insertion by default (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28885">SPARK-28885</a>)</p></li>
<li><p>Add a SQLConf <code class="docutils literal notranslate"><span class="pre">spark.sql.ansi.enabled</span></code> (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28989">SPARK-28989</a>)</p></li>
<li><p>Support ANSI SQL filter clause for aggregate expression (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27986">SPARK-27986</a>)</p></li>
<li><p>Support ANSI SQL <code class="docutils literal notranslate"><span class="pre">OVERLAY</span></code> function (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28077">SPARK-28077</a>)</p></li>
<li><p>Support ANSI nested bracketed comments (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28880">SPARK-28880</a>)</p></li>
<li><p>Throw exception on overflow for integers (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26218">SPARK-26218</a>)</p></li>
<li><p>Overflow check for interval arithmetic operations (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30341">SPARK-30341</a>)</p></li>
<li><p>Throw Exception when invalid string is cast to numeric type (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30292">SPARK-30292</a>)</p></li>
<li><p>Make interval multiply and divide’s overflow behavior consistent with other operations (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30919">SPARK-30919</a>)</p></li>
<li><p>Add ANSI type aliases for char and decimal (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29941">SPARK-29941</a>)</p></li>
<li><p>SQL Parser defines ANSI compliant reserved keywords (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26215">SPARK-26215</a>)</p></li>
<li><p>Forbid reserved keywords as identifiers when ANSI mode is on (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26976">SPARK-26976</a>)</p></li>
<li><p>Support ANSI SQL <code class="docutils literal notranslate"><span class="pre">LIKE</span> <span class="pre">...</span> <span class="pre">ESCAPE</span></code> syntax (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28083">SPARK-28083</a>)</p></li>
<li><p>Support ANSI SQL Boolean-Predicate syntax (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27924">SPARK-27924</a>)</p></li>
<li><p>Better support for correlated subquery processing (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-18455">SPARK-18455</a>)</p></li>
</ul>
</div>
<div class="section" id="monitoring-and-debugability-enhancements">
<h4>Monitoring and debugability enhancements<a class="headerlink" href="#monitoring-and-debugability-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>New Structured Streaming UI (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29543">SPARK-29543</a>)</p></li>
<li><p>SHS: Allow event logs for running streaming apps to be rolled over (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28594">SPARK-28594</a>)</p></li>
<li><p>Add an API that allows a user to define and observe arbitrary metrics on batch and streaming queries (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29345">SPARK-29345</a>)</p></li>
<li><p>Instrumentation for tracking per-query planning time (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26129">SPARK-26129</a>)</p></li>
<li><p>Put the basic shuffle metrics in the SQL exchange operator (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26139">SPARK-26139</a>)</p></li>
<li><p>SQL statement is shown in SQL Tab instead of callsite (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27045">SPARK-27045</a>)</p></li>
<li><p>Add tooltip to SparkUI (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29449">SPARK-29449</a>)</p></li>
<li><p>Improve the concurrent performance of History Server (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29043">SPARK-29043</a>)</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">EXPLAIN</span> <span class="pre">FORMATTED</span></code> command (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27395">SPARK-27395</a>)</p></li>
<li><p>Support Dumping truncated plans and generated code to a file (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26023">SPARK-26023</a>)</p></li>
<li><p>Enhance describe framework to describe the output of a query (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26982">SPARK-26982</a>)</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">SHOW</span> <span class="pre">VIEWS</span></code> command (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31113">SPARK-31113</a>)</p></li>
<li><p>Improve the error messages of SQL parser (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27901">SPARK-27901</a>)</p></li>
<li><p>Support Prometheus monitoring natively (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29429">SPARK-29429</a>)</p></li>
</ul>
</div>
<div class="section" id="pyspark-enhancements">
<h4>PySpark enhancements<a class="headerlink" href="#pyspark-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Redesigned pandas UDFs with type hints (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28264">SPARK-28264</a>)</p></li>
<li><p>Pandas UDF pipeline (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26412">SPARK-26412</a>)</p></li>
<li><p>Support StructType as arguments and return types for Scalar Pandas UDF (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27240">SPARK-27240</a> )</p></li>
<li><p>Support Dataframe Cogroup via Pandas UDFs (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27463">SPARK-27463</a>)</p></li>
<li><p>Add <code class="docutils literal notranslate"><span class="pre">mapInPandas</span></code> to allow an iterator of DataFrames (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28198">SPARK-28198</a>)</p></li>
<li><p>Certain SQL functions should take column names as well (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26979">SPARK-26979</a>)</p></li>
<li><p>Make PySpark SQL exceptions more Pythonic (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31849">SPARK-31849</a>)</p></li>
</ul>
</div>
<div class="section" id="documentation-and-test-coverage-enhancements">
<h4>Documentation and test coverage enhancements<a class="headerlink" href="#documentation-and-test-coverage-enhancements" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Build a SQL Reference (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28588">SPARK-28588</a>)</p></li>
<li><p>Build a user guide for WebUI (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28372">SPARK-28372</a>)</p></li>
<li><p>Build a page for SQL configuration documentation (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30510">SPARK-30510</a>)</p></li>
<li><p>Add version information for Spark configuration (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30839">SPARK-30839</a>)</p></li>
<li><p>Port regression tests from PostgreSQL (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27763">SPARK-27763</a>)</p></li>
<li><p>Thrift-server test coverage (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28608">SPARK-28608</a>)</p></li>
<li><p>Test coverage of UDFs (python UDF, pandas UDF, scala UDF)  (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27921">SPARK-27921</a>)</p></li>
</ul>
</div>
<div class="section" id="other-notable-changes">
<h4>Other notable changes<a class="headerlink" href="#other-notable-changes" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Built-in Hive execution upgrade from 1.2.1 to 2.3.6  (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23710">SPARK-23710</a>, <a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28723">SPARK-28723</a>, <a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31381">SPARK-31381</a>)</p></li>
<li><p>Use Apache Hive 2.3 dependency by default (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30034">SPARK-30034</a>)</p></li>
<li><p>GA Scala 2.12 and remove 2.11 (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26132">SPARK-26132</a>)</p></li>
<li><p>Improve logic for timing out executors in dynamic allocation (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-20286">SPARK-20286</a>)</p></li>
<li><p>Disk-persisted RDD blocks served by shuffle service and ignored for Dynamic Allocation (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27677">SPARK-27677</a>)</p></li>
<li><p>Acquire new executors to avoid hang because of blocklisting (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-22148">SPARK-22148</a>)</p></li>
<li><p>Allow sharing of Netty’s memory pool allocators (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24920">SPARK-24920</a>)</p></li>
<li><p>Fix deadlock between <code class="docutils literal notranslate"><span class="pre">TaskMemoryManager</span></code> and <code class="docutils literal notranslate"><span class="pre">UnsafeExternalSorter$SpillableIterator</span></code> (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27338">SPARK-27338</a>)</p></li>
<li><p>Introduce <code class="docutils literal notranslate"><span class="pre">AdmissionControl</span></code> APIs for StructuredStreaming (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30669">SPARK-30669</a>)</p></li>
<li><p>Spark History Main page performance improvement (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-25973">SPARK-25973</a>)</p></li>
<li><p>Speed up and slim down metric aggregation in SQL listener (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29562">SPARK-29562</a>)</p></li>
<li><p>Avoid the network when shuffle blocks are fetched from the same host (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27651">SPARK-27651</a>)</p></li>
<li><p>Improve file listing for <code class="docutils literal notranslate"><span class="pre">DistributedFileSystem</span></code> (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27801">SPARK-27801</a>)</p></li>
</ul>
</div>
<div class="section" id="behavior-changes-for-spark-core-spark-sql-and-structured-streaming">
<h4>Behavior changes for Spark core, Spark SQL, and Structured Streaming<a class="headerlink" href="#behavior-changes-for-spark-core-spark-sql-and-structured-streaming" title="Permalink to this headline"> </a></h4>
<p>The following migration guides list behavior changes between Apache Spark 2.4 and 3.0. These changes may require updates to jobs that you have been running on lower Databricks Runtime versions:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/core-migration-guide.html#upgrading-from-core-24-to-30">Migration Guide: Spark Core</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/sql-migration-guide.html#upgrading-from-spark-sql-24-to-30">Migration Guide: SQL, Datasets and DataFrame</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/ss-migration-guide.html#upgrading-from-structured-streaming-24-to-30">Migration Guide: Structured Streaming</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/pyspark-migration-guide.html#upgrading-from-pyspark-24-to-30">Migration Guide: PySpark (Python on Spark)</a></p></li>
</ul>
<p>The following behavior changes are not covered in these migration guides:</p>
<ul class="simple">
<li><p>In Spark 3.0, the deprecated class <code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.streaming.ProcessingTime</span></code> has been removed. Use <code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.streaming.Trigger.ProcessingTime</span></code> instead. Likewise, <code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.execution.streaming.continuous.ContinuousTrigger</span></code> has been removed in favor of <code class="docutils literal notranslate"><span class="pre">Trigger.Continuous</span></code>, and <code class="docutils literal notranslate"><span class="pre">org.apache.spark.sql.execution.streaming.OneTimeTrigger</span></code> has been hidden in favor of <code class="docutils literal notranslate"><span class="pre">Trigger.Once</span></code>. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28199">SPARK-28199</a>)</p></li>
<li><p>In Databricks Runtime 7.0, when reading a Hive SerDe table, by default Spark disallows reading files under a subdirectory that is not a table partition. To enable it, set the configuration <code class="docutils literal notranslate"><span class="pre">spark.databricks.io.hive.scanNonpartitionedDirectory.enabled</span></code> as <code class="docutils literal notranslate"><span class="pre">true</span></code>. This does not affect Spark native table readers and file readers.</p></li>
</ul>
</div>
<div class="section" id="programming-guides">
<h4>Programming guides:<a class="headerlink" href="#programming-guides" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.0/rdd-programming-guide.html">Spark RDD Programming Guide</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.0/sql-programming-guide.html">Spark SQL, DataFrames and Datasets Guide</a></p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.0/structured-streaming-programming-guide.html">Structured Streaming Programming Guide</a>.</p></li>
</ul>
</div>
</div>
<div class="section" id="mllib">
<h3><a class="toc-backref" href="#id4">MLlib</a><a class="headerlink" href="#mllib" title="Permalink to this headline"> </a></h3>
<div class="section" id="highlights">
<span id="highlights-1"></span><h4>Highlights<a class="headerlink" href="#highlights" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p>Multiple columns support was added to Binarizer (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23578">SPARK-23578</a>), StringIndexer (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-11215">SPARK-11215</a>), StopWordsRemover (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29808">SPARK-29808</a>) and PySpark QuantileDiscretizer (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-22796">SPARK-22796</a>)</p></li>
<li><p>Support tree-based feature transformation(<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-13677">SPARK-13677</a>)</p></li>
<li><p>Two new evaluators MultilabelClassificationEvaluator (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-16692">SPARK-16692</a>) and RankingEvaluator (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28045">SPARK-28045</a>) were added</p></li>
<li><p>Sample weights support was added in DecisionTreeClassifier/Regressor (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19591">SPARK-19591</a>), RandomForestClassifier/Regressor (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-9478">SPARK-9478</a>), GBTClassifier/Regressor (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-9612">SPARK-9612</a>), RegressionEvaluator (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24102">SPARK-24102</a>), BinaryClassificationEvaluator (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24103">SPARK-24103</a>), BisectingKMeans (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30351">SPARK-30351</a>), KMeans (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29967">SPARK-29967</a>) and GaussianMixture (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30102">SPARK-30102</a>)</p></li>
<li><p>R API for PowerIterationClustering was added (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19827">SPARK-19827</a>)</p></li>
<li><p>Added Spark ML listener for tracking ML pipeline status (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-23674">SPARK-23674</a>)</p></li>
<li><p>Fit with validation set was added to Gradient Boosted Trees in Python (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24333">SPARK-24333</a>)</p></li>
<li><p>RobustScaler transformer was added (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28399">SPARK-28399</a>)</p></li>
<li><p>Factorization Machines classifier and regressor were added (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29224">SPARK-29224</a>)</p></li>
<li><p>Gaussian Naive Bayes (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-16872">SPARK-16872</a>) and Complement Naive Bayes (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29942">SPARK-29942</a>) were added</p></li>
<li><p>ML function parity between Scala and Python (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-28958">SPARK-28958</a>)</p></li>
<li><p>predictRaw is made public in all the Classification models. predictProbability is made public in all of the Classification models except LinearSVCModel (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-30358">SPARK-30358</a>)</p></li>
</ul>
</div>
<div class="section" id="behavior-changes-for-mllib">
<h4>Behavior changes for MLlib<a class="headerlink" href="#behavior-changes-for-mllib" title="Permalink to this headline"> </a></h4>
<p>The following migration guide lists behavior changes between Apache Spark 2.4 and 3.0. These changes may require updates to jobs that you have been running on lower Databricks Runtime versions:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/ml-migration-guide.html#upgrading-from-mllib-24-to-30">Migration Guide: MLlib (Machine Learning)</a></p></li>
</ul>
<p>The following behavior changes are not covered in the migration guide:</p>
<ul class="simple">
<li><p>In Spark 3.0, a multiclass logistic regression in Pyspark will now (correctly) return <code class="docutils literal notranslate"><span class="pre">LogisticRegressionSummary</span></code>, not the subclass <code class="docutils literal notranslate"><span class="pre">BinaryLogisticRegressionSummary</span></code>. The additional methods exposed by <code class="docutils literal notranslate"><span class="pre">BinaryLogisticRegressionSummary</span></code> would not work in this case anyway. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31681">SPARK-31681</a>)</p></li>
<li><p> In Spark 3.0, <code class="docutils literal notranslate"><span class="pre">pyspark.ml.param.shared.Has*</span></code> mixins do not provide any <code class="docutils literal notranslate"><span class="pre">set*(self,</span> <span class="pre">value)</span></code> setter methods anymore, use the respective <code class="docutils literal notranslate"><span class="pre">self.set(self.*,</span> <span class="pre">value)</span></code> instead. See SPARK-29093 for details. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-29093">SPARK-29093</a>)</p></li>
</ul>
</div>
<div class="section" id="programming-guide">
<h4>Programming guide<a class="headerlink" href="#programming-guide" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.0/ml-guide.html">Machine Learning Library (MLlib) Guide</a></p></li>
</ul>
</div>
</div>
<div class="section" id="sparkr">
<h3><a class="toc-backref" href="#id5">SparkR</a><a class="headerlink" href="#sparkr" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>Arrow optimization in SparkR’s interoperability (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26759">SPARK-26759</a>)</p></li>
<li><p>Performance enhancement via vectorized R gapply(), dapply(), createDataFrame, collect()</p></li>
<li><p>“Eager execution” for R shell, IDE (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-24572">SPARK-24572</a>)</p></li>
<li><p>R API for Power Iteration Clustering (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-19827">SPARK-19827</a>)</p></li>
</ul>
<div class="section" id="behavior-changes-for-sparkr">
<h4>Behavior changes for SparkR<a class="headerlink" href="#behavior-changes-for-sparkr" title="Permalink to this headline"> </a></h4>
<p>The following migration guide lists behavior changes between Apache Spark 2.4 and 3.0. These changes may require updates to jobs that you have been running on lower Databricks Runtime versions:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/sparkr-migration-guide.html#upgrading-from-sparkr-24-to-30">Migration Guide: SparkR (R on Spark)</a></p></li>
</ul>
</div>
<div class="section" id="programming-guide">
<span id="programming-guide-1"></span><h4>Programming guide<a class="headerlink" href="#programming-guide" title="Permalink to this headline"> </a></h4>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.apache.org/docs/3.0.0/sparkr.html">SparkR (R on Spark)</a>.</p></li>
</ul>
</div>
</div>
<div class="section" id="graphx">
<h3><a class="toc-backref" href="#id6">GraphX</a><a class="headerlink" href="#graphx" title="Permalink to this headline"> </a></h3>
<p>Programming guide: <a class="reference external" href="https://spark.apache.org/docs/3.0.0/graphx-programming-guide.html">GraphX Programming Guide</a>.</p>
</div>
<div class="section" id="deprecations">
<h3><a class="toc-backref" href="#id7">Deprecations</a><a class="headerlink" href="#deprecations" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>Deprecate Python 2 support (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-27884">SPARK-27884</a>)</p></li>
<li><p>Deprecate R &lt; 3.4 support (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-26014">SPARK-26014</a>)</p></li>
</ul>
</div>
<div class="section" id="known-issues">
<h3><a class="toc-backref" href="#id8">Known issues</a><a class="headerlink" href="#known-issues" title="Permalink to this headline"> </a></h3>
<ul class="simple">
<li><p>Parsing day of year using pattern letter ‘D’ returns the wrong result if the year field is missing. This can happen in SQL functions like <code class="docutils literal notranslate"><span class="pre">to_timestamp</span></code> which parses datetime string to datetime values using a pattern string. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31939">SPARK-31939</a>)</p></li>
<li><p>Join/Window/Aggregate inside subqueries may lead to wrong results if the keys have values -0.0 and 0.0. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31958">SPARK-31958</a>)</p></li>
<li><p>A window query may fail with ambiguous self-join error unexpectedly. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31956">SPARK-31956</a>)</p></li>
<li><p>Streaming queries with <code class="docutils literal notranslate"><span class="pre">dropDuplicates</span></code> operator may not be able to restart with the checkpoint written by Spark 2.x. (<a class="reference external" href="https://issues.apache.org/jira/browse/SPARK-31990">SPARK-31990</a>)</p></li>
</ul>
</div>
</div>
<div class="section" id="maintenance-updates">
<span id="as"></span><h2>Maintenance updates<a class="headerlink" href="#maintenance-updates" title="Permalink to this headline"> </a></h2>
<p>See <a class="reference internal" href="maintenance-updates-archive.html#70"><span class="std std-ref">Databricks Runtime 7.0 maintenance updates</span></a>.</p>
</div>
<div class="section" id="system-environment">
<h2>System environment<a class="headerlink" href="#system-environment" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><strong>Operating System</strong>: Ubuntu 18.04.4 LTS</p></li>
<li><p><strong>Java</strong>: 1.8.0_252</p></li>
<li><p><strong>Scala</strong>: 2.12.10</p></li>
<li><p><strong>Python</strong>: 3.7.5</p></li>
<li><p><strong>R</strong>: R version 3.6.3 (2020-02-29)</p></li>
<li><p><strong>Delta Lake</strong> 0.7.0</p></li>
</ul>
<div class="section" id="installed-python-libraries">
<h3>Installed Python libraries<a class="headerlink" href="#installed-python-libraries" title="Permalink to this headline"> </a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
<th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
<th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>asn1crypto</p></td>
<td><p>1.3.0</p></td>
<td><p>backcall</p></td>
<td><p>0.1.0</p></td>
<td><p>boto3</p></td>
<td><p>1.12.0</p></td>
</tr>
<tr class="row-odd"><td><p>botocore</p></td>
<td><p>1.15.0</p></td>
<td><p>certifi</p></td>
<td><p>2020.4.5</p></td>
<td><p>cffi</p></td>
<td><p>1.14.0</p></td>
</tr>
<tr class="row-even"><td><p>chardet</p></td>
<td><p>3.0.4</p></td>
<td><p>cryptography</p></td>
<td><p>2.8</p></td>
<td><p>cycler</p></td>
<td><p>0.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>Cython</p></td>
<td><p>0.29.15</p></td>
<td><p>decorator</p></td>
<td><p>4.4.1</p></td>
<td><p>docutils</p></td>
<td><p>0.15.2</p></td>
</tr>
<tr class="row-even"><td><p>entrypoints</p></td>
<td><p>0.3</p></td>
<td><p>idna</p></td>
<td><p>2.8</p></td>
<td><p>ipykernel</p></td>
<td><p>5.1.4</p></td>
</tr>
<tr class="row-odd"><td><p>ipython</p></td>
<td><p>7.12.0</p></td>
<td><p>ipython-genutils</p></td>
<td><p>0.2.0</p></td>
<td><p>jedi</p></td>
<td><p>0.14.1</p></td>
</tr>
<tr class="row-even"><td><p>jmespath</p></td>
<td><p>0.9.4</p></td>
<td><p>joblib</p></td>
<td><p>0.14.1</p></td>
<td><p>jupyter-client</p></td>
<td><p>5.3.4</p></td>
</tr>
<tr class="row-odd"><td><p>jupyter-core</p></td>
<td><p>4.6.1</p></td>
<td><p>kiwisolver</p></td>
<td><p>1.1.0</p></td>
<td><p>matplotlib</p></td>
<td><p>3.1.3</p></td>
</tr>
<tr class="row-even"><td><p>numpy</p></td>
<td><p>1.18.1</p></td>
<td><p>pandas</p></td>
<td><p>1.0.1</p></td>
<td><p>parso</p></td>
<td><p>0.5.2</p></td>
</tr>
<tr class="row-odd"><td><p>patsy</p></td>
<td><p>0.5.1</p></td>
<td><p>pexpect</p></td>
<td><p>4.8.0</p></td>
<td><p>pickleshare</p></td>
<td><p>0.7.5</p></td>
</tr>
<tr class="row-even"><td><p>pip</p></td>
<td><p>20.0.2</p></td>
<td><p>prompt-toolkit</p></td>
<td><p>3.0.3</p></td>
<td><p>psycopg2</p></td>
<td><p>2.8.4</p></td>
</tr>
<tr class="row-odd"><td><p>ptyprocess</p></td>
<td><p>0.6.0</p></td>
<td><p>pyarrow</p></td>
<td><p>0.15.1</p></td>
<td><p>pycparser</p></td>
<td><p>2.19</p></td>
</tr>
<tr class="row-even"><td><p>Pygments</p></td>
<td><p>2.5.2</p></td>
<td><p>PyGObject</p></td>
<td><p>3.26.1</p></td>
<td><p>pyOpenSSL</p></td>
<td><p>19.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>pyparsing</p></td>
<td><p>2.4.6</p></td>
<td><p>PySocks</p></td>
<td><p>1.7.1</p></td>
<td><p>python-apt</p></td>
<td><p>1.6.5+ubuntu0.3</p></td>
</tr>
<tr class="row-even"><td><p>python-dateutil</p></td>
<td><p>2.8.1</p></td>
<td><p>pytz</p></td>
<td><p>2019.3</p></td>
<td><p>pyzmq</p></td>
<td><p>18.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>requests</p></td>
<td><p>2.22.0</p></td>
<td><p>s3transfer</p></td>
<td><p>0.3.3</p></td>
<td><p>scikit-learn</p></td>
<td><p>0.22.1</p></td>
</tr>
<tr class="row-even"><td><p>scipy</p></td>
<td><p>1.4.1</p></td>
<td><p>seaborn</p></td>
<td><p>0.10.0</p></td>
<td><p>setuptools</p></td>
<td><p>45.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>six</p></td>
<td><p>1.14.0</p></td>
<td><p>ssh-import-id</p></td>
<td><p>5.7</p></td>
<td><p>statsmodels</p></td>
<td><p>0.11.0</p></td>
</tr>
<tr class="row-even"><td><p>tornado</p></td>
<td><p>6.0.3</p></td>
<td><p>traitlets</p></td>
<td><p>4.3.3</p></td>
<td><p>unattended-upgrades</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-odd"><td><p>urllib3</p></td>
<td><p>1.25.8</p></td>
<td><p>virtualenv</p></td>
<td><p>16.7.10</p></td>
<td><p>wcwidth</p></td>
<td><p>0.1.8</p></td>
</tr>
<tr class="row-even"><td><p>wheel</p></td>
<td><p>0.34.2</p></td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="installed-r-libraries">
<span id="rlibraries"></span><h3>Installed R libraries<a class="headerlink" href="#installed-r-libraries" title="Permalink to this headline"> </a></h3>
<p>R libraries are installed from (<a class="reference external" href="https://mran.revolutionanalytics.com/snapshot/2020-04-22">Microsoft CRAN snapshot on 2020-04-22</a>).</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
<th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
<th class="head"><p>Library</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>askpass</p></td>
<td><p>1.1</p></td>
<td><p>assertthat</p></td>
<td><p>0.2.1</p></td>
<td><p>backports</p></td>
<td><p>1.1.6</p></td>
</tr>
<tr class="row-odd"><td><p>base</p></td>
<td><p>3.6.3</p></td>
<td><p>base64enc</p></td>
<td><p>0.1-3</p></td>
<td><p>BH</p></td>
<td><p>1.72.0-3</p></td>
</tr>
<tr class="row-even"><td><p>bit</p></td>
<td><p>1.1-15.2</p></td>
<td><p>bit64</p></td>
<td><p>0.9-7</p></td>
<td><p>blob</p></td>
<td><p>1.2.1</p></td>
</tr>
<tr class="row-odd"><td><p>boot</p></td>
<td><p>1.3-25</p></td>
<td><p>brew</p></td>
<td><p>1.0-6</p></td>
<td><p>broom</p></td>
<td><p>0.5.6</p></td>
</tr>
<tr class="row-even"><td><p>callr</p></td>
<td><p>3.4.3</p></td>
<td><p>caret</p></td>
<td><p>6.0-86</p></td>
<td><p>cellranger</p></td>
<td><p>1.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>chron</p></td>
<td><p>2.3-55</p></td>
<td><p>class</p></td>
<td><p>7.3-17</p></td>
<td><p>cli</p></td>
<td><p>2.0.2</p></td>
</tr>
<tr class="row-even"><td><p>clipr</p></td>
<td><p>0.7.0</p></td>
<td><p>cluster</p></td>
<td><p>2.1.0</p></td>
<td><p>codetools</p></td>
<td><p>0.2-16</p></td>
</tr>
<tr class="row-odd"><td><p>colorspace</p></td>
<td><p>1.4-1</p></td>
<td><p>commonmark</p></td>
<td><p>1.7</p></td>
<td><p>compiler</p></td>
<td><p>3.6.3</p></td>
</tr>
<tr class="row-even"><td><p>config</p></td>
<td><p>0.3</p></td>
<td><p>covr</p></td>
<td><p>3.5.0</p></td>
<td><p>crayon</p></td>
<td><p>1.3.4</p></td>
</tr>
<tr class="row-odd"><td><p>crosstalk</p></td>
<td><p>1.1.0.1</p></td>
<td><p>curl</p></td>
<td><p>4.3</p></td>
<td><p>data.table</p></td>
<td><p>1.12.8</p></td>
</tr>
<tr class="row-even"><td><p>datasets</p></td>
<td><p>3.6.3</p></td>
<td><p>DBI</p></td>
<td><p>1.1.0</p></td>
<td><p>dbplyr</p></td>
<td><p>1.4.3</p></td>
</tr>
<tr class="row-odd"><td><p>desc</p></td>
<td><p>1.2.0</p></td>
<td><p>devtools</p></td>
<td><p>2.3.0</p></td>
<td><p>digest</p></td>
<td><p>0.6.25</p></td>
</tr>
<tr class="row-even"><td><p>dplyr</p></td>
<td><p>0.8.5</p></td>
<td><p>DT</p></td>
<td><p>0.13</p></td>
<td><p>ellipsis</p></td>
<td><p>0.3.0</p></td>
</tr>
<tr class="row-odd"><td><p>evaluate</p></td>
<td><p>0.14</p></td>
<td><p>fansi</p></td>
<td><p>0.4.1</p></td>
<td><p>farver</p></td>
<td><p>2.0.3</p></td>
</tr>
<tr class="row-even"><td><p>fastmap</p></td>
<td><p>1.0.1</p></td>
<td><p>forcats</p></td>
<td><p>0.5.0</p></td>
<td><p>foreach</p></td>
<td><p>1.5.0</p></td>
</tr>
<tr class="row-odd"><td><p>foreign</p></td>
<td><p>0.8-76</p></td>
<td><p>forge</p></td>
<td><p>0.2.0</p></td>
<td><p>fs</p></td>
<td><p>1.4.1</p></td>
</tr>
<tr class="row-even"><td><p>generics</p></td>
<td><p>0.0.2</p></td>
<td><p>ggplot2</p></td>
<td><p>3.3.0</p></td>
<td><p>gh</p></td>
<td><p>1.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>git2r</p></td>
<td><p>0.26.1</p></td>
<td><p>glmnet</p></td>
<td><p>3.0-2</p></td>
<td><p>globals</p></td>
<td><p>0.12.5</p></td>
</tr>
<tr class="row-even"><td><p>glue</p></td>
<td><p>1.4.0</p></td>
<td><p>gower</p></td>
<td><p>0.2.1</p></td>
<td><p>graphics</p></td>
<td><p>3.6.3</p></td>
</tr>
<tr class="row-odd"><td><p>grDevices</p></td>
<td><p>3.6.3</p></td>
<td><p>grid</p></td>
<td><p>3.6.3</p></td>
<td><p>gridExtra</p></td>
<td><p>2.3</p></td>
</tr>
<tr class="row-even"><td><p>gsubfn</p></td>
<td><p>0.7</p></td>
<td><p>gtable</p></td>
<td><p>0.3.0</p></td>
<td><p>haven</p></td>
<td><p>2.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>highr</p></td>
<td><p>0.8</p></td>
<td><p>hms</p></td>
<td><p>0.5.3</p></td>
<td><p>htmltools</p></td>
<td><p>0.4.0</p></td>
</tr>
<tr class="row-even"><td><p>htmlwidgets</p></td>
<td><p>1.5.1</p></td>
<td><p>httpuv</p></td>
<td><p>1.5.2</p></td>
<td><p>httr</p></td>
<td><p>1.4.1</p></td>
</tr>
<tr class="row-odd"><td><p>hwriter</p></td>
<td><p>1.3.2</p></td>
<td><p>hwriterPlus</p></td>
<td><p>1.0-3</p></td>
<td><p>ini</p></td>
<td><p>0.3.1</p></td>
</tr>
<tr class="row-even"><td><p>ipred</p></td>
<td><p>0.9-9</p></td>
<td><p>isoband</p></td>
<td><p>0.2.1</p></td>
<td><p>iterators</p></td>
<td><p>1.0.12</p></td>
</tr>
<tr class="row-odd"><td><p>jsonlite</p></td>
<td><p>1.6.1</p></td>
<td><p>KernSmooth</p></td>
<td><p>2.23-17</p></td>
<td><p>knitr</p></td>
<td><p>1.28</p></td>
</tr>
<tr class="row-even"><td><p>labeling</p></td>
<td><p>0.3</p></td>
<td><p>later</p></td>
<td><p>1.0.0</p></td>
<td><p>lattice</p></td>
<td><p>0.20-41</p></td>
</tr>
<tr class="row-odd"><td><p>lava</p></td>
<td><p>1.6.7</p></td>
<td><p>lazyeval</p></td>
<td><p>0.2.2</p></td>
<td><p>lifecycle</p></td>
<td><p>0.2.0</p></td>
</tr>
<tr class="row-even"><td><p>lubridate</p></td>
<td><p>1.7.8</p></td>
<td><p>magrittr</p></td>
<td><p>1.5</p></td>
<td><p>markdown</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>MASS</p></td>
<td><p>7.3-51.6</p></td>
<td><p>Matrix</p></td>
<td><p>1.2-18</p></td>
<td><p>memoise</p></td>
<td><p>1.1.0</p></td>
</tr>
<tr class="row-even"><td><p>methods</p></td>
<td><p>3.6.3</p></td>
<td><p>mgcv</p></td>
<td><p>1.8-31</p></td>
<td><p>mime</p></td>
<td><p>0.9</p></td>
</tr>
<tr class="row-odd"><td><p>ModelMetrics</p></td>
<td><p>1.2.2.2</p></td>
<td><p>modelr</p></td>
<td><p>0.1.6</p></td>
<td><p>munsell</p></td>
<td><p>0.5.0</p></td>
</tr>
<tr class="row-even"><td><p>nlme</p></td>
<td><p>3.1-147</p></td>
<td><p>nnet</p></td>
<td><p>7.3-14</p></td>
<td><p>numDeriv</p></td>
<td><p>2016.8-1.1</p></td>
</tr>
<tr class="row-odd"><td><p>openssl</p></td>
<td><p>1.4.1</p></td>
<td><p>parallel</p></td>
<td><p>3.6.3</p></td>
<td><p>pillar</p></td>
<td><p>1.4.3</p></td>
</tr>
<tr class="row-even"><td><p>pkgbuild</p></td>
<td><p>1.0.6</p></td>
<td><p>pkgconfig</p></td>
<td><p>2.0.3</p></td>
<td><p>pkgload</p></td>
<td><p>1.0.2</p></td>
</tr>
<tr class="row-odd"><td><p>plogr</p></td>
<td><p>0.2.0</p></td>
<td><p>plyr</p></td>
<td><p>1.8.6</p></td>
<td><p>praise</p></td>
<td><p>1.0.0</p></td>
</tr>
<tr class="row-even"><td><p>prettyunits</p></td>
<td><p>1.1.1</p></td>
<td><p>pROC</p></td>
<td><p>1.16.2</p></td>
<td><p>processx</p></td>
<td><p>3.4.2</p></td>
</tr>
<tr class="row-odd"><td><p>prodlim</p></td>
<td><p>2019.11.13</p></td>
<td><p>progress</p></td>
<td><p>1.2.2</p></td>
<td><p>promises</p></td>
<td><p>1.1.0</p></td>
</tr>
<tr class="row-even"><td><p>proto</p></td>
<td><p>1.0.0</p></td>
<td><p>ps</p></td>
<td><p>1.3.2</p></td>
<td><p>purrr</p></td>
<td><p>0.3.4</p></td>
</tr>
<tr class="row-odd"><td><p>r2d3</p></td>
<td><p>0.2.3</p></td>
<td><p>R6</p></td>
<td><p>2.4.1</p></td>
<td><p>randomForest</p></td>
<td><p>4.6-14</p></td>
</tr>
<tr class="row-even"><td><p>rappdirs</p></td>
<td><p>0.3.1</p></td>
<td><p>rcmdcheck</p></td>
<td><p>1.3.3</p></td>
<td><p>RColorBrewer</p></td>
<td><p>1.1-2</p></td>
</tr>
<tr class="row-odd"><td><p>Rcpp</p></td>
<td><p>1.0.4.6</p></td>
<td><p>readr</p></td>
<td><p>1.3.1</p></td>
<td><p>readxl</p></td>
<td><p>1.3.1</p></td>
</tr>
<tr class="row-even"><td><p>recipes</p></td>
<td><p>0.1.10</p></td>
<td><p>rematch</p></td>
<td><p>1.0.1</p></td>
<td><p>rematch2</p></td>
<td><p>2.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>remotes</p></td>
<td><p>2.1.1</p></td>
<td><p>reprex</p></td>
<td><p>0.3.0</p></td>
<td><p>reshape2</p></td>
<td><p>1.4.4</p></td>
</tr>
<tr class="row-even"><td><p>rex</p></td>
<td><p>1.2.0</p></td>
<td><p>rjson</p></td>
<td><p>0.2.20</p></td>
<td><p>rlang</p></td>
<td><p>0.4.5</p></td>
</tr>
<tr class="row-odd"><td><p>rmarkdown</p></td>
<td><p>2.1</p></td>
<td><p>RODBC</p></td>
<td><p>1.3-16</p></td>
<td><p>roxygen2</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-even"><td><p>rpart</p></td>
<td><p>4.1-15</p></td>
<td><p>rprojroot</p></td>
<td><p>1.3-2</p></td>
<td><p>Rserve</p></td>
<td><p>1.8-6</p></td>
</tr>
<tr class="row-odd"><td><p>RSQLite</p></td>
<td><p>2.2.0</p></td>
<td><p>rstudioapi</p></td>
<td><p>0.11</p></td>
<td><p>rversions</p></td>
<td><p>2.0.1</p></td>
</tr>
<tr class="row-even"><td><p>rvest</p></td>
<td><p>0.3.5</p></td>
<td><p>scales</p></td>
<td><p>1.1.0</p></td>
<td><p>selectr</p></td>
<td><p>0.4-2</p></td>
</tr>
<tr class="row-odd"><td><p>sessioninfo</p></td>
<td><p>1.1.1</p></td>
<td><p>shape</p></td>
<td><p>1.4.4</p></td>
<td><p>shiny</p></td>
<td><p>1.4.0.2</p></td>
</tr>
<tr class="row-even"><td><p>sourcetools</p></td>
<td><p>0.1.7</p></td>
<td><p>sparklyr</p></td>
<td><p>1.2.0</p></td>
<td><p>SparkR</p></td>
<td><p>3.0.0</p></td>
</tr>
<tr class="row-odd"><td><p>spatial</p></td>
<td><p>7.3-11</p></td>
<td><p>splines</p></td>
<td><p>3.6.3</p></td>
<td><p>sqldf</p></td>
<td><p>0.4-11</p></td>
</tr>
<tr class="row-even"><td><p>SQUAREM</p></td>
<td><p>2020.2</p></td>
<td><p>stats</p></td>
<td><p>3.6.3</p></td>
<td><p>stats4</p></td>
<td><p>3.6.3</p></td>
</tr>
<tr class="row-odd"><td><p>stringi</p></td>
<td><p>1.4.6</p></td>
<td><p>stringr</p></td>
<td><p>1.4.0</p></td>
<td><p>survival</p></td>
<td><p>3.1-12</p></td>
</tr>
<tr class="row-even"><td><p>sys</p></td>
<td><p>3.3</p></td>
<td><p>tcltk</p></td>
<td><p>3.6.3</p></td>
<td><p>TeachingDemos</p></td>
<td><p>2.10</p></td>
</tr>
<tr class="row-odd"><td><p>testthat</p></td>
<td><p>2.3.2</p></td>
<td><p>tibble</p></td>
<td><p>3.0.1</p></td>
<td><p>tidyr</p></td>
<td><p>1.0.2</p></td>
</tr>
<tr class="row-even"><td><p>tidyselect</p></td>
<td><p>1.0.0</p></td>
<td><p>tidyverse</p></td>
<td><p>1.3.0</p></td>
<td><p>timeDate</p></td>
<td><p>3043.102</p></td>
</tr>
<tr class="row-odd"><td><p>tinytex</p></td>
<td><p>0.22</p></td>
<td><p>tools</p></td>
<td><p>3.6.3</p></td>
<td><p>usethis</p></td>
<td><p>1.6.0</p></td>
</tr>
<tr class="row-even"><td><p>utf8</p></td>
<td><p>1.1.4</p></td>
<td><p>utils</p></td>
<td><p>3.6.3</p></td>
<td><p>vctrs</p></td>
<td><p>0.2.4</p></td>
</tr>
<tr class="row-odd"><td><p>viridisLite</p></td>
<td><p>0.3.0</p></td>
<td><p>whisker</p></td>
<td><p>0.4</p></td>
<td><p>withr</p></td>
<td><p>2.2.0</p></td>
</tr>
<tr class="row-even"><td><p>xfun</p></td>
<td><p>0.13</p></td>
<td><p>xml2</p></td>
<td><p>1.3.1</p></td>
<td><p>xopen</p></td>
<td><p>1.0.0</p></td>
</tr>
<tr class="row-odd"><td><p>xtable</p></td>
<td><p>1.8-4</p></td>
<td><p>yaml</p></td>
<td><p>2.2.1</p></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="installed-java-and-scala-libraries-scala-212-cluster-version">
<h3>Installed Java and Scala libraries (Scala 2.12 cluster version)<a class="headerlink" href="#installed-java-and-scala-libraries-scala-212-cluster-version" title="Permalink to this headline"> </a></h3>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Group ID</p></th>
<th class="head"><p>Artifact ID</p></th>
<th class="head"><p>Version</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>antlr</p></td>
<td><p>antlr</p></td>
<td><p>2.7.7</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>amazon-kinesis-client</p></td>
<td><p>1.12.0</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-autoscaling</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudformation</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudfront</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudhsm</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudsearch</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudtrail</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudwatch</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cloudwatchmetrics</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-codedeploy</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cognitoidentity</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-cognitosync</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-config</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-core</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-datapipeline</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-directconnect</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-directory</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-dynamodb</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-ec2</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-ecs</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-efs</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-elasticache</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-elasticbeanstalk</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-elasticloadbalancing</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-elastictranscoder</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-emr</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-glacier</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-iam</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-importexport</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-kinesis</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-kms</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-lambda</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-logs</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-machinelearning</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-opsworks</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-rds</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-redshift</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-route53</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-s3</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-ses</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-simpledb</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-simpleworkflow</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-sns</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-sqs</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-ssm</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-storagegateway</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-sts</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-support</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-swf-libraries</p></td>
<td><p>1.11.22</p></td>
</tr>
<tr class="row-even"><td><p>com.amazonaws</p></td>
<td><p>aws-java-sdk-workspaces</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-odd"><td><p>com.amazonaws</p></td>
<td><p>jmespath-java</p></td>
<td><p>1.11.655</p></td>
</tr>
<tr class="row-even"><td><p>com.chuusai</p></td>
<td><p>shapeless_2.12</p></td>
<td><p>2.3.3</p></td>
</tr>
<tr class="row-odd"><td><p>com.clearspring.analytics</p></td>
<td><p>stream</p></td>
<td><p>2.9.6</p></td>
</tr>
<tr class="row-even"><td><p>com.databricks</p></td>
<td><p>Rserve</p></td>
<td><p>1.8-3</p></td>
</tr>
<tr class="row-odd"><td><p>com.databricks</p></td>
<td><p>jets3t</p></td>
<td><p>0.7.1-0</p></td>
</tr>
<tr class="row-even"><td><p>com.databricks.scalapb</p></td>
<td><p>compilerplugin_2.12</p></td>
<td><p>0.4.15-10</p></td>
</tr>
<tr class="row-odd"><td><p>com.databricks.scalapb</p></td>
<td><p>scalapb-runtime_2.12</p></td>
<td><p>0.4.15-10</p></td>
</tr>
<tr class="row-even"><td><p>com.esotericsoftware</p></td>
<td><p>kryo-shaded</p></td>
<td><p>4.0.2</p></td>
</tr>
<tr class="row-odd"><td><p>com.esotericsoftware</p></td>
<td><p>minlog</p></td>
<td><p>1.3.0</p></td>
</tr>
<tr class="row-even"><td><p>com.fasterxml</p></td>
<td><p>classmate</p></td>
<td><p>1.3.4</p></td>
</tr>
<tr class="row-odd"><td><p>com.fasterxml.jackson.core</p></td>
<td><p>jackson-annotations</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-even"><td><p>com.fasterxml.jackson.core</p></td>
<td><p>jackson-core</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.fasterxml.jackson.core</p></td>
<td><p>jackson-databind</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-even"><td><p>com.fasterxml.jackson.dataformat</p></td>
<td><p>jackson-dataformat-cbor</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.fasterxml.jackson.datatype</p></td>
<td><p>jackson-datatype-joda</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-even"><td><p>com.fasterxml.jackson.module</p></td>
<td><p>jackson-module-paranamer</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.fasterxml.jackson.module</p></td>
<td><p>jackson-module-scala_2.12</p></td>
<td><p>2.10.0</p></td>
</tr>
<tr class="row-even"><td><p>com.github.ben-manes.caffeine</p></td>
<td><p>caffeine</p></td>
<td><p>2.3.4</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.fommil</p></td>
<td><p>jniloader</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-even"><td><p>com.github.fommil.netlib</p></td>
<td><p>core</p></td>
<td><p>1.1.2</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.fommil.netlib</p></td>
<td><p>native_ref-java</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-even"><td><p>com.github.fommil.netlib</p></td>
<td><p>native_ref-java-natives</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.fommil.netlib</p></td>
<td><p>native_system-java</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-even"><td><p>com.github.fommil.netlib</p></td>
<td><p>native_system-java-natives</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.fommil.netlib</p></td>
<td><p>netlib-native_ref-linux-x86_64-natives</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-even"><td><p>com.github.fommil.netlib</p></td>
<td><p>netlib-native_system-linux-x86_64-natives</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.joshelser</p></td>
<td><p>dropwizard-metrics-hadoop-metrics2-reporter</p></td>
<td><p>0.1.2</p></td>
</tr>
<tr class="row-even"><td><p>com.github.luben</p></td>
<td><p>zstd-jni</p></td>
<td><p>1.4.4-3</p></td>
</tr>
<tr class="row-odd"><td><p>com.github.wendykierp</p></td>
<td><p>JTransforms</p></td>
<td><p>3.1</p></td>
</tr>
<tr class="row-even"><td><p>com.google.code.findbugs</p></td>
<td><p>jsr305</p></td>
<td><p>3.0.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.google.code.gson</p></td>
<td><p>gson</p></td>
<td><p>2.2.4</p></td>
</tr>
<tr class="row-even"><td><p>com.google.flatbuffers</p></td>
<td><p>flatbuffers-java</p></td>
<td><p>1.9.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.google.guava</p></td>
<td><p>guava</p></td>
<td><p>15.0</p></td>
</tr>
<tr class="row-even"><td><p>com.google.protobuf</p></td>
<td><p>protobuf-java</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-odd"><td><p>com.h2database</p></td>
<td><p>h2</p></td>
<td><p>1.4.195</p></td>
</tr>
<tr class="row-even"><td><p>com.helger</p></td>
<td><p>profiler</p></td>
<td><p>1.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>com.jcraft</p></td>
<td><p>jsch</p></td>
<td><p>0.1.50</p></td>
</tr>
<tr class="row-even"><td><p>com.jolbox</p></td>
<td><p>bonecp</p></td>
<td><p>0.8.0.RELEASE</p></td>
</tr>
<tr class="row-odd"><td><p>com.microsoft.azure</p></td>
<td><p>azure-data-lake-store-sdk</p></td>
<td><p>2.2.8</p></td>
</tr>
<tr class="row-even"><td><p>com.microsoft.sqlserver</p></td>
<td><p>mssql-jdbc</p></td>
<td><p>8.2.1.jre8</p></td>
</tr>
<tr class="row-odd"><td><p>com.ning</p></td>
<td><p>compress-lzf</p></td>
<td><p>1.0.3</p></td>
</tr>
<tr class="row-even"><td><p>com.sun.mail</p></td>
<td><p>javax.mail</p></td>
<td><p>1.5.2</p></td>
</tr>
<tr class="row-odd"><td><p>com.tdunning</p></td>
<td><p>json</p></td>
<td><p>1.8</p></td>
</tr>
<tr class="row-even"><td><p>com.thoughtworks.paranamer</p></td>
<td><p>paranamer</p></td>
<td><p>2.8</p></td>
</tr>
<tr class="row-odd"><td><p>com.trueaccord.lenses</p></td>
<td><p>lenses_2.12</p></td>
<td><p>0.4.12</p></td>
</tr>
<tr class="row-even"><td><p>com.twitter</p></td>
<td><p>chill-java</p></td>
<td><p>0.9.5</p></td>
</tr>
<tr class="row-odd"><td><p>com.twitter</p></td>
<td><p>chill_2.12</p></td>
<td><p>0.9.5</p></td>
</tr>
<tr class="row-even"><td><p>com.twitter</p></td>
<td><p>util-app_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.twitter</p></td>
<td><p>util-core_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-even"><td><p>com.twitter</p></td>
<td><p>util-function_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.twitter</p></td>
<td><p>util-jvm_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-even"><td><p>com.twitter</p></td>
<td><p>util-lint_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.twitter</p></td>
<td><p>util-registry_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-even"><td><p>com.twitter</p></td>
<td><p>util-stats_2.12</p></td>
<td><p>7.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>com.typesafe</p></td>
<td><p>config</p></td>
<td><p>1.2.1</p></td>
</tr>
<tr class="row-even"><td><p>com.typesafe.scala-logging</p></td>
<td><p>scala-logging_2.12</p></td>
<td><p>3.7.2</p></td>
</tr>
<tr class="row-odd"><td><p>com.univocity</p></td>
<td><p>univocity-parsers</p></td>
<td><p>2.8.3</p></td>
</tr>
<tr class="row-even"><td><p>com.zaxxer</p></td>
<td><p>HikariCP</p></td>
<td><p>3.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>commons-beanutils</p></td>
<td><p>commons-beanutils</p></td>
<td><p>1.9.4</p></td>
</tr>
<tr class="row-even"><td><p>commons-cli</p></td>
<td><p>commons-cli</p></td>
<td><p>1.2</p></td>
</tr>
<tr class="row-odd"><td><p>commons-codec</p></td>
<td><p>commons-codec</p></td>
<td><p>1.10</p></td>
</tr>
<tr class="row-even"><td><p>commons-collections</p></td>
<td><p>commons-collections</p></td>
<td><p>3.2.2</p></td>
</tr>
<tr class="row-odd"><td><p>commons-configuration</p></td>
<td><p>commons-configuration</p></td>
<td><p>1.6</p></td>
</tr>
<tr class="row-even"><td><p>commons-dbcp</p></td>
<td><p>commons-dbcp</p></td>
<td><p>1.4</p></td>
</tr>
<tr class="row-odd"><td><p>commons-digester</p></td>
<td><p>commons-digester</p></td>
<td><p>1.8</p></td>
</tr>
<tr class="row-even"><td><p>commons-fileupload</p></td>
<td><p>commons-fileupload</p></td>
<td><p>1.3.3</p></td>
</tr>
<tr class="row-odd"><td><p>commons-httpclient</p></td>
<td><p>commons-httpclient</p></td>
<td><p>3.1</p></td>
</tr>
<tr class="row-even"><td><p>commons-io</p></td>
<td><p>commons-io</p></td>
<td><p>2.4</p></td>
</tr>
<tr class="row-odd"><td><p>commons-lang</p></td>
<td><p>commons-lang</p></td>
<td><p>2.6</p></td>
</tr>
<tr class="row-even"><td><p>commons-logging</p></td>
<td><p>commons-logging</p></td>
<td><p>1.1.3</p></td>
</tr>
<tr class="row-odd"><td><p>commons-net</p></td>
<td><p>commons-net</p></td>
<td><p>3.1</p></td>
</tr>
<tr class="row-even"><td><p>commons-pool</p></td>
<td><p>commons-pool</p></td>
<td><p>1.5.4</p></td>
</tr>
<tr class="row-odd"><td><p>info.ganglia.gmetric4j</p></td>
<td><p>gmetric4j</p></td>
<td><p>1.0.10</p></td>
</tr>
<tr class="row-even"><td><p>io.airlift</p></td>
<td><p>aircompressor</p></td>
<td><p>0.10</p></td>
</tr>
<tr class="row-odd"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-core</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-even"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-graphite</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-healthchecks</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-even"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-jetty9</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-jmx</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-even"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-json</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-jvm</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-even"><td><p>io.dropwizard.metrics</p></td>
<td><p>metrics-servlets</p></td>
<td><p>4.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>io.netty</p></td>
<td><p>netty-all</p></td>
<td><p>4.1.47.Final</p></td>
</tr>
<tr class="row-even"><td><p>jakarta.annotation</p></td>
<td><p>jakarta.annotation-api</p></td>
<td><p>1.3.5</p></td>
</tr>
<tr class="row-odd"><td><p>jakarta.validation</p></td>
<td><p>jakarta.validation-api</p></td>
<td><p>2.0.2</p></td>
</tr>
<tr class="row-even"><td><p>jakarta.ws.rs</p></td>
<td><p>jakarta.ws.rs-api</p></td>
<td><p>2.1.6</p></td>
</tr>
<tr class="row-odd"><td><p>javax.activation</p></td>
<td><p>activation</p></td>
<td><p>1.1.1</p></td>
</tr>
<tr class="row-even"><td><p>javax.el</p></td>
<td><p>javax.el-api</p></td>
<td><p>2.2.4</p></td>
</tr>
<tr class="row-odd"><td><p>javax.jdo</p></td>
<td><p>jdo-api</p></td>
<td><p>3.0.1</p></td>
</tr>
<tr class="row-even"><td><p>javax.servlet</p></td>
<td><p>javax.servlet-api</p></td>
<td><p>3.1.0</p></td>
</tr>
<tr class="row-odd"><td><p>javax.servlet.jsp</p></td>
<td><p>jsp-api</p></td>
<td><p>2.1</p></td>
</tr>
<tr class="row-even"><td><p>javax.transaction</p></td>
<td><p>jta</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>javax.transaction</p></td>
<td><p>transaction-api</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-even"><td><p>javax.xml.bind</p></td>
<td><p>jaxb-api</p></td>
<td><p>2.2.2</p></td>
</tr>
<tr class="row-odd"><td><p>javax.xml.stream</p></td>
<td><p>stax-api</p></td>
<td><p>1.0-2</p></td>
</tr>
<tr class="row-even"><td><p>javolution</p></td>
<td><p>javolution</p></td>
<td><p>5.5.1</p></td>
</tr>
<tr class="row-odd"><td><p>jline</p></td>
<td><p>jline</p></td>
<td><p>2.14.6</p></td>
</tr>
<tr class="row-even"><td><p>joda-time</p></td>
<td><p>joda-time</p></td>
<td><p>2.10.5</p></td>
</tr>
<tr class="row-odd"><td><p>log4j</p></td>
<td><p>apache-log4j-extras</p></td>
<td><p>1.2.17</p></td>
</tr>
<tr class="row-even"><td><p>log4j</p></td>
<td><p>log4j</p></td>
<td><p>1.2.17</p></td>
</tr>
<tr class="row-odd"><td><p>net.razorvine</p></td>
<td><p>pyrolite</p></td>
<td><p>4.30</p></td>
</tr>
<tr class="row-even"><td><p>net.sf.jpam</p></td>
<td><p>jpam</p></td>
<td><p>1.1</p></td>
</tr>
<tr class="row-odd"><td><p>net.sf.opencsv</p></td>
<td><p>opencsv</p></td>
<td><p>2.3</p></td>
</tr>
<tr class="row-even"><td><p>net.sf.supercsv</p></td>
<td><p>super-csv</p></td>
<td><p>2.2.0</p></td>
</tr>
<tr class="row-odd"><td><p>net.snowflake</p></td>
<td><p>snowflake-ingest-sdk</p></td>
<td><p>0.9.6</p></td>
</tr>
<tr class="row-even"><td><p>net.snowflake</p></td>
<td><p>snowflake-jdbc</p></td>
<td><p>3.12.0</p></td>
</tr>
<tr class="row-odd"><td><p>net.snowflake</p></td>
<td><p>spark-snowflake_2.12</p></td>
<td><p>2.5.9-spark_2.4</p></td>
</tr>
<tr class="row-even"><td><p>net.sourceforge.f2j</p></td>
<td><p>arpack_combined_all</p></td>
<td><p>0.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.acplt.remotetea</p></td>
<td><p>remotetea-oncrpc</p></td>
<td><p>1.1.2</p></td>
</tr>
<tr class="row-even"><td><p>org.antlr</p></td>
<td><p>ST4</p></td>
<td><p>4.0.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.antlr</p></td>
<td><p>antlr-runtime</p></td>
<td><p>3.5.2</p></td>
</tr>
<tr class="row-even"><td><p>org.antlr</p></td>
<td><p>antlr4-runtime</p></td>
<td><p>4.7.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.antlr</p></td>
<td><p>stringtemplate</p></td>
<td><p>3.2.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.ant</p></td>
<td><p>ant</p></td>
<td><p>1.9.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.ant</p></td>
<td><p>ant-jsch</p></td>
<td><p>1.9.2</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.ant</p></td>
<td><p>ant-launcher</p></td>
<td><p>1.9.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.arrow</p></td>
<td><p>arrow-format</p></td>
<td><p>0.15.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.arrow</p></td>
<td><p>arrow-memory</p></td>
<td><p>0.15.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.arrow</p></td>
<td><p>arrow-vector</p></td>
<td><p>0.15.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.avro</p></td>
<td><p>avro</p></td>
<td><p>1.8.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.avro</p></td>
<td><p>avro-ipc</p></td>
<td><p>1.8.2</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.avro</p></td>
<td><p>avro-mapred-hadoop2</p></td>
<td><p>1.8.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.commons</p></td>
<td><p>commons-compress</p></td>
<td><p>1.8.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.commons</p></td>
<td><p>commons-crypto</p></td>
<td><p>1.0.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.commons</p></td>
<td><p>commons-lang3</p></td>
<td><p>3.9</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.commons</p></td>
<td><p>commons-math3</p></td>
<td><p>3.4.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.commons</p></td>
<td><p>commons-text</p></td>
<td><p>1.6</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.curator</p></td>
<td><p>curator-client</p></td>
<td><p>2.7.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.curator</p></td>
<td><p>curator-framework</p></td>
<td><p>2.7.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.curator</p></td>
<td><p>curator-recipes</p></td>
<td><p>2.7.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.derby</p></td>
<td><p>derby</p></td>
<td><p>10.12.1.1</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.directory.api</p></td>
<td><p>api-asn1-api</p></td>
<td><p>1.0.0-M20</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.directory.api</p></td>
<td><p>api-util</p></td>
<td><p>1.0.0-M20</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.directory.server</p></td>
<td><p>apacheds-i18n</p></td>
<td><p>2.0.0-M15</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.directory.server</p></td>
<td><p>apacheds-kerberos-codec</p></td>
<td><p>2.0.0-M15</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-annotations</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-auth</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-client</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-common</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-hdfs</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-mapreduce-client-app</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-mapreduce-client-common</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-mapreduce-client-core</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-mapreduce-client-jobclient</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-mapreduce-client-shuffle</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-yarn-api</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-yarn-client</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-yarn-common</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hadoop</p></td>
<td><p>hadoop-yarn-server-common</p></td>
<td><p>2.7.4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-beeline</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-cli</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-common</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-exec-core</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-jdbc</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-llap-client</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-llap-common</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-metastore</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-serde</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-shims</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive</p></td>
<td><p>hive-storage-api</p></td>
<td><p>2.7.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive</p></td>
<td><p>hive-vector-code-gen</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive.shims</p></td>
<td><p>hive-shims-0.23</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.hive.shims</p></td>
<td><p>hive-shims-common</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.hive.shims</p></td>
<td><p>hive-shims-scheduler</p></td>
<td><p>2.3.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.htrace</p></td>
<td><p>htrace-core</p></td>
<td><p>3.1.0-incubating</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.httpcomponents</p></td>
<td><p>httpclient</p></td>
<td><p>4.5.6</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.httpcomponents</p></td>
<td><p>httpcore</p></td>
<td><p>4.4.12</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.ivy</p></td>
<td><p>ivy</p></td>
<td><p>2.4.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.orc</p></td>
<td><p>orc-core</p></td>
<td><p>1.5.10</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.orc</p></td>
<td><p>orc-mapreduce</p></td>
<td><p>1.5.10</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.orc</p></td>
<td><p>orc-shims</p></td>
<td><p>1.5.10</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.parquet</p></td>
<td><p>parquet-column</p></td>
<td><p>1.10.1.2-databricks4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.parquet</p></td>
<td><p>parquet-common</p></td>
<td><p>1.10.1.2-databricks4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.parquet</p></td>
<td><p>parquet-encoding</p></td>
<td><p>1.10.1.2-databricks4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.parquet</p></td>
<td><p>parquet-format</p></td>
<td><p>2.4.0</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.parquet</p></td>
<td><p>parquet-hadoop</p></td>
<td><p>1.10.1.2-databricks4</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.parquet</p></td>
<td><p>parquet-jackson</p></td>
<td><p>1.10.1.2-databricks4</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.thrift</p></td>
<td><p>libfb303</p></td>
<td><p>0.9.3</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.thrift</p></td>
<td><p>libthrift</p></td>
<td><p>0.12.0</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.velocity</p></td>
<td><p>velocity</p></td>
<td><p>1.5</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.xbean</p></td>
<td><p>xbean-asm7-shaded</p></td>
<td><p>4.15</p></td>
</tr>
<tr class="row-even"><td><p>org.apache.yetus</p></td>
<td><p>audience-annotations</p></td>
<td><p>0.5.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.apache.zookeeper</p></td>
<td><p>zookeeper</p></td>
<td><p>3.4.14</p></td>
</tr>
<tr class="row-even"><td><p>org.codehaus.jackson</p></td>
<td><p>jackson-core-asl</p></td>
<td><p>1.9.13</p></td>
</tr>
<tr class="row-odd"><td><p>org.codehaus.jackson</p></td>
<td><p>jackson-jaxrs</p></td>
<td><p>1.9.13</p></td>
</tr>
<tr class="row-even"><td><p>org.codehaus.jackson</p></td>
<td><p>jackson-mapper-asl</p></td>
<td><p>1.9.13</p></td>
</tr>
<tr class="row-odd"><td><p>org.codehaus.jackson</p></td>
<td><p>jackson-xc</p></td>
<td><p>1.9.13</p></td>
</tr>
<tr class="row-even"><td><p>org.codehaus.janino</p></td>
<td><p>commons-compiler</p></td>
<td><p>3.0.16</p></td>
</tr>
<tr class="row-odd"><td><p>org.codehaus.janino</p></td>
<td><p>janino</p></td>
<td><p>3.0.16</p></td>
</tr>
<tr class="row-even"><td><p>org.datanucleus</p></td>
<td><p>datanucleus-api-jdo</p></td>
<td><p>4.2.4</p></td>
</tr>
<tr class="row-odd"><td><p>org.datanucleus</p></td>
<td><p>datanucleus-core</p></td>
<td><p>4.1.17</p></td>
</tr>
<tr class="row-even"><td><p>org.datanucleus</p></td>
<td><p>datanucleus-rdbms</p></td>
<td><p>4.1.19</p></td>
</tr>
<tr class="row-odd"><td><p>org.datanucleus</p></td>
<td><p>javax.jdo</p></td>
<td><p>3.2.0-m3</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-client</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-continuation</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-http</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-io</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-jndi</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-plus</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-proxy</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-security</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-server</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-servlet</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-servlets</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-util</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-webapp</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-odd"><td><p>org.eclipse.jetty</p></td>
<td><p>jetty-xml</p></td>
<td><p>9.4.18.v20190429</p></td>
</tr>
<tr class="row-even"><td><p>org.fusesource.leveldbjni</p></td>
<td><p>leveldbjni-all</p></td>
<td><p>1.8</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.hk2</p></td>
<td><p>hk2-api</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.hk2</p></td>
<td><p>hk2-locator</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.hk2</p></td>
<td><p>hk2-utils</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.hk2</p></td>
<td><p>osgi-resource-locator</p></td>
<td><p>1.0.3</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.hk2.external</p></td>
<td><p>aopalliance-repackaged</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.hk2.external</p></td>
<td><p>jakarta.inject</p></td>
<td><p>2.6.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.jersey.containers</p></td>
<td><p>jersey-container-servlet</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.jersey.containers</p></td>
<td><p>jersey-container-servlet-core</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.jersey.core</p></td>
<td><p>jersey-client</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.jersey.core</p></td>
<td><p>jersey-common</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.jersey.core</p></td>
<td><p>jersey-server</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-even"><td><p>org.glassfish.jersey.inject</p></td>
<td><p>jersey-hk2</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-odd"><td><p>org.glassfish.jersey.media</p></td>
<td><p>jersey-media-jaxb</p></td>
<td><p>2.30</p></td>
</tr>
<tr class="row-even"><td><p>org.hibernate.validator</p></td>
<td><p>hibernate-validator</p></td>
<td><p>6.1.0.Final</p></td>
</tr>
<tr class="row-odd"><td><p>org.javassist</p></td>
<td><p>javassist</p></td>
<td><p>3.25.0-GA</p></td>
</tr>
<tr class="row-even"><td><p>org.jboss.logging</p></td>
<td><p>jboss-logging</p></td>
<td><p>3.3.2.Final</p></td>
</tr>
<tr class="row-odd"><td><p>org.jdbi</p></td>
<td><p>jdbi</p></td>
<td><p>2.63.1</p></td>
</tr>
<tr class="row-even"><td><p>org.joda</p></td>
<td><p>joda-convert</p></td>
<td><p>1.7</p></td>
</tr>
<tr class="row-odd"><td><p>org.jodd</p></td>
<td><p>jodd-core</p></td>
<td><p>3.5.2</p></td>
</tr>
<tr class="row-even"><td><p>org.json4s</p></td>
<td><p>json4s-ast_2.12</p></td>
<td><p>3.6.6</p></td>
</tr>
<tr class="row-odd"><td><p>org.json4s</p></td>
<td><p>json4s-core_2.12</p></td>
<td><p>3.6.6</p></td>
</tr>
<tr class="row-even"><td><p>org.json4s</p></td>
<td><p>json4s-jackson_2.12</p></td>
<td><p>3.6.6</p></td>
</tr>
<tr class="row-odd"><td><p>org.json4s</p></td>
<td><p>json4s-scalap_2.12</p></td>
<td><p>3.6.6</p></td>
</tr>
<tr class="row-even"><td><p>org.lz4</p></td>
<td><p>lz4-java</p></td>
<td><p>1.7.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.mariadb.jdbc</p></td>
<td><p>mariadb-java-client</p></td>
<td><p>2.1.2</p></td>
</tr>
<tr class="row-even"><td><p>org.objenesis</p></td>
<td><p>objenesis</p></td>
<td><p>2.5.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.postgresql</p></td>
<td><p>postgresql</p></td>
<td><p>42.1.4</p></td>
</tr>
<tr class="row-even"><td><p>org.roaringbitmap</p></td>
<td><p>RoaringBitmap</p></td>
<td><p>0.7.45</p></td>
</tr>
<tr class="row-odd"><td><p>org.roaringbitmap</p></td>
<td><p>shims</p></td>
<td><p>0.7.45</p></td>
</tr>
<tr class="row-even"><td><p>org.rocksdb</p></td>
<td><p>rocksdbjni</p></td>
<td><p>6.2.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.rosuda.REngine</p></td>
<td><p>REngine</p></td>
<td><p>2.1.0</p></td>
</tr>
<tr class="row-even"><td><p>org.scala-lang</p></td>
<td><p>scala-compiler_2.12</p></td>
<td><p>2.12.10</p></td>
</tr>
<tr class="row-odd"><td><p>org.scala-lang</p></td>
<td><p>scala-library_2.12</p></td>
<td><p>2.12.10</p></td>
</tr>
<tr class="row-even"><td><p>org.scala-lang</p></td>
<td><p>scala-reflect_2.12</p></td>
<td><p>2.12.10</p></td>
</tr>
<tr class="row-odd"><td><p>org.scala-lang.modules</p></td>
<td><p>scala-collection-compat_2.12</p></td>
<td><p>2.1.1</p></td>
</tr>
<tr class="row-even"><td><p>org.scala-lang.modules</p></td>
<td><p>scala-parser-combinators_2.12</p></td>
<td><p>1.1.2</p></td>
</tr>
<tr class="row-odd"><td><p>org.scala-lang.modules</p></td>
<td><p>scala-xml_2.12</p></td>
<td><p>1.2.0</p></td>
</tr>
<tr class="row-even"><td><p>org.scala-sbt</p></td>
<td><p>test-interface</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.scalacheck</p></td>
<td><p>scalacheck_2.12</p></td>
<td><p>1.14.2</p></td>
</tr>
<tr class="row-even"><td><p>org.scalactic</p></td>
<td><p>scalactic_2.12</p></td>
<td><p>3.0.8</p></td>
</tr>
<tr class="row-odd"><td><p>org.scalanlp</p></td>
<td><p>breeze-macros_2.12</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-even"><td><p>org.scalanlp</p></td>
<td><p>breeze_2.12</p></td>
<td><p>1.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.scalatest</p></td>
<td><p>scalatest_2.12</p></td>
<td><p>3.0.8</p></td>
</tr>
<tr class="row-even"><td><p>org.slf4j</p></td>
<td><p>jcl-over-slf4j</p></td>
<td><p>1.7.30</p></td>
</tr>
<tr class="row-odd"><td><p>org.slf4j</p></td>
<td><p>jul-to-slf4j</p></td>
<td><p>1.7.30</p></td>
</tr>
<tr class="row-even"><td><p>org.slf4j</p></td>
<td><p>slf4j-api</p></td>
<td><p>1.7.30</p></td>
</tr>
<tr class="row-odd"><td><p>org.slf4j</p></td>
<td><p>slf4j-log4j12</p></td>
<td><p>1.7.30</p></td>
</tr>
<tr class="row-even"><td><p>org.spark-project.spark</p></td>
<td><p>unused</p></td>
<td><p>1.0.0</p></td>
</tr>
<tr class="row-odd"><td><p>org.springframework</p></td>
<td><p>spring-core</p></td>
<td><p>4.1.4.RELEASE</p></td>
</tr>
<tr class="row-even"><td><p>org.springframework</p></td>
<td><p>spring-test</p></td>
<td><p>4.1.4.RELEASE</p></td>
</tr>
<tr class="row-odd"><td><p>org.threeten</p></td>
<td><p>threeten-extra</p></td>
<td><p>1.5.0</p></td>
</tr>
<tr class="row-even"><td><p>org.tukaani</p></td>
<td><p>xz</p></td>
<td><p>1.5</p></td>
</tr>
<tr class="row-odd"><td><p>org.typelevel</p></td>
<td><p>algebra_2.12</p></td>
<td><p>2.0.0-M2</p></td>
</tr>
<tr class="row-even"><td><p>org.typelevel</p></td>
<td><p>cats-kernel_2.12</p></td>
<td><p>2.0.0-M4</p></td>
</tr>
<tr class="row-odd"><td><p>org.typelevel</p></td>
<td><p>machinist_2.12</p></td>
<td><p>0.6.8</p></td>
</tr>
<tr class="row-even"><td><p>org.typelevel</p></td>
<td><p>macro-compat_2.12</p></td>
<td><p>1.1.1</p></td>
</tr>
<tr class="row-odd"><td><p>org.typelevel</p></td>
<td><p>spire-macros_2.12</p></td>
<td><p>0.17.0-M1</p></td>
</tr>
<tr class="row-even"><td><p>org.typelevel</p></td>
<td><p>spire-platform_2.12</p></td>
<td><p>0.17.0-M1</p></td>
</tr>
<tr class="row-odd"><td><p>org.typelevel</p></td>
<td><p>spire-util_2.12</p></td>
<td><p>0.17.0-M1</p></td>
</tr>
<tr class="row-even"><td><p>org.typelevel</p></td>
<td><p>spire_2.12</p></td>
<td><p>0.17.0-M1</p></td>
</tr>
<tr class="row-odd"><td><p>org.xerial</p></td>
<td><p>sqlite-jdbc</p></td>
<td><p>3.8.11.2</p></td>
</tr>
<tr class="row-even"><td><p>org.xerial.snappy</p></td>
<td><p>snappy-java</p></td>
<td><p>1.1.7.5</p></td>
</tr>
<tr class="row-odd"><td><p>org.yaml</p></td>
<td><p>snakeyaml</p></td>
<td><p>1.24</p></td>
</tr>
<tr class="row-even"><td><p>oro</p></td>
<td><p>oro</p></td>
<td><p>2.0.8</p></td>
</tr>
<tr class="row-odd"><td><p>pl.edu.icm</p></td>
<td><p>JLargeArrays</p></td>
<td><p>1.5</p></td>
</tr>
<tr class="row-even"><td><p>software.amazon.ion</p></td>
<td><p>ion-java</p></td>
<td><p>1.0.2</p></td>
</tr>
<tr class="row-odd"><td><p>stax</p></td>
<td><p>stax-api</p></td>
<td><p>1.0.1</p></td>
</tr>
<tr class="row-even"><td><p>xmlenc</p></td>
<td><p>xmlenc</p></td>
<td><p>0.52</p></td>
</tr>
</tbody>
</table>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>