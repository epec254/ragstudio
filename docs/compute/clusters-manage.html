

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to manage Databricks clusters, including displaying, editing, starting, terminating, deleting, controlling access, and monitoring performance and logs." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Manage clusters">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Manage clusters &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/compute/clusters-manage.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/compute/clusters-manage.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/compute/clusters-manage.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/compute/clusters-manage.html" class="notranslate">English</option>
    <option value="../../ja/compute/clusters-manage.html" class="notranslate">日本語</option>
    <option value="../../pt/compute/clusters-manage.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Manage clusters</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="manage-clusters">
<h1>Manage clusters<a class="headerlink" href="#manage-clusters" title="Permalink to this headline"> </a></h1>
<p>This article describes how to manage Databricks clusters, including displaying, editing, starting, terminating, deleting, controlling access, and monitoring performance and logs.</p>
<div class="section" id="display-clusters">
<span id="cluster-list"></span><h2>Display clusters<a class="headerlink" href="#display-clusters" title="Permalink to this headline"> </a></h2>
<p>To view the clusters in your workspace, click <img alt="compute icon" src="../_images/clusters-icon.png" /> <strong>Compute</strong> in the sidebar.</p>
<p>On the left side are two columns indicating if the cluster has been pinned and the status of the cluster. Hover over the status to get more information.</p>
</div>
<div class="section" id="pin-a-cluster">
<span id="cluster-pin"></span><h2>Pin a cluster<a class="headerlink" href="#pin-a-cluster" title="Permalink to this headline"> </a></h2>
<p>30 days after a cluster is terminated, it is permanently deleted. To keep an all-purpose cluster configuration after a cluster has been <a class="reference internal" href="#cluster-terminate"><span class="std std-ref">terminated</span></a> for more than 30 days, an administrator can pin the cluster. Up to 100 clusters can be pinned.</p>
<p>Admins can pin a cluster from the cluster list or the cluster detail page by clicking the pin icon.</p>
<p>You can also invoke the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a> endpoint to pin a cluster programmatically.</p>
</div>
<div class="section" id="view-a-cluster-configuration-as-a-json-file">
<span id="cluster-json"></span><h2>View a cluster configuration as a JSON file<a class="headerlink" href="#view-a-cluster-configuration-as-a-json-file" title="Permalink to this headline"> </a></h2>
<p>Sometimes it can be helpful to view your cluster configuration as JSON. This is especially useful when you want to create similar clusters using the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a>. When you view an existing cluster, go to the <strong>Configuration</strong> tab, click <strong>JSON</strong> in the top right of the tab, copy the JSON, and paste it into your API call. JSON view is read-only.</p>
</div>
<div class="section" id="edit-a-cluster">
<span id="editing-clusters"></span><h2>Edit a cluster<a class="headerlink" href="#edit-a-cluster" title="Permalink to this headline"> </a></h2>
<p>You can edit a cluster configuration from the cluster details UI. You can also invoke the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a> endpoint to edit the cluster programmatically.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Notebooks and jobs that were attached to the cluster remain attached after editing.</p></li>
<li><p>Libraries installed on the cluster remain installed after editing.</p></li>
<li><p>If you edit any attribute of a running cluster (except for the cluster size and permissions), you must restart it. This can disrupt users who are currently using the cluster.</p></li>
<li><p>You can only edit running or terminated clusters. You can, however, update <em>permissions</em> for clusters that are not in those states, on the cluster details page.</p></li>
</ul>
</div>
</div>
<div class="section" id="clone-a-cluster">
<span id="cluster-clone"></span><h2>Clone a cluster<a class="headerlink" href="#clone-a-cluster" title="Permalink to this headline"> </a></h2>
<p>To clone an existing cluster, select <strong>Clone</strong> from the cluster’s <img alt="Kebab menu" src="../_images/kebab-menu.png" /> kebab menu (also known as the three-dot menu).</p>
<p>After you select clone, the cluster creation UI opens pre-populated with the cluster configuration. The following attributes are not included in the clone:</p>
<ul class="simple">
<li><p>Cluster permissions</p></li>
<li><p>Installed libraries</p></li>
<li><p>Attached notebooks</p></li>
</ul>
</div>
<div class="section" id="control-access-to-clusters">
<span id="cluster-permissions"></span><h2>Control access to clusters<a class="headerlink" href="#control-access-to-clusters" title="Permalink to this headline"> </a></h2>
<p>Cluster access control allows workspace admins to give fine-grained cluster access to other users. There are two types of cluster access control:</p>
<ul class="simple">
<li><p>Cluster-creation permission: Workspace admins can choose which users are allowed to create clusters.</p></li>
<li><p>Cluster-level permissions: A user who has the <strong>Can manage</strong> permission for a cluster can configure whether other users can attach to, restart, resize, and manage that cluster.</p></li>
</ul>
<p>To edit permissions for a cluster, select <strong>Edit Permissions</strong> from that cluster’s <img alt="Kebab menu" src="../_images/kebab-menu.png" /> kebab menu.</p>
<p>For more on cluster access control and cluster-level permissions, see <a class="reference internal" href="../security/auth-authz/access-control/cluster-acl.html"><span class="doc">Cluster access control</span></a>.</p>
</div>
<div class="section" id="terminate-a-cluster">
<span id="cluster-terminate"></span><h2>Terminate a cluster<a class="headerlink" href="#terminate-a-cluster" title="Permalink to this headline"> </a></h2>
<p>To save cluster resources, you can terminate a cluster. The terminated cluster’s configuration is stored so that it can be <a class="reference internal" href="#cluster-start"><span class="std std-ref">reused</span></a> (or, in the case of jobs, <a class="reference internal" href="#autostart-clusters"><span class="std std-ref">autostarted</span></a>) at a later time. You can manually terminate a cluster or configure the cluster to terminate automatically after a specified period of inactivity. When the number of terminated clusters exceeds 150, the oldest clusters are deleted.</p>
<p>Unless a cluster is <a class="reference internal" href="#pin-a-cluster"><span class="std std-ref">pinned</span></a> or restarted, it is automatically and permanently deleted 30 days after termination.</p>
<p>Terminated clusters appear in the cluster list with a gray circle at the left of the cluster name.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When you run a <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">job</span></a> on a <em>New Job Cluster</em> (which is usually recommended), the cluster terminates and is unavailable for restarting when the job is complete. On the other hand, if you schedule a job to run on an <em>Existing All-Purpose Cluster</em> that has been terminated, that cluster will <a class="reference internal" href="#autostart-clusters"><span class="std std-ref">autostart</span></a>.</p>
</div>
<div class="section" id="manual-termination">
<h3>Manual termination<a class="headerlink" href="#manual-termination" title="Permalink to this headline"> </a></h3>
<p>You can manually terminate a cluster from the cluster list (by clicking the square on the cluster’s row) or the cluster detail page (by clicking <strong>Terminate</strong>).</p>
</div>
<div class="section" id="automatic-termination">
<h3>Automatic termination<a class="headerlink" href="#automatic-termination" title="Permalink to this headline"> </a></h3>
<p>You can also set auto termination for a cluster. During cluster creation, you can specify an inactivity period in minutes after which you want the cluster to terminate.</p>
<p>If the difference between the current time and the last command run on the cluster is more than the inactivity period specified, Databricks automatically terminates that cluster.</p>
<p>A cluster is considered inactive when all commands on the cluster, including Spark jobs, Structured Streaming, and JDBC calls, have finished executing. This does not include commands run by SSH-ing into the cluster and running bash commands.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<ul class="simple">
<li><p>Clusters do not report activity resulting from the use of DStreams. This means that an auto-terminating cluster may be terminated while it is running DStreams. Turn off auto termination for clusters running DStreams or consider using Structured Streaming.</p></li>
<li><p>The auto termination feature monitors only Spark jobs, not user-defined local processes. Therefore, if all Spark jobs have completed, a cluster may be terminated, even if local processes are running.</p></li>
<li><p>Idle clusters continue to accumulate DBU and cloud instance charges during the inactivity period before termination.</p></li>
</ul>
</div>
<div class="section" id="configure-automatic-termination">
<h4>Configure automatic termination<a class="headerlink" href="#configure-automatic-termination" title="Permalink to this headline"> </a></h4>
<p>You can configure automatic termination in the create cluster UI. Ensure that the box is checked, and enter the number of minutes in the  <strong>Terminate after ___ of minutes of inactivity</strong> setting.</p>
<p>You can opt out of auto termination by clearing the Auto Termination checkbox or by specifying an inactivity period of <code class="docutils literal notranslate"><span class="pre">0</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Auto termination is best supported in the latest Spark versions. Older Spark versions have known limitations which can result in inaccurate reporting of cluster activity. For example, clusters running JDBC, R, or streaming commands can report a stale activity time that leads to premature cluster termination. Please upgrade to the most recent Spark version to benefit from bug fixes and improvements to auto termination.</p>
</div>
</div>
</div>
<div class="section" id="unexpected-termination">
<span id="automatic-termination"></span><h3>Unexpected termination<a class="headerlink" href="#unexpected-termination" title="Permalink to this headline"> </a></h3>
<p>Sometimes a cluster is terminated unexpectedly, not as a result of a manual termination or a configured automatic termination.</p>
<p>For a list of termination reasons and remediation steps, see the <a class="reference external" href="https://kb.databricks.com/clusters/termination-reasons.html">Knowledge Base</a>.</p>
</div>
</div>
<div class="section" id="delete-a-cluster">
<span id="cluster-delete"></span><h2>Delete a cluster<a class="headerlink" href="#delete-a-cluster" title="Permalink to this headline"> </a></h2>
<p>Deleting a cluster terminates the cluster and removes its configuration. To delete a cluster, select <strong>Delete</strong> from the cluster’s <img alt="Kebab menu" src="../_images/kebab-menu.png" /> menu.</p>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>You cannot undo this action.</p>
</div>
<p>To delete a pinned cluster, it must first be unpinned by an administrator.</p>
<p>You can also invoke the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a> endpoint to delete a cluster programmatically.</p>
</div>
<div class="section" id="restart-a-cluster">
<span id="cluster-start"></span><h2>Restart a cluster<a class="headerlink" href="#restart-a-cluster" title="Permalink to this headline"> </a></h2>
<p>You can restart a previously terminated cluster from the cluster list, the cluster detail page, or a notebook. You can also invoke the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a> endpoint to start a cluster programmatically.</p>
<p>Databricks identifies a cluster using its unique <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">cluster ID</a>. When you start a terminated cluster, Databricks re-creates the cluster with the same ID, automatically installs all the libraries, and reattaches the notebooks.</p>
<div class="section" id="restart-a-cluster-to-update-it-with-the-latest-images">
<h3>Restart a cluster to update it with the latest images<a class="headerlink" href="#restart-a-cluster-to-update-it-with-the-latest-images" title="Permalink to this headline"> </a></h3>
<p>When you restart a cluster, it gets the latest images for the compute resource containers and the VM hosts. It is important to schedule regular restarts for long-running clusters such as those used for processing streaming data.</p>
<p>It is your responsibility to restart all compute resources regularly to keep the image up-to-date with the latest image version.</p>
<p></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>If you enable the <a class="reference internal" href="../security/privacy/security-profile.html"><span class="doc">compliance security profile</span></a> for your account or your workspace, long-running clusters are automatically restarted after 25 days. Databricks recommends that workspace admins restart clusters manually during a scheduled maintenance window. This reduces the risk of an auto-restart disrupting a scheduled job.</p></li>
<li><p>If your workspace is part of the <a class="reference internal" href="../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, the 25 day limit does not apply. Clusters restart only if needed during the scheduled maintenance windows.</p></li>
</ul>
</div>
</div>
</div>
<div class="section" id="notebook-example-find-long-running-clusters">
<span id="cluster-long-running-script"></span><h2>Notebook example: Find long-running clusters<a class="headerlink" href="#notebook-example-find-long-running-clusters" title="Permalink to this headline"> </a></h2>
<p>If you are a workspace admin, you can run a script that determines how long each of your clusters has been running, and optionally, restart them if they are older than a specified number of days. Databricks provides this script as a notebook.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, you might not need this script. Clusters restart automatically if needed during the scheduled maintenance windows.</p>
</div>
<p>The first lines of the script define configuration parameters:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">min_age_output</span></code>: The maximum number of days that a cluster can run. Default is 1.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">perform_restart</span></code>: If <code class="docutils literal notranslate"><span class="pre">True</span></code>, the script restarts clusters with age greater than the number of days specified by <code class="docutils literal notranslate"><span class="pre">min_age_output</span></code>. The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>, which identifies the long-running clusters but does not restart them.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">secret_configuration</span></code>: Replace <code class="docutils literal notranslate"><span class="pre">REPLACE_WITH_SCOPE</span></code> and <code class="docutils literal notranslate"><span class="pre">REPLACE_WITH_KEY</span></code> with a <a class="reference internal" href="../security/secrets/index.html"><span class="doc">secret scope and key name</span></a>. For more details of setting up the secrets, see the notebook.</p></li>
</ul>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>If you set <code class="docutils literal notranslate"><span class="pre">perform_restart</span></code> to <code class="docutils literal notranslate"><span class="pre">True</span></code>, the script automatically restarts eligible clusters, which can cause active jobs to fail and reset open notebooks. To reduce the risk of disrupting your workspace’s business-critical jobs, plan a scheduled maintenance window and be sure to notify the workspace users.</p>
</div>
<div class="embedded-notebook-section section" id="identify-and-optionally-restart-long-running-clusters-notebook">
<span id="clusters-long-running-optional-restart"></span><h3>Identify and optionally restart long-running clusters notebook<a class="headerlink" href="#identify-and-optionally-restart-long-running-clusters-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/clusters-long-running-optional-restart.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/clusters-long-running-optional-restart.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/clusters-long-running-optional-restart.html"            id="b1b25e8367829df090ca28f7052064f064437da3fff852bdd2d7d52fdcdd5d4e" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
<div class="section" id="cluster-autostart-for-jobs-and-jdbcodbc-queries">
<span id="autostart-clusters"></span><h2>Cluster autostart for jobs and JDBC/ODBC queries<a class="headerlink" href="#cluster-autostart-for-jobs-and-jdbcodbc-queries" title="Permalink to this headline"> </a></h2>
<p>When a job assigned to a terminated cluster is scheduled to run, or you connect to a terminated cluster from a JDBC/ODBC interface, the cluster is automatically restarted.  See <a class="reference internal" href="../workflows/jobs/create-run-jobs.html#job-create"><span class="std std-ref">Create a job</span></a> and <a class="reference internal" href="../integrations/jdbc-odbc-bi.html"><span class="doc">JDBC connect</span></a>.</p>
<p>Cluster autostart allows you to configure clusters to auto-terminate without requiring manual intervention to restart the clusters for scheduled jobs. Furthermore, you can schedule cluster initialization by scheduling a job to run on a terminated cluster.</p>
<p>Before a cluster is restarted automatically, <a class="reference internal" href="../security/auth-authz/access-control/cluster-acl.html"><span class="doc">cluster</span></a> and <a class="reference internal" href="../security/auth-authz/access-control/jobs-acl.html"><span class="doc">job</span></a> access control permissions are checked.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your cluster was created in Databricks platform version 2.70 or earlier, there is no autostart: jobs scheduled to run on terminated clusters will fail.</p>
</div>
</div>
<div class="section" id="view-cluster-information-in-the-apache-spark-ui">
<span id="view-cluster-information-in-the-as-ui"></span><span id="spark-ui"></span><h2>View cluster information in the Apache Spark UI<a class="headerlink" href="#view-cluster-information-in-the-apache-spark-ui" title="Permalink to this headline"> </a></h2>
<p>You can view detailed information about Spark jobs by selecting the <strong>Spark UI</strong> tab on the cluster details page.</p>
<p>If you restart a terminated cluster, the Spark UI displays information for the restarted cluster, not the historical information for the terminated cluster.</p>
</div>
<div class="section" id="view-cluster-logs">
<h2>View cluster logs<a class="headerlink" href="#view-cluster-logs" title="Permalink to this headline"> </a></h2>
<p>Databricks provides three kinds of logging of cluster-related activity:</p>
<ul class="simple">
<li><p>Cluster event logs, which capture cluster lifecycle events like creation, termination, and configuration edits.</p></li>
<li><p>Apache Spark driver and worker log, which you can use for debugging.</p></li>
<li><p>Cluster init-script logs, which are valuable for debugging init scripts.</p></li>
</ul>
<p>This section discusses cluster event logs and driver and worker logs. For details about init-script logs, see <a class="reference internal" href="../init-scripts/logs.html"><span class="doc">Init script logging</span></a>.</p>
<div class="section" id="cluster-event-logs">
<span id="event-log"></span><h3>Cluster event logs<a class="headerlink" href="#cluster-event-logs" title="Permalink to this headline"> </a></h3>
<p>The cluster event log displays important cluster lifecycle events that are triggered manually by user actions or automatically by Databricks. Such events affect the operation of a cluster as a whole and the jobs running in the cluster.</p>
<p>For supported event types, see the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Clusters API</a> data structure.</p>
<p>Events are stored for 60 days, which is comparable to other data retention times in Databricks.</p>
<div class="section" id="view-a-cluster-event-log">
<h4>View a cluster event log<a class="headerlink" href="#view-a-cluster-event-log" title="Permalink to this headline"> </a></h4>
<p>To view the cluster’s event log, select the <strong>Event log</strong> tab on the cluster details pages.</p>
<p>For more information about an event, click its row in the log, then click the <strong>JSON</strong> tab for details.</p>
</div>
</div>
<div class="section" id="cluster-driver-and-worker-logs">
<span id="driver-logs"></span><h3>Cluster driver and worker logs<a class="headerlink" href="#cluster-driver-and-worker-logs" title="Permalink to this headline"> </a></h3>
<p>The direct print and log statements from your notebooks, jobs, and libraries go to the Spark driver logs. You can access these log files from the <strong>Driver logs</strong> tab on the cluster details page. Click the name of a log file to download it.</p>
<p>These logs have three outputs:</p>
<ul class="simple">
<li><p>Standard output</p></li>
<li><p>Standard error</p></li>
<li><p>Log4j logs</p></li>
</ul>
<p>To view Spark worker logs, use the <strong>Spark UI</strong> tab. You can also <a class="reference internal" href="configure.html#cluster-log-delivery"><span class="std std-ref">configure a log delivery location</span></a> for the cluster. Both worker and cluster logs are delivered to the location you specify.</p>
</div>
</div>
<div class="section" id="monitor-performance">
<span id="cluster-performance"></span><h2>Monitor performance<a class="headerlink" href="#monitor-performance" title="Permalink to this headline"> </a></h2>
<p>To help you monitor the performance of Databricks clusters, Databricks provides access to metrics from the cluster details page. For Databricks Runtime 12.2 and below, Databricks provides access to <a class="reference external" href="http://ganglia.sourceforge.net/">Ganglia</a> metrics. For Databricks Runtime 13.0 and above, cluster metrics are provided by Databricks.</p>
<p>You can also install <a class="reference external" href="https://www.datadoghq.com/">Datadog</a> agents on cluster nodes to send Datadog metrics to your Datadog account.</p>
<div class="section" id="cluster-metrics">
<span id="metrics"></span><h3>Cluster metrics<a class="headerlink" href="#cluster-metrics" title="Permalink to this headline"> </a></h3>
<p>Clusters metrics is the default monitoring tool for Databricks Runtime 13.0 and above. To access the cluster metrics UI, navigate to the <strong>Metrics</strong> tab on the cluster details page.</p>
<p>You can view historical metrics by selecting a time range using the date picker filter. Metrics are collected every minute. You can also get the latest metrics by clicking the <strong>Refresh</strong> button. For more information, see <a class="reference internal" href="cluster-metrics.html"><span class="doc">View cluster metrics</span></a>.</p>
</div>
<div class="section" id="ganglia-metrics">
<span id="metrics-ganglia"></span><h3>Ganglia metrics<a class="headerlink" href="#ganglia-metrics" title="Permalink to this headline"> </a></h3>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ganglia metrics are only available for Databricks Runtime 12.2 and below.</p>
</div>
<p>To access the Ganglia UI, navigate to the <strong>Metrics</strong> tab on the cluster details page. CPU metrics are available in the Ganglia UI for all Databricks runtimes. GPU metrics are available for GPU-enabled clusters.</p>
<p>To view live metrics, click the <strong>Ganglia UI</strong> link.</p>
<p>To view historical metrics, click a snapshot file. The snapshot contains aggregated metrics for the hour preceding the selected time.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ganglia isn’t supported with Docker containers. If you use a <a class="reference internal" href="custom-containers.html"><span class="doc">Docker container</span></a> with your cluster, Ganglia metrics will not be available.</p>
</div>
<div class="section" id="configure-ganglia-metrics-collection">
<h4>Configure Ganglia metrics collection<a class="headerlink" href="#configure-ganglia-metrics-collection" title="Permalink to this headline"> </a></h4>
<p>By default, Databricks collects Ganglia metrics every 15 minutes. To configure the collection period, set the <code class="docutils literal notranslate"><span class="pre">DATABRICKS_GANGLIA_SNAPSHOT_PERIOD_MINUTES</span></code> environment variable using an <a class="reference internal" href="../init-scripts/index.html"><span class="doc">init script</span></a> or in the <code class="docutils literal notranslate"><span class="pre">spark_env_vars</span></code> field in the <a class="reference external" href="https://docs.databricks.com/api/workspace/clusters">Create new cluster API</a>.</p>
</div>
</div>
</div>
<div class="section" id="notebook-example-datadog-metrics">
<span id="datadog-metrics"></span><h2>Notebook example: Datadog metrics<a class="headerlink" href="#notebook-example-datadog-metrics" title="Permalink to this headline"> </a></h2>
<div class="figure align-default">
<img alt="Datadog metrics" src="../_images/datadog-metrics.png" />
</div>
<p>You can install <a class="reference external" href="https://www.datadoghq.com/">Datadog</a> agents on cluster nodes to send Datadog metrics to your Datadog account. The following notebook demonstrates how to install a Datadog agent on a cluster using a <a class="reference internal" href="../init-scripts/cluster-scoped.html"><span class="doc">cluster-scoped init script</span></a>.</p>
<p>To install the Datadog agent on all clusters, manage the cluster-scoped init script using a cluster policy.</p>
<div class="embedded-notebook-section section" id="install-datadog-agent-init-script-notebook">
<span id="datadog-init-script"></span><h3>Install Datadog agent init script notebook<a class="headerlink" href="#install-datadog-agent-init-script-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/datadog-init-script.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/datadog-init-script.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/datadog-init-script.html"            id="e00f7a1a48b820a63115a27032807a2e775d35535f79e52181f8c3ab841094df" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
<div class="section" id="decommission-spot-instances">
<span id="notebook-example-datadog-metrics"></span><span id="decommission"></span><h2>Decommission spot instances<a class="headerlink" href="#decommission-spot-instances" title="Permalink to this headline"> </a></h2>
<p>Because <a class="reference internal" href="configure.html#spot-instances"><span class="std std-ref">spot instances</span></a> can reduce costs, creating clusters using spot instances rather than on-demand instances is a common way to run jobs. However, spot instances can be preempted by cloud provider scheduling mechanisms. Preemption of spot instances can cause issues with jobs that are running, including:</p>
<ul class="simple">
<li><p>Shuffle fetch failures</p></li>
<li><p>Shuffle data loss</p></li>
<li><p>RDD data loss</p></li>
<li><p>Job failures</p></li>
</ul>
<p>You can enable decommissioning to help address these issues. Decommissioning takes advantage of the notification that the cloud provider usually sends before a spot instance is decommissioned. When a spot instance containing an executor receives a preemption notification, the decommissioning process will attempt to migrate shuffle and RDD data to healthy executors. The duration before the final preemption is typically 30 seconds to 2 minutes, depending on the cloud provider.</p>
<p>Databricks recommends enabling data migration when decommissioning is also enabled. Generally, the possibility of errors decreases as more data is migrated, including shuffle fetching failures, shuffle data loss, and RDD data loss. Data migration can also lead to less re-computation and saved costs.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Decommissioning is a best effort and does not guarantee that all data can be migrated before final preemption. Decommissioning cannot guarantee against shuffle fetch failures when running tasks are fetching shuffle data from the executor.</p>
</div>
<p>With decommissioning enabled, task failures caused by spot instance preemption are not added to the total number of failed attempts. Task failures caused by preemption are not counted as failed attempts because the cause of the failure is external to the task and will not result in job failure.</p>
<div class="section" id="enable-decommissioning">
<h3>Enable decommissioning<a class="headerlink" href="#enable-decommissioning" title="Permalink to this headline"> </a></h3>
<p>To enable decommissioning on a cluster, enter the following properties in the <strong>Spark</strong> tab under <strong>Advanced Options</strong> in the cluster configuration UI. For information on these properties, see <a class="reference external" href="https://spark.apache.org/docs/latest/configuration.html">Spark configuration</a>.</p>
<ul>
<li><p>To enable decommissioning for applications, enter this property in the <strong>Spark config</strong> field:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">decommission</span><span class="o">.</span><span class="n">enabled</span> <span class="n">true</span>
</pre></div>
</div>
</li>
<li><p>To enable shuffle data migration during decommissioning, enter this property in the <strong>Spark config</strong> field:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">decommission</span><span class="o">.</span><span class="n">enabled</span> <span class="n">true</span>
<span class="n">spark</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">decommission</span><span class="o">.</span><span class="n">shuffleBlocks</span><span class="o">.</span><span class="n">enabled</span> <span class="n">true</span>
</pre></div>
</div>
</li>
<li><p>To enable RDD cache data migration during decommissioning, enter this property in the <strong>Spark config</strong> field:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">decommission</span><span class="o">.</span><span class="n">enabled</span> <span class="n">true</span>
<span class="n">spark</span><span class="o">.</span><span class="n">storage</span><span class="o">.</span><span class="n">decommission</span><span class="o">.</span><span class="n">rddBlocks</span><span class="o">.</span><span class="n">enabled</span> <span class="n">true</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>When RDD StorageLevel replication is set to more than 1, Databricks does not recommend enabling RDD data migration since the replicas ensure RDDs will not lose data.</p>
</div>
</li>
<li><p>To enable decommissioning for workers, enter this property in the <strong>Environment Variables</strong> field:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">SPARK_WORKER_OPTS</span><span class="o">=</span><span class="s2">&quot;-Dspark.decommission.enabled=true&quot;</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="view-the-decommission-status-and-loss-reason-in-the-ui">
<h3>View the decommission status and loss reason in the UI<a class="headerlink" href="#view-the-decommission-status-and-loss-reason-in-the-ui" title="Permalink to this headline"> </a></h3>
<p>To access a worker’s decommission status from the UI, navigate to the <strong>Spark Cluster UI - Master</strong> tab.</p>
<p>When the decommissioning finishes, you can view the executor’s loss reason in the <strong>Spark UI &gt; Executors</strong> tab on the cluster details page.</p>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>