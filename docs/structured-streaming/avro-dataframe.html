

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to use Apache Avro data in Apache Kafka as a source and sink for streaming data in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Read and write streaming Avro data">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Read and write streaming Avro data &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/structured-streaming/avro-dataframe.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/structured-streaming/avro-dataframe.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/structured-streaming/avro-dataframe.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/structured-streaming/avro-dataframe.html" class="notranslate">English</option>
    <option value="../../ja/structured-streaming/avro-dataframe.html" class="notranslate">日本語</option>
    <option value="../../pt/structured-streaming/avro-dataframe.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Read and write streaming Avro data</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="read-and-write-streaming-avro-data">
<h1>Read and write streaming Avro data<a class="headerlink" href="#read-and-write-streaming-avro-data" title="Permalink to this headline"> </a></h1>
<p><a class="reference external" href="https://avro.apache.org/">Apache Avro</a> is a commonly used data serialization system in the streaming world. A typical solution is to put data in Avro format in Apache Kafka, metadata in <a class="reference external" href="https://docs.confluent.io/current/schema-registry/docs/index.html">Confluent Schema Registry</a>, and then run queries with a streaming framework that connects to both Kafka and Schema Registry.</p>
<p>Databricks supports the <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> and <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> <a class="reference external" href="https://spark.apache.org/docs/latest/sql-data-sources-avro.html#to_avro-and-from_avro">functions</a> to build streaming pipelines with Avro data in Kafka and metadata in Schema Registry. The function <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> encodes a column as binary in Avro format and <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> decodes Avro binary data into a column. Both functions transform one column to another column, and the input/output SQL data type can be a complex type or a primitive type.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> and <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> functions:</p>
<ul class="simple">
<li><p>Are available in <a class="reference external" href="https://spark.apache.org/docs/latest/sql-data-sources-avro.html#to_avro-and-from_avro">Python</a>, Scala, and Java.</p></li>
<li><p>Can be passed to SQL functions in both batch and streaming queries.</p></li>
</ul>
</div>
<p>Also see <a class="reference internal" href="../query/formats/avro.html"><span class="doc">Avro file data source</span></a>.</p>
<div class="section" id="manually-specified-schema-example">
<h2>Manually specified schema example<a class="headerlink" href="#manually-specified-schema-example" title="Permalink to this headline"> </a></h2>
<p>Similar to <a class="reference internal" href="../sql/language-manual/functions/from_json.html"><span class="doc">from_json</span></a> and <a class="reference internal" href="../sql/language-manual/functions/to_json.html"><span class="doc">to_json</span></a>, you can use <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> and <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> with any binary column. You can specify the Avro schema manually, as in the following example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">avro</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">avro</span><span class="p">.</span><span class="nc">SchemaBuilder</span>

<span class="c1">// When reading the key and value of a Kafka topic, decode the</span>
<span class="c1">// binary (Avro) data into structured data.</span>
<span class="c1">// The schema of the resulting DataFrame is: &lt;key: string, value: int&gt;</span>
<span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span>
<span class="w">  </span><span class="p">.</span><span class="n">readStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="nc">SchemaBuilder</span><span class="p">.</span><span class="n">builder</span><span class="p">().</span><span class="n">stringType</span><span class="p">()).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="nc">SchemaBuilder</span><span class="p">.</span><span class="n">builder</span><span class="p">().</span><span class="n">intType</span><span class="p">()).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>

<span class="c1">// Convert structured data to binary from string (key column) and</span>
<span class="c1">// int (value column) and save to a Kafka topic.</span>
<span class="n">dataDF</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
<span class="w">  </span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;topic&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="jsonformatschema-example">
<h2>jsonFormatSchema example<a class="headerlink" href="#jsonformatschema-example" title="Permalink to this headline"> </a></h2>
<p>You can also specify a schema as a JSON string. For example, if <code class="docutils literal notranslate"><span class="pre">/tmp/user.avsc</span></code> is:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;namespace&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;example.avro&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;record&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;User&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;fields&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;name&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;string&quot;</span><span class="p">},</span>
<span class="w">    </span><span class="p">{</span><span class="nt">&quot;name&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;favorite_color&quot;</span><span class="p">,</span><span class="w"> </span><span class="nt">&quot;type&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;string&quot;</span><span class="p">,</span><span class="w"> </span><span class="s2">&quot;null&quot;</span><span class="p">]}</span>
<span class="w">  </span><span class="p">]</span>
<span class="p">}</span>
</pre></div>
</div>
<p>You can create a JSON string:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.avro.functions</span> <span class="kn">import</span> <span class="n">from_avro</span><span class="p">,</span> <span class="n">to_avro</span>

<span class="n">jsonFormatSchema</span> <span class="o">=</span> <span class="nb">open</span><span class="p">(</span><span class="s2">&quot;/tmp/user.avsc&quot;</span><span class="p">,</span> <span class="s2">&quot;r&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">read</span><span class="p">()</span>
</pre></div>
</div>
<p>Then use the schema in <code class="docutils literal notranslate"><span class="pre">from_avro</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># 1. Decode the Avro data into a struct.</span>
<span class="c1"># 2. Filter by column &quot;favorite_color&quot;.</span>
<span class="c1"># 3. Encode the column &quot;name&quot; in Avro format.</span>

<span class="n">output</span> <span class="o">=</span> <span class="n">df</span>\
  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">from_avro</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">,</span> <span class="n">jsonFormatSchema</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;user&quot;</span><span class="p">))</span>\
  <span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="s1">&#39;user.favorite_color == &quot;red&quot;&#39;</span><span class="p">)</span>\
  <span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">to_avro</span><span class="p">(</span><span class="s2">&quot;user.name&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="example-with-schema-registry">
<h2>Example with Schema Registry<a class="headerlink" href="#example-with-schema-registry" title="Permalink to this headline"> </a></h2>
<p>If your cluster has a Schema Registry service, <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> can work with it so that you don’t need to specify the Avro schema manually.</p>
<p>The following example demonstrates reading a Kafka topic “t”, assuming the key and value are already registered in Schema Registry as subjects “t-key” and “t-value” of types <code class="docutils literal notranslate"><span class="pre">STRING</span></code> and <code class="docutils literal notranslate"><span class="pre">INT</span></code>:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">avro</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>

<span class="kd">val</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;https://myhost:8081&quot;</span>
<span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span>
<span class="w">  </span><span class="p">.</span><span class="n">readStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t-key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t-value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
</pre></div>
</div>
<p>For <code class="docutils literal notranslate"><span class="pre">to_avro</span></code>, the default output Avro schema might not match the schema of the target subject in the Schema Registry service for the following reasons:</p>
<ul class="simple">
<li><p>The mapping from Spark SQL type to Avro schema is not one-to-one. See <a class="reference internal" href="../query/formats/avro.html#supported-types-for-spark-sql---avro-conversion"><span class="std std-ref">Supported types for Spark SQL -&gt; Avro conversion</span></a>.</p></li>
<li><p>If the converted output Avro schema is of record type, the record name is <code class="docutils literal notranslate"><span class="pre">topLevelRecord</span></code> and there is no namespace by default.</p></li>
</ul>
<p>If the default output schema of <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> matches the schema of the target subject, you can do the following:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">dataDF</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-key&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-value&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
<span class="p">.</span><span class="n">writeStream</span>
<span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;topic&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>Otherwise, you must provide the schema of the target subject in the <code class="docutils literal notranslate"><span class="pre">to_avro</span></code> function:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="c1">// The Avro schema of subject &quot;t-value&quot; in JSON string format.</span>
<span class="kd">val</span><span class="w"> </span><span class="n">avroSchema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...</span>
<span class="c1">// The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">dataDF</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-key&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-value&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">avroSchema</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
<span class="p">.</span><span class="n">writeStream</span>
<span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;topic&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="section" id="authenticate-to-an-external-confluent-schema-registry">
<span id="auth-registry"></span><h2>Authenticate to an external Confluent Schema Registry<a class="headerlink" href="#authenticate-to-an-external-confluent-schema-registry" title="Permalink to this headline"> </a></h2>
<p>In Databricks Runtime 12.1 and above, you can authenticate to an external Confluent Schema Registry. The following examples demonstrate how to configure your schema registry options to include auth credentials and API keys.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">avro</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span><span class="w"> </span><span class="nn">scala</span><span class="p">.</span><span class="nn">collection</span><span class="p">.</span><span class="nc">JavaConverters</span><span class="p">.</span><span class="n">_</span>

<span class="kd">val</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;https://confluent-schema-registry-endpoint&quot;</span>
<span class="kd">val</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Map</span><span class="p">(</span>
<span class="w">      </span><span class="s">&quot;confluent.schema.registry.basic.auth.credentials.source&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;USER_INFO&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="s">&quot;confluent.schema.registry.basic.auth.user.info&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;confluentApiKey:confluentApiSecret&quot;</span><span class="p">)</span>

<span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span>
<span class="w">  </span><span class="p">.</span><span class="n">readStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t-key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t-value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>

<span class="c1">// The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">dataDF</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-key&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-value&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
<span class="p">.</span><span class="n">writeStream</span>
<span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;topic&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">save</span><span class="p">()</span>

<span class="c1">// The Avro schema of subject &quot;t-value&quot; in JSON string format.</span>
<span class="kd">val</span><span class="w"> </span><span class="n">avroSchema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="p">...</span>

<span class="c1">// The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">dataDF</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-key&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">),</span>
<span class="w">    </span><span class="n">to_avro</span><span class="p">(</span><span class="n">$</span><span class="s">&quot;value&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">lit</span><span class="p">(</span><span class="s">&quot;t-value&quot;</span><span class="p">),</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="p">,</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">,</span><span class="w"> </span><span class="n">avroSchema</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;value&quot;</span><span class="p">))</span>
<span class="p">.</span><span class="n">writeStream</span>
<span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;topic&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="p">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
<div class="compound-last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">lit</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.avro.functions</span> <span class="kn">import</span> <span class="n">from_avro</span><span class="p">,</span> <span class="n">to_avro</span>

<span class="n">schema_registry_address</span> <span class="o">=</span> <span class="s2">&quot;https://confluent-schema-registry-endpoint&quot;</span>
<span class="n">schema_registry_options</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;confluent.schema.registry.basic.auth.credentials.source&quot;</span><span class="p">:</span> <span class="s1">&#39;USER_INFO&#39;</span><span class="p">,</span>
  <span class="s2">&quot;confluent.schema.registry.basic.auth.user.info&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">secret</span><span class="si">}</span><span class="s2">&quot;</span>
<span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="n">servers</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">from_avro</span><span class="p">(</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
      <span class="n">options</span> <span class="o">=</span> <span class="n">schema_registry_options</span><span class="p">,</span>
      <span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;t-key&quot;</span><span class="p">,</span>
      <span class="n">schemaRegistryAddress</span> <span class="o">=</span> <span class="n">schema_registry_address</span>
    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
    <span class="n">from_avro</span><span class="p">(</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">),</span>
      <span class="n">options</span> <span class="o">=</span> <span class="n">schema_registry_options</span><span class="p">,</span>
      <span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;t-value&quot;</span><span class="p">,</span>
      <span class="n">schemaRegistryAddress</span> <span class="o">=</span> <span class="n">schema_registry_address</span>
    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>

<span class="c1"># The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">data_df</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">to_avro</span><span class="p">(</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
      <span class="n">subject</span> <span class="o">=</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;t-key&quot;</span><span class="p">),</span>
      <span class="n">schemaRegistryAddress</span> <span class="o">=</span> <span class="n">schema_registry_address</span><span class="p">,</span>
      <span class="n">options</span> <span class="o">=</span> <span class="n">schema_registry_options</span>
    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
    <span class="n">to_avro</span><span class="p">(</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">),</span>
      <span class="n">subject</span> <span class="o">=</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;t-value&quot;</span><span class="p">),</span>
      <span class="n">schemaRegistryAddress</span> <span class="o">=</span> <span class="n">schema_registry_address</span><span class="p">,</span>
      <span class="n">options</span> <span class="o">=</span> <span class="n">schema_registry_options</span>
    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">)</span>
  <span class="p">)</span>
<span class="o">.</span><span class="n">writeStream</span>
<span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="n">servers</span><span class="p">)</span>
<span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">save</span><span class="p">()</span>

<span class="c1"># The Avro schema of subject &quot;t-value&quot; in JSON string format.</span>
<span class="n">avro_schema</span> <span class="o">=</span> <span class="o">...</span>

<span class="c1"># The converted data is saved to Kafka as a Kafka topic &quot;t&quot;.</span>
<span class="n">data_df</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">to_avro</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;t-key&quot;</span><span class="p">),</span> <span class="n">schema_registry_address</span><span class="p">,</span> <span class="n">schema_registry_options</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
    <span class="n">to_avro</span><span class="p">(</span><span class="n">col</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">),</span> <span class="n">lit</span><span class="p">(</span><span class="s2">&quot;t-value&quot;</span><span class="p">),</span> <span class="n">schema_registry_address</span><span class="p">,</span> <span class="n">schema_registry_options</span><span class="p">,</span> <span class="n">avro_schema</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;value&quot;</span><span class="p">))</span>
<span class="o">.</span><span class="n">writeStream</span>
<span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="n">servers</span><span class="p">)</span>
<span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;topic&quot;</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">)</span>
<span class="o">.</span><span class="n">save</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="use-schema-evolution-mode-with-from_avro">
<span id="schema-evolution"></span><h2>Use schema evolution mode with <code class="docutils literal notranslate"><span class="pre">from_avro</span></code><a class="headerlink" href="#use-schema-evolution-mode-with-from_avro" title="Permalink to this headline"> </a></h2>
<p>In Databricks Runtime 14.2 and above, you can use schema evolution mode with <code class="docutils literal notranslate"><span class="pre">from_avro</span></code>. Enabling schema evolution mode causes the job to throw an <code class="docutils literal notranslate"><span class="pre">UnknownFieldException</span></code> after detecting schema evolution. Databricks recommends configuring jobs with schema evolution mode to automatically restart on task failure. See <a class="reference internal" href="query-recovery.html#restart-job"><span class="std std-ref">Configure Structured Streaming jobs to restart streaming queries on failure</span></a>.</p>
<p>Schema evolution is useful if you expect the schema of your source data to evolve over time and ingest all fields from your data source. If your queries already explicitly specify which fields to query in your data source, added fields are ignored regardless of schema evolution.</p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">avroSchemaEvolutionMode</span></code> option to enable schema evolution. The following table describes the options for schema evolution mode:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 9%" />
<col style="width: 91%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Option</p></th>
<th class="head"><p>Behavior</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">none</span></code></p></td>
<td><p> <strong>Default</strong>. Ignores schema evolution and the job continues.</p></td>
</tr>
<tr class="row-odd"><td><p> <code class="docutils literal notranslate"><span class="pre">restart</span></code></p></td>
<td><p> Throws an <code class="docutils literal notranslate"><span class="pre">UnknownFieldException</span></code> when detecting schema evolution. Requires a job restart.</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>You can change this configuration between streaming jobs and reuse the same checkpoint. Disabling schema evolution can result in dropped columns.</p>
</div>
</div>
<div class="section" id="configure-the-parse-mode">
<h2>Configure the parse mode<a class="headerlink" href="#configure-the-parse-mode" title="Permalink to this headline"> </a></h2>
<p>You can configure the parse mode to determine whether you want to fail or emit null records when schema evolution mode is disabled and the schema evolves in a non-backward compatible way. With default settings, <code class="docutils literal notranslate"><span class="pre">from_avro</span></code> fails when it observes incompatible schema changes.</p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">mode</span></code> option to specify parse mode. The following table describes the option for parse mode:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 10%" />
<col style="width: 90%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Option</p></th>
<th class="head"><p>Behavior</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">FAILFAST</span></code></p></td>
<td><p> <strong>Default</strong>. A parsing error throws a <code class="docutils literal notranslate"><span class="pre">SparkException</span></code> with an <code class="docutils literal notranslate"><span class="pre">errorClass</span></code> of <code class="docutils literal notranslate"><span class="pre">MALFORMED_AVRO_MESSAGE</span></code>.</p></td>
</tr>
<tr class="row-odd"><td><p> <code class="docutils literal notranslate"><span class="pre">PERMISSIVE</span></code></p></td>
<td><p> A parsing error is ignored and a null record is emitted.</p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>With schema evolution enabled, <code class="docutils literal notranslate"><span class="pre">FAILFAST</span></code> only throws exceptions if a record is corrupted.</p>
</div>
</div>
<div class="section" id="example-using-schema-evolution-and-setting-parse-mode">
<h2>Example using schema evolution and setting parse mode<a class="headerlink" href="#example-using-schema-evolution-and-setting-parse-mode" title="Permalink to this headline"> </a></h2>
<p>The following example demonstrates enabling schema evolution and specifying <code class="docutils literal notranslate"><span class="pre">FAILFAST</span></code> parse mode with a Confluent Schema Registry:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="k">import</span><span class="w"> </span><span class="nn">org</span><span class="p">.</span><span class="nn">apache</span><span class="p">.</span><span class="nn">spark</span><span class="p">.</span><span class="nn">sql</span><span class="p">.</span><span class="nn">avro</span><span class="p">.</span><span class="nn">functions</span><span class="p">.</span><span class="n">_</span>
<span class="k">import</span><span class="w"> </span><span class="nn">scala</span><span class="p">.</span><span class="nn">collection</span><span class="p">.</span><span class="nc">JavaConverters</span><span class="p">.</span><span class="n">_</span>

<span class="kd">val</span><span class="w"> </span><span class="n">schemaRegistryAddr</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;https://confluent-schema-registry-endpoint&quot;</span>
<span class="kd">val</span><span class="w"> </span><span class="n">schemaRegistryOptions</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nc">Map</span><span class="p">(</span>
<span class="w">      </span><span class="s">&quot;confluent.schema.registry.basic.auth.credentials.source&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;USER_INFO&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="s">&quot;confluent.schema.registry.basic.auth.user.info&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;confluentApiKey:confluentApiSecret&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="s">&quot;avroSchemaEvolutionMode&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;restart&quot;</span><span class="p">,</span>
<span class="w">      </span><span class="s">&quot;mode&quot;</span><span class="w"> </span><span class="o">-&gt;</span><span class="w"> </span><span class="s">&quot;FAILFAST&quot;</span><span class="p">)</span>

<span class="kd">val</span><span class="w"> </span><span class="n">df</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">spark</span>
<span class="w">  </span><span class="p">.</span><span class="n">readStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">servers</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;t&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">load</span><span class="p">()</span>
<span class="w">  </span><span class="p">.</span><span class="n">select</span><span class="p">(</span>
<span class="w">    </span><span class="c1">// We read the &quot;key&quot; binary column from the subject &quot;t-key&quot; in the schema</span>
<span class="w">    </span><span class="c1">// registry at schemaRegistryAddr. We provide schemaRegistryOptions,</span>
<span class="w">    </span><span class="c1">// which has avroSchemaEvolutionMode -&gt; &quot;restart&quot;. This instructs from_avro</span>
<span class="w">    </span><span class="c1">// to fail the query if the schema for the subject t-key evolves.</span>
<span class="w">    </span><span class="n">from_avro</span><span class="p">(</span>
<span class="w">            </span><span class="n">$</span><span class="s">&quot;key&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="s">&quot;t-key&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="n">schemaRegistryAddr</span><span class="p">,</span>
<span class="w">            </span><span class="n">schemaRegistryOptions</span><span class="p">.</span><span class="n">asJava</span><span class="p">).</span><span class="n">as</span><span class="p">(</span><span class="s">&quot;key&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="compound-last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">pyspark.sql.functions</span> <span class="kn">import</span> <span class="n">col</span><span class="p">,</span> <span class="n">lit</span>
<span class="kn">from</span> <span class="nn">pyspark.sql.avro.functions</span> <span class="kn">import</span> <span class="n">from_avro</span><span class="p">,</span> <span class="n">to_avro</span>

<span class="n">schema_registry_address</span> <span class="o">=</span> <span class="s2">&quot;https://confluent-schema-registry-endpoint&quot;</span>
<span class="n">schema_registry_options</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s2">&quot;confluent.schema.registry.basic.auth.credentials.source&quot;</span><span class="p">:</span> <span class="s1">&#39;USER_INFO&#39;</span><span class="p">,</span>
  <span class="s2">&quot;confluent.schema.registry.basic.auth.user.info&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">key</span><span class="si">}</span><span class="s2">:</span><span class="si">{</span><span class="n">secret</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
  <span class="s2">&quot;avroSchemaEvolutionMode&quot;</span><span class="p">:</span> <span class="s2">&quot;restart&quot;</span><span class="p">,</span>
  <span class="s2">&quot;mode&quot;</span><span class="p">:</span> <span class="s2">&quot;FAILFAST&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">df</span> <span class="o">=</span> <span class="p">(</span><span class="n">spark</span>
  <span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="n">servers</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;t&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">()</span>
  <span class="o">.</span><span class="n">select</span><span class="p">(</span>
    <span class="n">from_avro</span><span class="p">(</span>
      <span class="n">data</span> <span class="o">=</span> <span class="n">col</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">),</span>
      <span class="n">options</span> <span class="o">=</span> <span class="n">schema_registry_options</span><span class="p">,</span>
      <span class="n">subject</span> <span class="o">=</span> <span class="s2">&quot;t-key&quot;</span><span class="p">,</span>
      <span class="n">schemaRegistryAddress</span> <span class="o">=</span> <span class="n">schema_registry_address</span>
    <span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;key&quot;</span><span class="p">)</span>
  <span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>