

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Using Databricks workflows, you can easily configure your Structured Streaming queries to automatically restart on failure." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Recover from Structured Streaming query failures with workflows">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Recover from Structured Streaming query failures with workflows &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/structured-streaming/query-recovery.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/structured-streaming/query-recovery.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/structured-streaming/query-recovery.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/structured-streaming/query-recovery.html" class="notranslate">English</option>
    <option value="../../ja/structured-streaming/query-recovery.html" class="notranslate">日本語</option>
    <option value="../../pt/structured-streaming/query-recovery.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Recover from Structured Streaming query failures with workflows</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="recover-from-structured-streaming-query-failures-with-workflows">
<span id="recover-from-ss-query-failures-with-workflows"></span><h1>Recover from Structured Streaming query failures with workflows<a class="headerlink" href="#recover-from-structured-streaming-query-failures-with-workflows" title="Permalink to this headline"> </a></h1>
<p>Structured Streaming provides fault-tolerance and data consistency for streaming queries; using Databricks workflows, you can easily configure your Structured Streaming queries to automatically restart on failure. By enabling checkpointing for a streaming query, you can restart the query after a failure. The restarted query continues where the failed one left off.</p>
<div class="section" id="enable-checkpointing-for-structured-streaming-queries">
<span id="enable-checkpointing-for-ss-queries"></span><h2>Enable checkpointing for Structured Streaming queries<a class="headerlink" href="#enable-checkpointing-for-structured-streaming-queries" title="Permalink to this headline"> </a></h2>
<p>Databricks recommends that you always specify the <code class="docutils literal notranslate"><span class="pre">checkpointLocation</span></code> option a cloud storage path before you start the query. For example:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">streamingDataFrame</span><span class="p">.</span><span class="n">writeStream</span>
<span class="w">  </span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;parquet&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;path&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;/path/to/table&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;checkpointLocation&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;/path/to/table/_checkpoint&quot;</span><span class="p">)</span>
<span class="w">  </span><span class="p">.</span><span class="n">start</span><span class="p">()</span>
</pre></div>
</div>
<p>This checkpoint location preserves all of the essential information that identifies a query. Each query must have a different checkpoint location. Multiple queries should never have the same location. For more information, see the <a class="reference external" href="https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html">Structured Streaming Programming Guide</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>While <code class="docutils literal notranslate"><span class="pre">checkpointLocation</span></code> is required for most types of output sinks, some sinks, such as memory sink, may automatically generate a temporary checkpoint location when you do not provide <code class="docutils literal notranslate"><span class="pre">checkpointLocation</span></code>. These temporary checkpoint locations do not ensure any fault tolerance or data consistency guarantees and may not get cleaned up properly. Avoid potential pitfalls by always specifying a <code class="docutils literal notranslate"><span class="pre">checkpointLocation</span></code>.</p>
</div>
</div>
<div class="section" id="configure-structured-streaming-jobs-to-restart-streaming-queries-on-failure">
<span id="configure-ss-jobs-to-restart-streaming-queries-on-failure"></span><span id="restart-job"></span><h2>Configure Structured Streaming jobs to restart streaming queries on failure<a class="headerlink" href="#configure-structured-streaming-jobs-to-restart-streaming-queries-on-failure" title="Permalink to this headline"> </a></h2>
<p>You can create a Databricks <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">job</span></a> with the notebook or JAR that has your streaming queries and configure it to:</p>
<ul class="simple">
<li><p>Always use a new cluster.</p></li>
<li><p>Always retry on failure.</p></li>
</ul>
<p>Automatically restarting on job failure is especially important when configuring streaming workloads with schema evolution. Schema evolution works on Databricks by raising an expected error when a schema change is detected, and then properly processing data using the new schema when the job restarts. Databricks recommends always configuring streaming tasks that contain queries with schema evolution to restart automatically in Databricks workflows.</p>
<p><a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">Jobs</span></a> have tight integration with Structured Streaming APIs and can monitor all streaming queries active in a run. This configuration ensures that if any part of the query fails, jobs automatically terminate the run (along with all the other queries) and start a new run in a new cluster. This re-runs the notebook or JAR code and restarts all of the queries again. This is the safest way to return to a good state.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>Failure in any of the active streaming queries causes the active run to fail and terminate all the other streaming queries.</p></li>
<li><p>You do not need to use <code class="docutils literal notranslate"><span class="pre">streamingQuery.awaitTermination()</span></code> or <code class="docutils literal notranslate"><span class="pre">spark.streams.awaitAnyTermination()</span></code> at the end of your notebook. Jobs automatically prevent a run from completing when a streaming query is active.</p></li>
<li><p>Databricks recommends using jobs instead of <code class="docutils literal notranslate"><span class="pre">%run</span></code> and <code class="docutils literal notranslate"><span class="pre">dbutils.notebook.run()</span></code> when orchestrating Structured Streaming notebooks. See <a class="reference internal" href="../notebooks/notebook-workflows.html"><span class="doc">Run a Databricks notebook from another notebook</span></a>.</p></li>
</ul>
</div>
<p>The following is an example of a recommended job configuration.</p>
<ul class="simple">
<li><p><strong>Cluster</strong>: Set this always to use a new cluster and use the latest Spark version (or at least version 2.1). Queries started in Spark 2.1 and above are recoverable after query and Spark version upgrades.</p></li>
<li><p><strong>Notifications</strong>: Set this if you want email notification on failures.</p></li>
<li><p><strong>Schedule</strong>: <em>Do not set a schedule</em>.</p></li>
<li><p><strong>Timeout</strong>: <em>Do not set a timeout.</em> Streaming queries run for an indefinitely long time.</p></li>
<li><p><strong>Maximum concurrent runs</strong>: Set to <strong>1</strong>. There must be only one instance of each query concurrently active.</p></li>
<li><p><strong>Retries</strong>: Set to <strong>Unlimited</strong>.</p></li>
</ul>
<p>See <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">Create and run Databricks Jobs</span></a> to understand these configurations.</p>
</div>
<div class="section" id="recover-after-changes-in-a-structured-streaming-query">
<span id="recover-after-changes-in-a-ss-query"></span><h2>Recover after changes in a Structured Streaming query<a class="headerlink" href="#recover-after-changes-in-a-structured-streaming-query" title="Permalink to this headline"> </a></h2>
<p>There are limitations on what changes in a streaming query are allowed between restarts from the same checkpoint location. Here are a few changes that are either not allowed or the effect of the change is not well-defined. For all of them:</p>
<ul class="simple">
<li><p>The term <em>allowed</em> means you can do the specified change but whether the semantics of its effect is well-defined depends on the query and the change.</p></li>
<li><p>The term <em>not allowed</em> means you should not do the specified change as the restarted query is likely to fail with unpredictable errors.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">sdf</span></code> represents a streaming DataFrame/Dataset generated with <code class="docutils literal notranslate"><span class="pre">sparkSession.readStream</span></code>.</p></li>
</ul>
<div class="section" id="types-of-changes-in-structured-streaming-queries">
<span id="types-of-changes-in-ss-queries"></span><h3>Types of changes in Structured Streaming queries<a class="headerlink" href="#types-of-changes-in-structured-streaming-queries" title="Permalink to this headline"> </a></h3>
<ul>
<li><p><strong>Changes in the number or type (that is, different source) of input sources</strong>: This is not allowed.</p></li>
<li><p><strong>Changes in the parameters of input sources</strong>: Whether this is allowed and whether the semantics of the change are well-defined depends on the source and the query. Here are a few examples.</p>
<ul>
<li><p>Addition, deletion, and modification of rate limits is allowed:</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;article&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>to</p>
<div class="highlight-scala notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="p">.</span><span class="n">readStream</span><span class="p">.</span><span class="n">format</span><span class="p">(</span><span class="s">&quot;kafka&quot;</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;subscribe&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;article&quot;</span><span class="p">).</span><span class="n">option</span><span class="p">(</span><span class="s">&quot;maxOffsetsPerTrigger&quot;</span><span class="p">,</span><span class="w"> </span><span class="p">...)</span>
</pre></div>
</div>
</li>
<li><p>Changes to subscribed articles and files are generally not allowed as the results are unpredictable: <code class="docutils literal notranslate"><span class="pre">spark.readStream.format(&quot;kafka&quot;).option(&quot;subscribe&quot;,</span> <span class="pre">&quot;article&quot;)</span></code> to <code class="docutils literal notranslate"><span class="pre">spark.readStream.format(&quot;kafka&quot;).option(&quot;subscribe&quot;,</span> <span class="pre">&quot;newarticle&quot;)</span></code></p></li>
</ul>
</li>
<li><p><strong>Changes in the trigger interval</strong>: You can change triggers between incremental batches and time intervals. See <a class="reference internal" href="triggers.html#change-interval"><span class="std std-ref">Changing trigger intervals between runs</span></a>.</p></li>
<li><p><strong>Changes in the type of output sink</strong>: Changes between a few specific combinations of sinks are allowed. This needs to be verified on a case-by-case basis. Here are a few examples.</p>
<ul class="simple">
<li><p>File sink to Kafka sink is allowed. Kafka will see only the new data.</p></li>
<li><p>Kafka sink to file sink is not allowed.</p></li>
<li><p>Kafka sink changed to foreach, or vice versa is allowed.</p></li>
</ul>
</li>
<li><p><strong>Changes in the parameters of output sink</strong>: Whether this is allowed and whether the semantics of the change are well-defined depends on the sink and the query. Here are a few examples.</p>
<ul class="simple">
<li><p>Changes to output directory of a file sink is not allowed: <code class="docutils literal notranslate"><span class="pre">sdf.writeStream.format(&quot;parquet&quot;).option(&quot;path&quot;,</span> <span class="pre">&quot;/somePath&quot;)</span></code> to <code class="docutils literal notranslate"><span class="pre">sdf.writeStream.format(&quot;parquet&quot;).option(&quot;path&quot;,</span> <span class="pre">&quot;/anotherPath&quot;)</span></code></p></li>
<li><p>Changes to output topic is allowed: <code class="docutils literal notranslate"><span class="pre">sdf.writeStream.format(&quot;kafka&quot;).option(&quot;topic&quot;,</span> <span class="pre">&quot;topic1&quot;)</span></code> to <code class="docutils literal notranslate"><span class="pre">sdf.writeStream.format(&quot;kafka&quot;).option(&quot;topic&quot;,</span> <span class="pre">&quot;topic2&quot;)</span></code></p></li>
<li><p>Changes to the user-defined foreach sink (that is, the <code class="docutils literal notranslate"><span class="pre">ForeachWriter</span></code> code) is allowed, but the semantics of the change depends on the code.</p></li>
</ul>
</li>
<li><p><strong>Changes in projection / filter / map-like operations</strong>: Some cases are allowed. For example:</p>
<ul class="simple">
<li><p>Addition / deletion of filters is allowed: <code class="docutils literal notranslate"><span class="pre">sdf.selectExpr(&quot;a&quot;)</span></code> to <code class="docutils literal notranslate"><span class="pre">sdf.where(...).selectExpr(&quot;a&quot;).filter(...)</span></code>.</p></li>
<li><p>Changes in projections with same output schema is allowed: <code class="docutils literal notranslate"><span class="pre">sdf.selectExpr(&quot;stringColumn</span> <span class="pre">AS</span> <span class="pre">json&quot;).writeStream</span></code> to <code class="docutils literal notranslate"><span class="pre">sdf.select(to_json(...).as(&quot;json&quot;)).writeStream</span></code>.</p></li>
<li><p>Changes in projections with different output schema are conditionally allowed: <code class="docutils literal notranslate"><span class="pre">sdf.selectExpr(&quot;a&quot;).writeStream</span></code> to <code class="docutils literal notranslate"><span class="pre">sdf.selectExpr(&quot;b&quot;).writeStream</span></code> is allowed only if the output sink allows the schema change from <code class="docutils literal notranslate"><span class="pre">&quot;a&quot;</span></code> to <code class="docutils literal notranslate"><span class="pre">&quot;b&quot;</span></code>.</p></li>
</ul>
</li>
<li><p><strong>Changes in stateful operations</strong>: Some operations in streaming queries need to maintain state data in order to continuously update the result. Structured Streaming automatically checkpoints the state data to fault-tolerant storage (for example, DBFS, AWS S3, Azure Blob storage) and restores it after restart. However, this assumes that the schema of the state data remains same across restarts. This means that <em>any changes (that is, additions, deletions, or schema modifications) to the stateful operations of a streaming query are not allowed between restarts</em>. Here is the list of stateful operations whose schema should not be changed between restarts in order to ensure state recovery:</p>
<ul class="simple">
<li><p><strong>Streaming aggregation</strong>: For example, <code class="docutils literal notranslate"><span class="pre">sdf.groupBy(&quot;a&quot;).agg(...)</span></code>. Any change in number or type of grouping keys or aggregates is not allowed.</p></li>
<li><p><strong>Streaming deduplication</strong>: For example, <code class="docutils literal notranslate"><span class="pre">sdf.dropDuplicates(&quot;a&quot;)</span></code>. Any change in number or type of grouping keys or aggregates is not allowed.</p></li>
<li><p><strong>Stream-stream join</strong>: For example, <code class="docutils literal notranslate"><span class="pre">sdf1.join(sdf2,</span> <span class="pre">...)</span></code> (i.e. both inputs are generated with <code class="docutils literal notranslate"><span class="pre">sparkSession.readStream</span></code>). Changes in the schema or equi-joining columns are not allowed. Changes in join type (outer or inner) not allowed. Other changes in the join condition are ill-defined.</p></li>
<li><p><strong>Arbitrary stateful operation</strong>: For example, <code class="docutils literal notranslate"><span class="pre">sdf.groupByKey(...).mapGroupsWithState(...)</span></code> or <code class="docutils literal notranslate"><span class="pre">sdf.groupByKey(...).flatMapGroupsWithState(...)</span></code>. Any change to the schema of the user-defined state and the type of timeout is not allowed. Any change within the user-defined state-mapping function are allowed, but the semantic effect of the change depends on the user-defined logic. If you really want to support state schema changes, then you can explicitly encode/decode your complex state data structures into bytes using an encoding/decoding scheme that supports schema migration. For example, if you save your state as Avro-encoded bytes, then you can change the Avro-state-schema between query restarts as this restores the binary state.</p></li>
</ul>
</li>
</ul>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>