

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn what to consider before migrating a Parquet data lake to Delta Lake on Databricks, as well as the four Databricks recommended migration paths to do so." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Migrate a Parquet data lake to Delta Lake">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Migrate a Parquet data lake to Delta Lake &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/migration/parquet-to-delta-lake.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/migration/parquet-to-delta-lake.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/migration/parquet-to-delta-lake.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/migration/parquet-to-delta-lake.html" class="notranslate">English</option>
    <option value="../../ja/migration/parquet-to-delta-lake.html" class="notranslate">日本語</option>
    <option value="../../pt/migration/parquet-to-delta-lake.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Migrate a Parquet data lake to Delta Lake</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="migrate-a-parquet-data-lake-to-delta-lake">
<span id="migrate-a-parquet-data-lake-to-delta"></span><h1>Migrate a Parquet data lake to Delta Lake<a class="headerlink" href="#migrate-a-parquet-data-lake-to-delta-lake" title="Permalink to this headline"> </a></h1>
<p>This article provides recommendations for converting an existing Parquet data lake to Delta Lake. Delta Lake is the underlying format in the <a class="reference internal" href="../lakehouse/index.html"><span class="doc">Databricks lakehouse</span></a>. See <a class="reference internal" href="../delta/index.html"><span class="doc">What is Delta Lake?</span></a>.</p>
<div class="section" id="considerations-before-converting-to-delta-lake">
<span id="considerations-before-converting-to-delta"></span><h2>Considerations before converting to Delta Lake<a class="headerlink" href="#considerations-before-converting-to-delta-lake" title="Permalink to this headline"> </a></h2>
<p>Your Parquet data lake likely has a partitioning strategy that has been optimized for your existing workloads and systems. While you can convert to Delta Lake and maintain this partitioning structure, over-partitioned tables are one of the main culprits that cause slow workloads on Delta Lake. See <a class="reference internal" href="../tables/partitions.html"><span class="doc">When to partition tables on Databricks</span></a> and <a class="reference internal" href="spark.html#parquet-delta"><span class="std std-ref">guidelines for adapting Spark code to Databricks</span></a>.</p>
<p>You also need to consider whether or not the data being converted is still growing, as well as how frequently data is currently being queried. You might choose different approaches for different Parquet tables in your data lake.</p>
</div>
<div class="section" id="approaches-to-delta-lake-conversion">
<span id="approaches-to-delta-conversion"></span><h2>Approaches to Delta Lake conversion<a class="headerlink" href="#approaches-to-delta-lake-conversion" title="Permalink to this headline"> </a></h2>
<p>The following matrix outlines the four main approaches to converting a Parquet data lake to Delta Lake and some of the trade-offs. To clarify each column:</p>
<ul class="simple">
<li><p><strong>Incremental</strong>: Denotes functionality that supports converting additional data appended to the conversion source after conversion has begun.</p></li>
<li><p><strong>Duplicates data</strong>: Indicates whether data is written to a new location or modified in place.</p></li>
<li><p><strong>Maintains data structure</strong>: Indicates whether the partitioning strategy is maintained during conversion.</p></li>
<li><p><strong>Backfill data</strong>: Denotes functionality that supports backfilling data that has been added to the conversion source after conversion has begun.</p></li>
<li><p><strong>Ease of use</strong>: Indicates the level of user effort to configure and run the data conversion.</p></li>
</ul>
<table class="docutils align-default">
<colgroup>
<col style="width: 22%" />
<col style="width: 11%" />
<col style="width: 14%" />
<col style="width: 23%" />
<col style="width: 12%" />
<col style="width: 17%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Method</p></th>
<th class="head"><p>Incremental</p></th>
<th class="head"><p>Duplicates data</p></th>
<th class="head"><p>Maintains data structure</p></th>
<th class="head"><p>Backfill data</p></th>
<th class="head"><p>Ease of use</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Deep <code class="docutils literal notranslate"><span class="pre">CLONE</span></code> Parquet</p></td>
<td><p> Yes</p></td>
<td><p> Yes</p></td>
<td><p> Yes</p></td>
<td><p> Yes</p></td>
<td><p> Easy</p></td>
</tr>
<tr class="row-odd"><td><p> Shallow <code class="docutils literal notranslate"><span class="pre">CLONE</span></code> Parquet</p></td>
<td><p> Yes</p></td>
<td><p> No</p></td>
<td><p> Yes</p></td>
<td><p> Yes</p></td>
<td><p> Easy</p></td>
</tr>
<tr class="row-even"><td><p> <code class="docutils literal notranslate"><span class="pre">CONVERT</span> <span class="pre">TO</span> <span class="pre">DELTA</span></code></p></td>
<td><p> No</p></td>
<td><p> No</p></td>
<td><p> Yes</p></td>
<td><p> No</p></td>
<td><p> Easy</p></td>
</tr>
<tr class="row-odd"><td><p> Auto Loader</p></td>
<td><p> Yes</p></td>
<td><p> Yes</p></td>
<td><p> No</p></td>
<td><p> Optional</p></td>
<td><p> Some configuration</p></td>
</tr>
<tr class="row-even"><td><p> Batch Spark job</p></td>
<td><p> Custom logic</p></td>
<td><p> Yes</p></td>
<td><p> No</p></td>
<td><p> Custom logic</p></td>
<td><p> Custom logic</p></td>
</tr>
</tbody>
</table>
<p>The following sections discuss each of these options in greater depth.</p>
</div>
<div class="section" id="migrate-parquet-data-with-clone-parquet">
<h2>Migrate Parquet data with <code class="docutils literal notranslate"><span class="pre">CLONE</span></code> Parquet<a class="headerlink" href="#migrate-parquet-data-with-clone-parquet" title="Permalink to this headline"> </a></h2>
<p>You can use <code class="docutils literal notranslate"><span class="pre">CLONE</span></code> Parquet to incrementally copy data from a Parquet data lake to Delta Lake. Shallow clones create pointers to existing Parquet files, maintaining your Parquet table in its original location and format while providing optimized access through collected file statistics. You can write to the table created by a shallow clone without impacting the original data source.</p>
<p>Deep clone copies all data files from the source to a new location while converting to Delta Lake. Deep clone allows you to incrementally detect new files, including backfill operations, on subsequent execution of the logic. See <a class="reference internal" href="../delta/clone-parquet.html"><span class="doc">Incrementally clone Parquet and Iceberg tables to Delta Lake</span></a>.</p>
<p>The following example demonstrates using <code class="docutils literal notranslate"><span class="pre">CLONE</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CREATE</span><span class="w"> </span><span class="k">OR</span><span class="w"> </span><span class="k">REPLACE</span><span class="w"> </span><span class="k">TABLE</span><span class="w"> </span><span class="o">&lt;</span><span class="n">target</span><span class="o">-</span><span class="k">table</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="w"> </span><span class="p">[</span><span class="n">SHALLOW</span><span class="p">]</span><span class="w"> </span><span class="n">CLONE</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`/</span><span class="n">path</span><span class="o">/</span><span class="k">to</span><span class="o">/</span><span class="k">data</span><span class="o">`</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="migrate-parquet-data-with-convert-to-delta">
<h2>Migrate Parquet data with <code class="docutils literal notranslate"><span class="pre">CONVERT</span> <span class="pre">TO</span> <span class="pre">DELTA</span></code><a class="headerlink" href="#migrate-parquet-data-with-convert-to-delta" title="Permalink to this headline"> </a></h2>
<p>You can use <code class="docutils literal notranslate"><span class="pre">CONVERT</span> <span class="pre">TO</span> <span class="pre">DELTA</span></code> to transform a directory of Parquet files into a Delta table with a single command. Once you have converted a table to Delta Lake, you should stop reading and writing from the table using Parquet logic. Data written to the target directory after conversion has started might not be reflected in the resultant Delta table. See <a class="reference internal" href="../delta/convert-to-delta.html"><span class="doc">Convert to Delta Lake</span></a>.</p>
<p>The follow example demonstrates using <code class="docutils literal notranslate"><span class="pre">CONVERT</span> <span class="pre">TO</span> <span class="pre">DELTA</span></code>:</p>
<div class="highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">CONVERT</span><span class="w"> </span><span class="k">TO</span><span class="w"> </span><span class="n">DELTA</span><span class="w"> </span><span class="n">parquet</span><span class="p">.</span><span class="o">`</span><span class="n">s3</span><span class="p">:</span><span class="o">//</span><span class="n">my</span><span class="o">-</span><span class="n">bucket</span><span class="o">/</span><span class="n">parquet</span><span class="o">-</span><span class="k">data</span><span class="o">`</span><span class="p">;</span>
</pre></div>
</div>
</div>
<div class="section" id="migrate-parquet-data-with-auto-loader">
<span id="migrate-parquet-data-with-al"></span><h2>Migrate Parquet data with Auto Loader<a class="headerlink" href="#migrate-parquet-data-with-auto-loader" title="Permalink to this headline"> </a></h2>
<p>While Auto Loader is a product designed for incremental data ingestion from cloud object storage, you can leverage it to implement a pattern that incrementally copies all data from a given directory to a target table. See <a class="reference internal" href="../ingestion/auto-loader/index.html"><span class="doc">What is Auto Loader?</span></a>.</p>
<p>The following code example includes configurations that:</p>
<ul class="simple">
<li><p>Process all existing files in the source directory.</p></li>
<li><p>Trigger an automatic weekly backfill job to capture files that might have been missed.</p></li>
<li><p>Allow Apache Spark to use many Spark jobs to avoid spill and out-of-memory errors associated with large data partitions.</p></li>
<li><p>Provide end-to-end exactly-once processing guarantees.</p></li>
</ul>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">spark</span><span class="o">.</span><span class="n">readStream</span>
  <span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;cloudFiles&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.format&quot;</span><span class="p">,</span> <span class="s2">&quot;parquet&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.includeExistingFiles&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.backfillInterval&quot;</span><span class="p">,</span> <span class="s2">&quot;1 week&quot;</span><span class="p">)</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;cloudFiles.schemaLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">writeStream</span>
  <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;checkpointLocation&quot;</span><span class="p">,</span> <span class="n">checkpoint_path</span><span class="p">)</span>
  <span class="o">.</span><span class="n">trigger</span><span class="p">(</span><span class="n">availableNow</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
  <span class="o">.</span><span class="n">toTable</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
<p>You can use Auto Loader in Delta Live Tables with either Python or SQL:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../ingestion/onboard-data.html"><span class="doc">Load data using streaming tables (Python/SQL notebook)</span></a></p></li>
</ul>
<ul class="simple">
<li><p><a class="reference internal" href="../sql/load-data-streaming-table.html"><span class="doc">Load data using streaming tables in Databricks SQL</span></a></p></li>
</ul>
</div>
<div class="section" id="migrate-parquet-data-with-custom-apache-spark-batch-logic">
<span id="migrate-parquet-data-with-custom-as-batch-logic"></span><h2>Migrate Parquet data with custom Apache Spark batch logic<a class="headerlink" href="#migrate-parquet-data-with-custom-apache-spark-batch-logic" title="Permalink to this headline"> </a></h2>
<p>Writing custom Apache Spark logic provides great flexibility in controlling how and when different data from your source system is migrated, but might require extensive configuration to provide capabilities built into other approaches.</p>
<p>At the heart of this approach is a simple Apache Spark read and write operation, such as the following:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;parquet&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="n">file_path</span><span class="p">)</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s2">&quot;append&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">saveAsTable</span><span class="p">(</span><span class="n">table_name</span><span class="p">)</span>
</pre></div>
</div>
<p>To perform backfills or incremental migration, you might be able to rely on the partitioning structure of your data source, but might also need to write custom logic to track which files have been added since you last loaded data from the source. While you can use Delta Lake <a class="reference internal" href="../delta/merge.html"><span class="doc">merge</span></a> capabilities to avoid writing duplicate records, comparing all records from a large Parquet source table to the contents of a large Delta table is a computationally expensive task.</p>
</div>
<div class="section" id="when-shouldnt-you-convert-to-delta-lake">
<span id="when-shouldnt-you-convert-to-delta"></span><h2>When shouldn’t you convert to Delta Lake?<a class="headerlink" href="#when-shouldnt-you-convert-to-delta-lake" title="Permalink to this headline"> </a></h2>
<p>Before converting all your existing Parquet data to Delta Lake, you are likely to consider potential trade-offs.</p>
<p>Databricks designs many optimized features of the lakehouse around Delta Lake, and Delta Lake provides a rich open source ecosystem with <a class="reference external" href="https://delta.io/integrations/">native connectors</a> for many languages and enterprise data systems. <a class="reference internal" href="../data-sharing/index.html"><span class="doc">Delta Sharing</span></a> extends the ability to share data stored with Delta Lake to other clients.</p>
<p>Delta Lake is built on top of Parquet, and as such, Databricks also has optimized readers and writers for interacting with Parquet files.</p>
<p>Databricks recommends using Delta Lake for all tables that receive regular updates or queries from Databricks. You might choose to maintain data in Parquet format in some cases, such as the following:</p>
<ul class="simple">
<li><p>An upstream system that writes data to Parquet does not support native writing to Delta Lake.</p></li>
<li><p>A downstream system that reads Parquet data cannot read Delta Lake.</p></li>
</ul>
<p>In both of these cases, you might want to replicate your tables to Delta Lake to leverage performance benefits while reading, writing, updating, and deleting records in the table.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Simultaneously modifying data in the same Delta table stored in S3 from multiple workspaces or data systems is not recommended. See <a class="reference internal" href="../delta/s3-limitations.html"><span class="doc">Delta Lake limitations on S3</span></a>.</p>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>