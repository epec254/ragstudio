

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="This article provides details for the Delta Live Tables Python programming interface." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Delta Live Tables Python language reference">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Delta Live Tables Python language reference &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/delta-live-tables/python-ref.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/delta-live-tables/python-ref.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/delta-live-tables/python-ref.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/delta-live-tables/python-ref.html" class="notranslate">English</option>
    <option value="../../ja/delta-live-tables/python-ref.html" class="notranslate">日本語</option>
    <option value="../../pt/delta-live-tables/python-ref.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Delta Live Tables Python language reference</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="delta-live-tables-python-language-reference">
<span id="dlt-python-language-reference"></span><h1>Delta Live Tables Python language reference<a class="headerlink" href="#delta-live-tables-python-language-reference" title="Permalink to this headline"> </a></h1>
<p>This article provides details for the Delta Live Tables Python programming interface.</p>
<p>For information on the SQL API, see the <a class="reference internal" href="sql-ref.html"><span class="doc">Delta Live Tables SQL language reference</span></a>.</p>
<p>For details specific to configuring Auto Loader, see <a class="reference internal" href="../ingestion/auto-loader/index.html"><span class="doc">What is Auto Loader?</span></a>.</p>
<div class="section" id="limitations">
<span id="python-limitations"></span><h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline"> </a></h2>
<p>The Delta Live Tables Python interface has the following limitations:</p>
<ul class="simple">
<li><p>The Python <code class="docutils literal notranslate"><span class="pre">table</span></code> and <code class="docutils literal notranslate"><span class="pre">view</span></code> functions must return a DataFrame. Some functions that operate on DataFrames do not return DataFrames and should not be used. Because DataFrame transformations are executed <em>after</em> the full dataflow graph has been resolved, using such operations might have unintended side effects. These operations include functions such as <code class="docutils literal notranslate"><span class="pre">collect()</span></code>, <code class="docutils literal notranslate"><span class="pre">count()</span></code>, <code class="docutils literal notranslate"><span class="pre">toPandas()</span></code>, <code class="docutils literal notranslate"><span class="pre">save()</span></code>, and <code class="docutils literal notranslate"><span class="pre">saveAsTable()</span></code>. However, you can include these functions outside of <code class="docutils literal notranslate"><span class="pre">table</span></code> or <code class="docutils literal notranslate"><span class="pre">view</span></code> function definitions because this code is run once during the graph initialization phase.</p></li>
<li><p>The <code class="docutils literal notranslate"><span class="pre">pivot()</span></code> function is not supported. The <code class="docutils literal notranslate"><span class="pre">pivot</span></code> operation in Spark requires eager loading of input data to compute the schema of the output. This capability is not supported in Delta Live Tables.</p></li>
</ul>
</div>
<div class="section" id="import-the-dlt-python-module">
<h2>Import the <code class="docutils literal notranslate"><span class="pre">dlt</span></code> Python module<a class="headerlink" href="#import-the-dlt-python-module" title="Permalink to this headline"> </a></h2>
<p>Delta Live Tables Python functions are defined in the <code class="docutils literal notranslate"><span class="pre">dlt</span></code> module. Your pipelines implemented with the Python API must import this module:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>
</pre></div>
</div>
</div>
<div class="section" id="create-a-delta-live-tables-materialized-view-or-streaming-table">
<span id="create-a-dlt-materialized-view-or-streaming-table"></span><span id="create-table-python"></span><h2>Create a Delta Live Tables materialized view or streaming table<a class="headerlink" href="#create-a-delta-live-tables-materialized-view-or-streaming-table" title="Permalink to this headline"> </a></h2>
<p>In Python, Delta Live Tables determines whether to update a dataset as a materialized view or streaming table based on the defining query. The <code class="docutils literal notranslate"><span class="pre">&#64;table</span></code> decorator is used to define both materialized views and streaming tables.</p>
<p>To define a materialized view in Python, apply <code class="docutils literal notranslate"><span class="pre">&#64;table</span></code> to a query that performs a static read against a data source. To define a streaming table, apply <code class="docutils literal notranslate"><span class="pre">&#64;table</span></code> to a query that performs a streaming read against a data source. Both dataset types have the same syntax specification as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&lt;name&gt;&quot;</span><span class="p">,</span>
  <span class="n">comment</span><span class="o">=</span><span class="s2">&quot;&lt;comment&gt;&quot;</span><span class="p">,</span>
  <span class="n">spark_conf</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">table_properties</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">path</span><span class="o">=</span><span class="s2">&quot;&lt;storage-location-path&gt;&quot;</span><span class="p">,</span>
  <span class="n">partition_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;partition-column&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;partition-column&gt;&quot;</span><span class="p">],</span>
  <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;schema-definition&quot;</span><span class="p">,</span>
  <span class="n">temporary</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_or_fail</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_or_drop</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all_or_drop</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all_or_fail</span>
<span class="k">def</span> <span class="o">&lt;</span><span class="n">function</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">query</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="create-a-delta-live-tables-view">
<span id="create-a-dlt-view"></span><span id="create-view-python"></span><h2>Create a Delta Live Tables view<a class="headerlink" href="#create-a-delta-live-tables-view" title="Permalink to this headline"> </a></h2>
<p>To define a view in Python, apply the <code class="docutils literal notranslate"><span class="pre">&#64;view</span></code> decorator. Like the <code class="docutils literal notranslate"><span class="pre">&#64;table</span></code> decorator, you can use views in Delta Live Tables for either static or streaming datasets. The following is the syntax for defining views with Python:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">view</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;&lt;name&gt;&quot;</span><span class="p">,</span>
  <span class="n">comment</span><span class="o">=</span><span class="s2">&quot;&lt;comment&gt;&quot;</span><span class="p">)</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_or_fail</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_or_drop</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all_or_drop</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">expect_all_or_fail</span>
<span class="k">def</span> <span class="o">&lt;</span><span class="n">function</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="p">():</span>
    <span class="k">return</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">query</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-define-tables-and-views">
<h2>Example: Define tables and views<a class="headerlink" href="#example-define-tables-and-views" title="Permalink to this headline"> </a></h2>
<p>To define a table or view in Python, apply the <code class="docutils literal notranslate"><span class="pre">&#64;dlt.view</span></code> or <code class="docutils literal notranslate"><span class="pre">&#64;dlt.table</span></code> decorator to a function. You can use the function name or the <code class="docutils literal notranslate"><span class="pre">name</span></code> parameter to assign the table or view name. The following example defines two different datasets: a view called <code class="docutils literal notranslate"><span class="pre">taxi_raw</span></code> that takes a JSON file as the input source and a table called <code class="docutils literal notranslate"><span class="pre">filtered_data</span></code> that takes the <code class="docutils literal notranslate"><span class="pre">taxi_raw</span></code> view as input:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">view</span>
<span class="k">def</span> <span class="nf">taxi_raw</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/databricks-datasets/nyctaxi/sample/json/&quot;</span><span class="p">)</span>

<span class="c1"># Use the function name as the table name</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">filtered_data</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">dlt</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;taxi_raw&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>

<span class="c1"># Use the name parameter as the table name</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">(</span>
  <span class="n">name</span><span class="o">=</span><span class="s2">&quot;filtered_data&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">create_filtered_data</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">dlt</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;taxi_raw&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-access-a-dataset-defined-in-the-same-pipeline">
<h2>Example: Access a dataset defined in the same pipeline<a class="headerlink" href="#example-access-a-dataset-defined-in-the-same-pipeline" title="Permalink to this headline"> </a></h2>
<p>In addition to reading from external data sources, you can access datasets defined in the same pipeline with the Delta Live Tables <code class="docutils literal notranslate"><span class="pre">read()</span></code> function. The following example demonstrates creating a <code class="docutils literal notranslate"><span class="pre">customers_filtered</span></code> dataset using the <code class="docutils literal notranslate"><span class="pre">read()</span></code> function:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers_raw</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/data/customers.csv&quot;</span><span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers_filteredA</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">dlt</span><span class="o">.</span><span class="n">read</span><span class="p">(</span><span class="s2">&quot;customers_raw&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>You can also use the <code class="docutils literal notranslate"><span class="pre">spark.table()</span></code> function to access a dataset defined in the same pipeline. When using the <code class="docutils literal notranslate"><span class="pre">spark.table()</span></code> function to access a dataset defined in the pipeline, in the function argument prepend the <code class="docutils literal notranslate"><span class="pre">LIVE</span></code> keyword to the dataset name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers_raw</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/data/customers.csv&quot;</span><span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers_filteredB</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;LIVE.customers_raw&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-read-from-a-table-registered-in-a-metastore">
<h2>Example: Read from a table registered in a metastore<a class="headerlink" href="#example-read-from-a-table-registered-in-a-metastore" title="Permalink to this headline"> </a></h2>
<p>To read data from a table registered in the Hive metastore, in the function argument omit the <code class="docutils literal notranslate"><span class="pre">LIVE</span></code> keyword and optionally qualify the table name with the database name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">customers</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;sales.customers&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="o">...</span><span class="p">)</span>
</pre></div>
</div>
<p>For an example of reading from a Unity Catalog table, see <a class="reference internal" href="unity-catalog.html#ingest-data"><span class="std std-ref">Ingest data into a Unity Catalog pipeline</span></a>.</p>
</div>
<div class="section" id="example-access-a-dataset-using-sparksql">
<h2>Example: Access a dataset using <code class="docutils literal notranslate"><span class="pre">spark.sql</span></code><a class="headerlink" href="#example-access-a-dataset-using-sparksql" title="Permalink to this headline"> </a></h2>
<p>You can also return a dataset using a <code class="docutils literal notranslate"><span class="pre">spark.sql</span></code> expression in a query function. To read from an internal dataset, prepend <code class="docutils literal notranslate"><span class="pre">LIVE.</span></code> to the dataset name:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span>
<span class="k">def</span> <span class="nf">chicago_customers</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;SELECT * FROM LIVE.customers_cleaned WHERE city = &#39;Chicago&#39;&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="write-to-a-streaming-table-from-multiple-source-streams">
<span id="write-to-a-st-from-multiple-source-streams"></span><span id="append-flows"></span><h2>Write to a streaming table from multiple source streams<a class="headerlink" href="#write-to-a-streaming-table-from-multiple-source-streams" title="Permalink to this headline"> </a></h2>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>Delta Live Tables support for <code class="docutils literal notranslate"><span class="pre">&#64;append_flow</span></code> is in <a class="reference internal" href="../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<p>You can use the <code class="docutils literal notranslate"><span class="pre">&#64;append_flow</span></code> decorator to write to a streaming table from multiple streaming sources to do the following:</p>
<ul class="simple">
<li><p>Add and remove streaming sources that append data to an existing streaming table without requiring a full refresh. For example, you might have a table that combines regional data from every region you’re operating in. As new regions are rolled out, you can add the new region data to the table without performing a full refresh.</p></li>
<li><p>Update a streaming table by appending missing historical data (backfilling). For example, you have an existing streaming table that is written to by an Apache Kafka topic. You also have historical data stored in a table that you need inserted exactly once into the streaming table and you cannot stream the data because you need to perform a complex aggregation before inserting the data.</p></li>
</ul>
<p>The following is the syntax for <code class="docutils literal notranslate"><span class="pre">&#64;append_flow</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="n">dlt</span><span class="o">.</span><span class="n">create_streaming_table</span><span class="p">(</span><span class="s2">&quot;&lt;target-table-name&gt;&quot;</span><span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">append_flow</span><span class="p">(</span>
  <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;&lt;target-table-name&gt;&quot;</span><span class="p">,</span>
  <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;&lt;flow-name&gt;&quot;</span><span class="p">,</span> <span class="c1"># optional, defaults to function name</span>
  <span class="n">spark_conf</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span> <span class="c1"># optional</span>
  <span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;&lt;comment&quot;</span><span class="p">)</span> <span class="c1"># optional</span>
<span class="k">def</span> <span class="o">&lt;</span><span class="n">function</span><span class="o">-</span><span class="n">name</span><span class="o">&gt;</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span><span class="o">&lt;</span><span class="n">streaming</span> <span class="n">query</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-write-to-a-streaming-table-from-multiple-kafka-topics">
<span id="example-write-to-a-st-from-multiple-kafka-topics"></span><h2>Example: Write to a streaming table from multiple Kafka topics<a class="headerlink" href="#example-write-to-a-streaming-table-from-multiple-kafka-topics" title="Permalink to this headline"> </a></h2>
<p>The following example creates a streaming table named <code class="docutils literal notranslate"><span class="pre">kafkaTarget</span></code> and writes to that streaming table from two Kafka topics:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="n">dlt</span><span class="o">.</span><span class="n">create_streaming_table</span><span class="p">(</span><span class="s2">&quot;kafka_target&quot;</span><span class="p">)</span>

<span class="c1"># Kafka stream from multiple topics</span>
<span class="nd">@dlt</span><span class="o">.</span><span class="n">append_flow</span><span class="p">(</span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;kafka_target&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">topic1</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,...&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic1&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">load</span><span class="p">()</span>
  <span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">append_flow</span><span class="p">(</span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;kafka_target&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">topic2</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span>
    <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;kafka&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;kafka.bootstrap.servers&quot;</span><span class="p">,</span> <span class="s2">&quot;host1:port1,...&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;subscribe&quot;</span><span class="p">,</span> <span class="s2">&quot;topic2&quot;</span><span class="p">)</span>
      <span class="o">.</span><span class="n">load</span><span class="p">()</span>
  <span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="example-run-a-one-time-data-backfill">
<h2>Example: Run a one-time data backfill<a class="headerlink" href="#example-run-a-one-time-data-backfill" title="Permalink to this headline"> </a></h2>
<p>The following example runs a query to append historical data to a streaming table:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>To ensure a true one-time backfill when the backfill query is part of a pipeline that runs on a scheduled basis or continuously, remove the query after running the pipeline once. To append new data if it arrives in the backfill directory, leave the query in place.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">dlt</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">()</span>
<span class="k">def</span> <span class="nf">csv_target</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;path/to/sourceDir&quot;</span><span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">append_flow</span><span class="p">(</span><span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;csv_target&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">backfill</span><span class="p">():</span>
  <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;path/to/backfill/data/dir&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="control-how-tables-are-materialized">
<h2>Control how tables are materialized<a class="headerlink" href="#control-how-tables-are-materialized" title="Permalink to this headline"> </a></h2>
<p>Tables also offer additional control of their materialization:</p>
<ul class="simple">
<li><p>Specify how tables are <a class="reference internal" href="#schema-partition-example"><span class="std std-ref">partitioned</span></a> using <code class="docutils literal notranslate"><span class="pre">partition_cols</span></code>. You can use partitioning to speed up queries.</p></li>
<li><p>You can set table properties when you define a view or table. See <a class="reference internal" href="properties.html#table-properties"><span class="std std-ref">Delta Live Tables table properties</span></a>.</p></li>
<li><p>Set a storage location for table data using the <code class="docutils literal notranslate"><span class="pre">path</span></code> setting. By default, table data is stored in the pipeline storage location if <code class="docutils literal notranslate"><span class="pre">path</span></code> isn’t set.</p></li>
<li><p>You can use <a class="reference internal" href="../delta/generated-columns.html"><span class="doc">generated columns</span></a> in your schema definition. See <a class="reference internal" href="#schema-partition-example"><span class="std std-ref">Example: Specify a schema and partition columns</span></a>.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For tables less than 1 TB in size, Databricks recommends letting Delta Live Tables control data organization. Unless you expect your table to grow beyond a terabyte, you should generally not specify partition columns.</p>
</div>
</div>
<div class="section" id="example-specify-a-schema-and-partition-columns">
<span id="schema-partition-example"></span><h2>Example: Specify a schema and partition columns<a class="headerlink" href="#example-specify-a-schema-and-partition-columns" title="Permalink to this headline"> </a></h2>
<p>You can optionally specify a table schema using a Python <code class="docutils literal notranslate"><span class="pre">StructType</span></code> or a SQL DDL string. When specified with a DDL string, the definition can include <a class="reference internal" href="../delta/generated-columns.html"><span class="doc">generated columns</span></a>.</p>
<p>The following example creates a table called <code class="docutils literal notranslate"><span class="pre">sales</span></code> with a schema specified using a Python <code class="docutils literal notranslate"><span class="pre">StructType</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">sales_schema</span> <span class="o">=</span> <span class="n">StructType</span><span class="p">([</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;customer_id&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;customer_name&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;number_of_line_items&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;order_datetime&quot;</span><span class="p">,</span> <span class="n">StringType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">),</span>
  <span class="n">StructField</span><span class="p">(</span><span class="s2">&quot;order_number&quot;</span><span class="p">,</span> <span class="n">LongType</span><span class="p">(),</span> <span class="kc">True</span><span class="p">)]</span>
<span class="p">)</span>

<span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">(</span>
  <span class="n">comment</span><span class="o">=</span><span class="s2">&quot;Raw data on sales&quot;</span><span class="p">,</span>
  <span class="n">schema</span><span class="o">=</span><span class="n">sales_schema</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">sales</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>The following example specifies the schema for a table using a DDL string, defines a generated column, and defines a partition column:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@dlt</span><span class="o">.</span><span class="n">table</span><span class="p">(</span>
  <span class="n">comment</span><span class="o">=</span><span class="s2">&quot;Raw data on sales&quot;</span><span class="p">,</span>
  <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;&quot;&quot;</span>
<span class="s2">    customer_id STRING,</span>
<span class="s2">    customer_name STRING,</span>
<span class="s2">    number_of_line_items STRING,</span>
<span class="s2">    order_datetime STRING,</span>
<span class="s2">    order_number LONG,</span>
<span class="s2">    order_day_of_week STRING GENERATED ALWAYS AS (dayofweek(order_datetime))</span>
<span class="s2">    &quot;&quot;&quot;</span><span class="p">,</span>
  <span class="n">partition_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;order_day_of_week&quot;</span><span class="p">])</span>
<span class="k">def</span> <span class="nf">sales</span><span class="p">():</span>
  <span class="k">return</span> <span class="p">(</span><span class="s2">&quot;...&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>By default, Delta Live Tables infers the schema from the <code class="docutils literal notranslate"><span class="pre">table</span></code> definition if you don’t specify a schema.</p>
</div>
<div class="section" id="configure-a-streaming-table-to-ignore-changes-in-a-source-streaming-table">
<span id="ignore-changes"></span><h2>Configure a streaming table to ignore changes in a source streaming table<a class="headerlink" href="#configure-a-streaming-table-to-ignore-changes-in-a-source-streaming-table" title="Permalink to this headline"> </a></h2>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The <code class="docutils literal notranslate"><span class="pre">skipChangeCommits</span></code> flag works only with <code class="docutils literal notranslate"><span class="pre">spark.readStream</span></code> using the <code class="docutils literal notranslate"><span class="pre">option()</span></code> function. You cannot use this flag in a <code class="docutils literal notranslate"><span class="pre">dlt.read_stream()</span></code> function.</p></li>
<li><p>You cannot use the <code class="docutils literal notranslate"><span class="pre">skipChangeCommits</span></code> flag when the source streaming table is defined as the target of an <a class="reference internal" href="#cdc"><span class="std std-ref">apply_changes()</span></a> function.</p></li>
</ul>
</div>
<p>By default, streaming tables require append-only sources. When a streaming table uses another streaming table as a source, and the source streaming table requires updates or deletes, for example, GDPR “right to be forgotten” processing, the <code class="docutils literal notranslate"><span class="pre">skipChangeCommits</span></code> flag can be set when reading the source streaming table to ignore those changes. For more information about this flag, see <a class="reference internal" href="../structured-streaming/delta-lake.html#ignore-changes"><span class="std std-ref">Ignore updates and deletes</span></a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="nd">@table</span>
<span class="k">def</span> <span class="nf">b</span><span class="p">():</span>
   <span class="k">return</span> <span class="n">spark</span><span class="o">.</span><span class="n">readStream</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;skipChangeCommits&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;LIVE.A&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="python-delta-live-tables-properties">
<span id="python-dlt-properties"></span><span id="python-properties"></span><h2>Python Delta Live Tables properties<a class="headerlink" href="#python-delta-live-tables-properties" title="Permalink to this headline"> </a></h2>
<p>The following tables describe the options and properties you can specify while defining tables and views with Delta Live Tables:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>&#64;table or &#64;view</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">name</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>An optional name for the table or view. If not defined,
the function name is used as the table or view name.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">comment</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>An optional description for the table.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">spark_conf</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>An optional list of Spark configurations for the execution
of this query.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">table_properties</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>An optional list of
<a class="reference internal" href="properties.html"><span class="doc">table properties</span></a>
for the table.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">path</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>An optional storage location for table data. If not set,
the system will default to the pipeline storage location.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">partition_cols</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">a</span> <span class="pre">collection</span> <span class="pre">of</span> <span class="pre">str</span></code></p>
<p>An optional collection, for example, a <code class="docutils literal notranslate"><span class="pre">list</span></code>, of one or
more columns to use for partitioning the table.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">schema</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">StructType</span></code></p>
<p>An optional schema definition for the table. Schemas can
be defined as a SQL DDL string, or with a Python
<code class="docutils literal notranslate"><span class="pre">StructType</span></code>.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">temporary</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">bool</span></code></p>
<p>Create a table but do not persist metadata for the table.
The <code class="docutils literal notranslate"><span class="pre">temporary</span></code> keyword instructs Delta Live Tables to create a table
that is available to the pipeline but should not be
accessed outside the pipline. To reduce processing time,
a temporary table persists for the lifetime of the
pipeline that creates it, and not just a single update.</p>
<p>The default is ‘False’.</p>
</td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Table or view definition</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">def</span> <span class="pre">&lt;function-name&gt;()</span></code></strong></p>
<p>A Python function that defines the dataset. If the <code class="docutils literal notranslate"><span class="pre">name</span></code>
parameter is not set, then <code class="docutils literal notranslate"><span class="pre">&lt;function-name&gt;</span></code> is used as
the target dataset name.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">query</span></code></strong></p>
<p>A Spark SQL statement that returns a Spark Dataset or Koalas DataFrame.</p>
<p>Use <code class="docutils literal notranslate"><span class="pre">dlt.read()</span></code> or <code class="docutils literal notranslate"><span class="pre">spark.table()</span></code> to perform a complete read from a dataset defined in the same
pipeline. When using the <code class="docutils literal notranslate"><span class="pre">spark.table()</span></code> function to read from a dataset defined in the same
pipeline, prepend the <code class="docutils literal notranslate"><span class="pre">LIVE</span></code> keyword to the dataset name in the function argument. For example, to
read from a dataset named <code class="docutils literal notranslate"><span class="pre">customers</span></code>:</p>
<p><code class="docutils literal notranslate"><span class="pre">spark.table(&quot;LIVE.customers&quot;)</span></code></p>
<p>You can also use the <code class="docutils literal notranslate"><span class="pre">spark.table()</span></code> function to read from a table registered in the metastore by
omitting the <code class="docutils literal notranslate"><span class="pre">LIVE</span></code> keyword and optionally qualifying the table name with the database name:</p>
<p><code class="docutils literal notranslate"><span class="pre">spark.table(&quot;sales.customers&quot;)</span></code></p>
<p>Use <code class="docutils literal notranslate"><span class="pre">dlt.read_stream()</span></code> to perform a streaming read from a dataset defined in the same pipeline.</p>
<p>Use the <code class="docutils literal notranslate"><span class="pre">spark.sql</span></code> function to define a SQL query to create the return dataset.</p>
<p>Use <a class="reference external" href="https://api-docs.databricks.com/python/pyspark/latest/pyspark.sql/dataframe.html">PySpark</a>
syntax to define Delta Live Tables queries with Python.</p>
</td>
</tr>
</tbody>
</table>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Expectations</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect(&quot;description&quot;,</span> <span class="pre">&quot;constraint&quot;)</span></code></strong></p>
<p>Declare a data quality constraint identified by
<code class="docutils literal notranslate"><span class="pre">description</span></code>. If a row violates the expectation, include
the row in the target dataset.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect_or_drop(&quot;description&quot;,</span> <span class="pre">&quot;constraint&quot;)</span></code></strong></p>
<p>Declare a data quality constraint identified by
<code class="docutils literal notranslate"><span class="pre">description</span></code>. If a row violates the expectation, drop the
row from the target dataset.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect_or_fail(&quot;description&quot;,</span> <span class="pre">&quot;constraint&quot;)</span></code></strong></p>
<p>Declare a data quality constraint identified by
<code class="docutils literal notranslate"><span class="pre">description</span></code>. If a row violates the expectation,
immediately stop execution.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect_all(expectations)</span></code></strong></p>
<p>Declare one or more data quality constraints.
<code class="docutils literal notranslate"><span class="pre">expectations</span></code> is a Python dictionary, where the key is
the expectation description and the value is the
expectation constraint. If a row violates any of the
expectations, include the row in the target dataset.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect_all_or_drop(expectations)</span></code></strong></p>
<p>Declare one or more data quality constraints.
<code class="docutils literal notranslate"><span class="pre">expectations</span></code> is a Python dictionary, where the key is
the expectation description and the value is the
expectation constraint. If a row violates any of the
expectations, drop the row from the target dataset.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">&#64;expect_all_or_fail(expectations)</span></code></strong></p>
<p>Declare one or more data quality constraints.
<code class="docutils literal notranslate"><span class="pre">expectations</span></code> is a Python dictionary, where the key is
the expectation description and the value is the
expectation constraint. If a row violates any of the
expectations, immediately stop execution.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="change-data-capture-with-python-in-delta-live-tables">
<span id="change-data-capture-with-python-in-dlt"></span><span id="cdc"></span><h2>Change data capture with Python in Delta Live Tables<a class="headerlink" href="#change-data-capture-with-python-in-delta-live-tables" title="Permalink to this headline"> </a></h2>
<p>Use the <code class="docutils literal notranslate"><span class="pre">apply_changes()</span></code> function in the Python API to use Delta Live Tables CDC functionality. The Delta Live Tables Python CDC interface also provides the <a class="reference internal" href="#create-target-fn"><span class="std std-ref">create_streaming_table()</span></a> function. You can use this function to create the target table required by the <code class="docutils literal notranslate"><span class="pre">apply_changes()</span></code> function.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">apply_changes</span><span class="p">(</span>
  <span class="n">target</span> <span class="o">=</span> <span class="s2">&quot;&lt;target-table&gt;&quot;</span><span class="p">,</span>
  <span class="n">source</span> <span class="o">=</span> <span class="s2">&quot;&lt;data-source&gt;&quot;</span><span class="p">,</span>
  <span class="n">keys</span> <span class="o">=</span> <span class="p">[</span><span class="s2">&quot;key1&quot;</span><span class="p">,</span> <span class="s2">&quot;key2&quot;</span><span class="p">,</span> <span class="s2">&quot;keyN&quot;</span><span class="p">],</span>
  <span class="n">sequence_by</span> <span class="o">=</span> <span class="s2">&quot;&lt;sequence-column&gt;&quot;</span><span class="p">,</span>
  <span class="n">ignore_null_updates</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
  <span class="n">apply_as_deletes</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
  <span class="n">apply_as_truncates</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
  <span class="n">column_list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
  <span class="n">except_column_list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
  <span class="n">stored_as_scd_type</span> <span class="o">=</span> <span class="o">&lt;</span><span class="nb">type</span><span class="o">&gt;</span><span class="p">,</span>
  <span class="n">track_history_column_list</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
  <span class="n">track_history_except_column_list</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The default behavior for <code class="docutils literal notranslate"><span class="pre">INSERT</span></code> and <code class="docutils literal notranslate"><span class="pre">UPDATE</span></code> events is to <em>upsert</em> CDC events from the source: update any rows in the target table that match the specified key(s) or insert a new row when a matching record does not exist in the target table. Handling for <code class="docutils literal notranslate"><span class="pre">DELETE</span></code> events can be specified with the <code class="docutils literal notranslate"><span class="pre">APPLY</span> <span class="pre">AS</span> <span class="pre">DELETE</span> <span class="pre">WHEN</span></code> condition.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>You must declare a target streaming table to apply changes into. You can optionally specify the schema for your target table. When specifying the schema of the <code class="docutils literal notranslate"><span class="pre">apply_changes</span></code> target table, you must also include the <code class="docutils literal notranslate"><span class="pre">__START_AT</span></code> and <code class="docutils literal notranslate"><span class="pre">__END_AT</span></code> columns with the same data type as the <code class="docutils literal notranslate"><span class="pre">sequence_by</span></code> field.</p>
</div>
<p>See <a class="reference internal" href="cdc.html"><span class="doc">Simplified change data capture with the APPLY CHANGES API in Delta Live Tables</span></a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Arguments</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">target</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>The name of the table to be updated. You can use the <a class="reference internal" href="#create-target-fn"><span class="std std-ref">create_streaming_table()</span></a>
function to create the target table before executing the <code class="docutils literal notranslate"><span class="pre">apply_changes()</span></code> function.</p>
<p>This parameter is required.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">source</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>The data source containing CDC records.</p>
<p>This parameter is required.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">keys</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">list</span></code></p>
<p>The column or combination of columns that uniquely identify a row in the source data. This is used to identify
which CDC events apply to specific records in the target table.</p>
<p>You can specify either:</p>
<ul class="simple">
<li><p>A list of strings: <code class="docutils literal notranslate"><span class="pre">[&quot;userId&quot;,</span> <span class="pre">&quot;orderId&quot;]</span></code></p></li>
<li><p>A list of Spark SQL <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions: <code class="docutils literal notranslate"><span class="pre">[col(&quot;userId&quot;),</span> <span class="pre">col(&quot;orderId&quot;]</span></code></p></li>
</ul>
<p>Arguments to <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions cannot include qualifiers. For example, you can use <code class="docutils literal notranslate"><span class="pre">col(userId)</span></code>, but you
cannot use <code class="docutils literal notranslate"><span class="pre">col(source.userId)</span></code>.</p>
<p>This parameter is required.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">sequence_by</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">col()</span></code></p>
<p>The column name specifying the logical order of CDC events in the source data. Delta Live Tables uses this sequencing to
handle change events that arrive out of order.</p>
<p>You can specify either:</p>
<ul class="simple">
<li><p>A string: <code class="docutils literal notranslate"><span class="pre">&quot;sequenceNum&quot;</span></code></p></li>
<li><p>A Spark SQL <code class="docutils literal notranslate"><span class="pre">col()</span></code> function: <code class="docutils literal notranslate"><span class="pre">col(&quot;sequenceNum&quot;)</span></code></p></li>
</ul>
<p>Arguments to <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions cannot include qualifiers. For example, you can use <code class="docutils literal notranslate"><span class="pre">col(userId)</span></code>, but you
cannot use <code class="docutils literal notranslate"><span class="pre">col(source.userId)</span></code>.</p>
<p>This parameter is required.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">ignore_null_updates</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">bool</span></code></p>
<p>Allow ingesting updates containing a subset of the target columns. When a CDC event matches an existing row
and <code class="docutils literal notranslate"><span class="pre">ignore_null_updates</span></code> is <code class="docutils literal notranslate"><span class="pre">True</span></code>, columns with a <code class="docutils literal notranslate"><span class="pre">null</span></code> will retain their existing values in the target.
This also applies to nested columns with a value of <code class="docutils literal notranslate"><span class="pre">null</span></code>. When <code class="docutils literal notranslate"><span class="pre">ignore_null_updates</span></code> is <code class="docutils literal notranslate"><span class="pre">False</span></code>,
existing values will be overwritten with <code class="docutils literal notranslate"><span class="pre">null</span></code> values.</p>
<p>This parameter is optional.</p>
<p>The default is <code class="docutils literal notranslate"><span class="pre">False</span></code>.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">apply_as_deletes</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">expr()</span></code></p>
<p>Specifies when a CDC event should be treated as a <code class="docutils literal notranslate"><span class="pre">DELETE</span></code> rather than an upsert. To handle out-of-order data,
the deleted row is temporarily retained as a tombstone in the underlying Delta table, and a view is created in
the metastore that filters out these tombstones. The retention interval can be configured with the
<code class="docutils literal notranslate"><span class="pre">pipelines.cdc.tombstoneGCThresholdInSeconds</span></code>
<a class="reference internal" href="properties.html#table-properties"><span class="std std-ref">table property</span></a>.</p>
<p>You can specify either:</p>
<ul class="simple">
<li><p>A string: <code class="docutils literal notranslate"><span class="pre">&quot;Operation</span> <span class="pre">=</span> <span class="pre">'DELETE'&quot;</span></code></p></li>
<li><p>A Spark SQL <code class="docutils literal notranslate"><span class="pre">expr()</span></code> function: <code class="docutils literal notranslate"><span class="pre">expr(&quot;Operation</span> <span class="pre">=</span> <span class="pre">'DELETE'&quot;)</span></code></p></li>
</ul>
<p>This parameter is optional.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">apply_as_truncates</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">expr()</span></code></p>
<p>Specifies when a CDC event should be treated as a full table <code class="docutils literal notranslate"><span class="pre">TRUNCATE</span></code>. Because this clause triggers a full
truncate  of the target table, it should be used only for specific use cases requiring this functionality.</p>
<p>The <code class="docutils literal notranslate"><span class="pre">apply_as_truncates</span></code> parameter is supported only for SCD type 1. SCD type 2 does not support truncate.</p>
<p>You can specify either:</p>
<ul class="simple">
<li><p>A string: <code class="docutils literal notranslate"><span class="pre">&quot;Operation</span> <span class="pre">=</span> <span class="pre">'TRUNCATE'&quot;</span></code></p></li>
<li><p>A Spark SQL <code class="docutils literal notranslate"><span class="pre">expr()</span></code> function: <code class="docutils literal notranslate"><span class="pre">expr(&quot;Operation</span> <span class="pre">=</span> <span class="pre">'TRUNCATE'&quot;)</span></code></p></li>
</ul>
<p>This parameter is optional.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">column_list</span></code></strong></p>
<p><strong><code class="docutils literal notranslate"><span class="pre">except_column_list</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">list</span></code></p>
<p>A subset of columns to include in the target table. Use <code class="docutils literal notranslate"><span class="pre">column_list</span></code> to specify the complete list of columns
to include. Use <code class="docutils literal notranslate"><span class="pre">except_column_list</span></code> to specify the columns to exclude. You can declare either value as a list
of strings or as Spark SQL <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">column_list</span> <span class="pre">=</span> <span class="pre">[&quot;userId&quot;,</span> <span class="pre">&quot;name&quot;,</span> <span class="pre">&quot;city&quot;]</span></code>.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">column_list</span> <span class="pre">=</span> <span class="pre">[col(&quot;userId&quot;),</span> <span class="pre">col(&quot;name&quot;),</span> <span class="pre">col(&quot;city&quot;)]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">except_column_list</span> <span class="pre">=</span> <span class="pre">[&quot;operation&quot;,</span> <span class="pre">&quot;sequenceNum&quot;]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">except_column_list</span> <span class="pre">=</span> <span class="pre">[col(&quot;operation&quot;),</span> <span class="pre">col(&quot;sequenceNum&quot;)</span></code></p></li>
</ul>
<p>Arguments to <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions cannot include qualifiers. For example, you can use <code class="docutils literal notranslate"><span class="pre">col(userId)</span></code>, but you
cannot use <code class="docutils literal notranslate"><span class="pre">col(source.userId)</span></code>.</p>
<p>This parameter is optional.</p>
<p>The default is to include all columns in the target table when no <code class="docutils literal notranslate"><span class="pre">column_list</span></code> or <code class="docutils literal notranslate"><span class="pre">except_column_list</span></code>
argument is passed to the function.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">stored_as_scd_type</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">int</span></code></p>
<p>Whether to store records as SCD type 1 or SCD type 2.</p>
<p>Set to <code class="docutils literal notranslate"><span class="pre">1</span></code> for SCD type 1 or <code class="docutils literal notranslate"><span class="pre">2</span></code> for SCD type 2.</p>
<p>This clause is optional.</p>
<p>The default is SCD type 1.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">track_history_column_list</span></code></strong></p>
<p><strong><code class="docutils literal notranslate"><span class="pre">track_history_except_column_list</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">list</span></code></p>
<p>A subset of output columns to be tracked for history in the target table.
Use <code class="docutils literal notranslate"><span class="pre">track_history_column_list</span></code> to specify the complete list of columns to be tracked. Use
<code class="docutils literal notranslate"><span class="pre">track_history_except_column_list</span></code> to specify the columns to be excluded from tracking. You can declare
either value as a list of strings or as Spark SQL <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions:
- <code class="docutils literal notranslate"><span class="pre">track_history_column_list</span> <span class="pre">=</span> <span class="pre">[&quot;userId&quot;,</span> <span class="pre">&quot;name&quot;,</span> <span class="pre">&quot;city&quot;]</span></code>.
- <code class="docutils literal notranslate"><span class="pre">track_history_column_list</span> <span class="pre">=</span> <span class="pre">[col(&quot;userId&quot;),</span> <span class="pre">col(&quot;name&quot;),</span> <span class="pre">col(&quot;city&quot;)]</span></code>
- <code class="docutils literal notranslate"><span class="pre">track_history_except_column_list</span> <span class="pre">=</span> <span class="pre">[&quot;operation&quot;,</span> <span class="pre">&quot;sequenceNum&quot;]</span></code>
- <code class="docutils literal notranslate"><span class="pre">track_history_except_column_list</span> <span class="pre">=</span> <span class="pre">[col(&quot;operation&quot;),</span> <span class="pre">col(&quot;sequenceNum&quot;)</span></code></p>
<p>Arguments to <code class="docutils literal notranslate"><span class="pre">col()</span></code> functions cannot include qualifiers. For example, you can use <code class="docutils literal notranslate"><span class="pre">col(userId)</span></code>, but you
cannot use <code class="docutils literal notranslate"><span class="pre">col(source.userId)</span></code>.</p>
<p>This parameter is optional.</p>
<p>The default is to include all columns in the target table when no <code class="docutils literal notranslate"><span class="pre">track_history_column_list</span></code> or
<code class="docutils literal notranslate"><span class="pre">track_history_except_column_list</span></code> argument is passed to the function.</p>
</td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="create-a-target-table-for-cdc-output">
<span id="create-target-fn"></span><h2>Create a target table for CDC output<a class="headerlink" href="#create-a-target-table-for-cdc-output" title="Permalink to this headline"> </a></h2>
<p>Use the <code class="docutils literal notranslate"><span class="pre">create_streaming_table()</span></code> function to create a target table for the <code class="docutils literal notranslate"><span class="pre">apply_changes()</span></code> output records.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">create_target_table()</span></code> and <code class="docutils literal notranslate"><span class="pre">create_streaming_live_table()</span></code> functions are deprecated. Databricks recommends updating existing code to use the <code class="docutils literal notranslate"><span class="pre">create_streaming_table()</span></code> function.</p>
</div>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">create_streaming_table</span><span class="p">(</span>
  <span class="n">name</span> <span class="o">=</span> <span class="s2">&quot;&lt;table-name&gt;&quot;</span><span class="p">,</span>
  <span class="n">comment</span> <span class="o">=</span> <span class="s2">&quot;&lt;comment&gt;&quot;</span>
  <span class="n">spark_conf</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">table_properties</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">partition_cols</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;&lt;partition-column&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;partition-column&gt;&quot;</span><span class="p">],</span>
  <span class="n">path</span><span class="o">=</span><span class="s2">&quot;&lt;storage-location-path&gt;&quot;</span><span class="p">,</span>
  <span class="n">schema</span><span class="o">=</span><span class="s2">&quot;schema-definition&quot;</span><span class="p">,</span>
  <span class="n">expect_all</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">expect_all_or_drop</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">},</span>
  <span class="n">expect_all_or_fail</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;&lt;key&gt;&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&quot;</span><span class="p">,</span> <span class="s2">&quot;&lt;key&quot;</span> <span class="p">:</span> <span class="s2">&quot;&lt;value&gt;&quot;</span><span class="p">}</span>
<span class="p">)</span>
</pre></div>
</div>
<table class="docutils align-default">
<colgroup>
<col style="width: 100%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Arguments</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">name</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>The table name.</p>
<p>This parameter is required.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">comment</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>An optional description for the table.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">spark_conf</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>An optional list of Spark configurations for the execution of this query.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">table_properties</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>An optional list of <a class="reference internal" href="properties.html"><span class="doc">table properties</span></a> for the table.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">partition_cols</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">array</span></code></p>
<p>An optional list of one or more columns to use for partitioning the table.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">path</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code></p>
<p>An optional storage location for table data. If not set, the system will default to the pipeline storage
location.</p>
</td>
</tr>
<tr class="row-even"><td><p><strong><code class="docutils literal notranslate"><span class="pre">schema</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">str</span></code> or <code class="docutils literal notranslate"><span class="pre">StructType</span></code></p>
<p>An optional schema definition for the table. Schemas can be defined as a SQL DDL string, or with a Python
<code class="docutils literal notranslate"><span class="pre">StructType</span></code>.</p>
</td>
</tr>
<tr class="row-odd"><td><p><strong><code class="docutils literal notranslate"><span class="pre">expect_all</span></code></strong>
<strong><code class="docutils literal notranslate"><span class="pre">expect_all_or_drop</span></code></strong>
<strong><code class="docutils literal notranslate"><span class="pre">expect_all_or_fail</span></code></strong></p>
<p>Type: <code class="docutils literal notranslate"><span class="pre">dict</span></code></p>
<p>Optional data quality constraints for the table.
See <a class="reference internal" href="expectations.html#expect-all"><span class="std std-ref">multiple expectations</span></a>.</p>
</td>
</tr>
</tbody>
</table>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>