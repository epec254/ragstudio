

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Complete a hands-on tutorial that demonstrates how to use Databricks Asset Bundles to work with Databricks jobs." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Develop a job on Databricks by using Databricks Asset Bundles">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Develop a job on Databricks by using Databricks Asset Bundles &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/workflows/jobs/how-to/use-bundles-with-jobs.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/workflows/jobs/how-to/use-bundles-with-jobs.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/workflows/jobs/how-to/use-bundles-with-jobs.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../../en/workflows/jobs/how-to/use-bundles-with-jobs.html" class="notranslate">English</option>
    <option value="../../../../ja/workflows/jobs/how-to/use-bundles-with-jobs.html" class="notranslate">日本語</option>
    <option value="../../../../pt/workflows/jobs/how-to/use-bundles-with-jobs.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Develop a job on Databricks by using Databricks Asset Bundles</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="develop-a-job-on-databricks-by-using-databricks-asset-bundles">
<h1>Develop a job on Databricks by using Databricks Asset Bundles<a class="headerlink" href="#develop-a-job-on-databricks-by-using-databricks-asset-bundles" title="Permalink to this headline"> </a></h1>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>This feature is in <a class="reference internal" href="../../../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<p><em>Databricks Asset Bundles</em>, also known simply as <em>bundles</em>, enable you to programmatically validate, deploy, and run Databricks resources such as jobs. You can also use bundles to programmatically manage Delta Live Tables pipelines and to work with MLOps Stacks. See <a class="reference internal" href="../../../dev-tools/bundles/index.html"><span class="doc">What are Databricks Asset Bundles?</span></a>.</p>
<p>This article describes steps that you can complete from a local development setup to use a bundle that programmatically manages a job. See <a class="reference internal" href="../../index.html"><span class="doc">Introduction to Databricks Workflows</span></a>.</p>
<p>If you have existing jobs that were created by using the Databricks Workflows user interface or API that you want to move to bundles, then you must recreate them as bundle configuration files. To do so, Databricks recommends that you first create a bundle by using the steps below and the validate whether the bundle works. You can then add job definitions, notebooks, and other sources to the bundle. See <a class="reference internal" href="#existing-job"><span class="std std-ref">Add an existing job definition to a bundle</span></a>.</p>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Databricks CLI version 0.205 or above. To check your installed version of the Databricks CLI, run the command <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">-v</span></code>. To install Databricks CLI version 0.205 or above, see <a class="reference internal" href="../../../dev-tools/cli/install.html"><span class="doc">Install or update the Databricks CLI</span></a>.</p></li>
<li><p>The remote workspace must have workspace files enabled. See <a class="reference internal" href="../../../files/workspace.html"><span class="doc">What are workspace files?</span></a>.</p></li>
</ul>
</div>
<div class="section" id="decision-create-the-bundle-manually-or-by-using-a-template">
<h2>Decision: Create the bundle manually or by using a template<a class="headerlink" href="#decision-create-the-bundle-manually-or-by-using-a-template" title="Permalink to this headline"> </a></h2>
<p>Decide whether you want to create a starter bundle by using a template or to create the bundle manually. Creating the bundle by using a template is faster and easier, but the bundle might produce content that is not needed, and the bundle’s default settings must be further customized for real applications. Creating the bundle manually gives you full control over the bundle’s settings, but you must be familiar with how bundles work, as you are doing all of the work from the beginning. Choose one of the following sets of steps:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#create-the-bundle-by-using-a-template"><span class="std std-ref">Create the bundle by using a template</span></a></p></li>
<li><p><a class="reference internal" href="#create-the-bundle-manually"><span class="std std-ref">Create the bundle manually</span></a></p></li>
</ul>
</div>
<div class="section" id="create-the-bundle-by-using-a-template">
<h2>Create the bundle by using a template<a class="headerlink" href="#create-the-bundle-by-using-a-template" title="Permalink to this headline"> </a></h2>
<p>In these steps, you create the bundle by using the Databricks default bundle template for Python. These steps guide you to create a bundle that consists of a notebook or Python code, paired with the the definition of a job to run it. You then validate, deploy, and run the deployed job within your Databricks workspace.</p>
<div class="section" id="step-1-set-up-authentication">
<h3>Step 1: Set up authentication<a class="headerlink" href="#step-1-set-up-authentication" title="Permalink to this headline"> </a></h3>
<p>In this step, you set up authentication between the Databricks CLI on your development machine and your Databricks workspace. This article assumes that you want to use a Databricks personal access token and a corresponding Databricks configuration profile for authentication. For additional authentication types you can use instead, see <a class="reference internal" href="../../../dev-tools/auth/index.html#auth-types"><span class="std std-ref">Supported Databricks authentication types</span></a>.</p>
<p>To create a personal access token, do the following:</p>
<ol class="arabic simple">
<li><p>In your Databricks workspace, click your Databricks username in the top bar, and then select <strong>User Settings</strong> from the drop down.</p></li>
<li><p>Click <strong>Developer</strong>.</p></li>
<li><p>Next to <strong>Access tokens</strong>, click <strong>Manage</strong>.</p></li>
<li><p>Click <strong>Generate new token</strong>.</p></li>
<li><p>(Optional) Enter a comment that helps you to identify this token in the future, and change the token’s default lifetime of 90 days. To create a token with no lifetime (not recommended), leave the <strong>Lifetime (days)</strong> box empty (blank).</p></li>
<li><p>Click <strong>Generate</strong>.</p></li>
<li><p>Copy the displayed token to a secure location, and then click <strong>Done</strong>.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Be sure to save the copied token in a secure location. Do not share your copied token with others. If you lose the copied token, you cannot regenerate that exact same token. Instead, you must repeat this procedure to create a new token. If you lose the copied token, or you believe that the token has been compromised, Databricks strongly recommends that you immediately delete that token from your workspace by clicking the trash can (<strong>Revoke</strong>) icon next to the token on the <strong>Access tokens</strong> page.</p>
<p>If you are not able to create or use tokens in your workspace, this might be because your workspace administrator has disabled tokens or has not given you permission to create or use tokens. See your workspace administrator or the following:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../administration-guide/access-control/tokens.html#enable-tokens"><span class="std std-ref">Enable or disable personal access token authentication for the workspace</span></a></p></li>
<li><p><a class="reference internal" href="../../../security/auth-authz/api-access-permissions.html#pat"><span class="std std-ref">Personal access token permissions</span></a></p></li>
</ul>
</div>
<p>To create a configuration profile that uses this personal access token, do the following:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following procedure uses the <a class="reference internal" href="../../../dev-tools/cli/install.html"><span class="doc">Databricks CLI</span></a> to create a Databricks <a class="reference internal" href="../../../dev-tools/auth/index.html#config-profiles"><span class="std std-ref">configuration profile</span></a> with the name <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code>. If you already have a <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile, this procedure overwrites your existing <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile.</p>
<p>To check whether you already have a <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile, and to view this profile’s settings if it exists, use the Databricks CLI to run the command <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">auth</span> <span class="pre">env</span> <span class="pre">--profile</span> <span class="pre">DEFAULT</span></code>.</p>
<p>To create a configuration profile with a name other than <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code>, replace the <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> part of <code class="docutils literal notranslate"><span class="pre">--profile</span> <span class="pre">DEFAULT</span></code> in the following <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">configure</span></code> command with a different name for the configuration profile.</p>
</div>
<ol class="arabic">
<li><p>Use the <a class="reference internal" href="../../../dev-tools/cli/install.html"><span class="doc">Databricks CLI</span></a> to create a Databricks <a class="reference internal" href="../../../dev-tools/auth/index.html#config-profiles"><span class="std std-ref">configuration profile</span></a> named <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> that uses Databricks personal access token authentication. To do this, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>configure<span class="w"> </span>--profile<span class="w"> </span>DEFAULT
</pre></div>
</div>
</li>
<li><p>For the prompt <strong>Databricks Host</strong>, enter your Databricks <a class="reference internal" href="../../../workspace/workspace-details.html#workspace-url"><span class="std std-ref">workspace instance URL</span></a>, for example <code class="docutils literal notranslate"><span class="pre">https://dbc-a1b2345c-d6e7.cloud.databricks.com</span></code>.</p></li>
<li><p>For the prompt <strong>Personal Access Token</strong>, enter the Databricks personal access token for your workspace.</p></li>
</ol>
</div>
<div class="section" id="step-2-create-the-bundle">
<h3>Step 2: Create the bundle<a class="headerlink" href="#step-2-create-the-bundle" title="Permalink to this headline"> </a></h3>
<p>A bundle contains the artifacts you want to deploy and the settings for the resources that you want to run.</p>
<ol class="arabic">
<li><p>Use your terminal or command prompt to switch to a directory on your local development machine that will contain the template’s generated bundle.</p></li>
<li><p>Use the Dataricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">init</span></code> command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>init
</pre></div>
</div>
</li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">Template</span> <span class="pre">to</span> <span class="pre">use</span></code>, leave the default value of <code class="docutils literal notranslate"><span class="pre">default-python</span></code> by pressing <code class="docutils literal notranslate"><span class="pre">Enter</span></code>.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">Unique</span> <span class="pre">name</span> <span class="pre">for</span> <span class="pre">this</span> <span class="pre">project</span></code>, leave the default value of <code class="docutils literal notranslate"><span class="pre">my_project</span></code>, or type a different value, and then press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>. This determines the name of the root directory for this bundle. This root directory is created within your current working directory.</p></li>
<li><p>If you want your bundle to include a sample notebook, for <code class="docutils literal notranslate"><span class="pre">Include</span> <span class="pre">a</span> <span class="pre">stub</span> <span class="pre">(sample)</span> <span class="pre">notebook</span></code>, leave the default value of <code class="docutils literal notranslate"><span class="pre">yes</span></code> by pressing <code class="docutils literal notranslate"><span class="pre">Enter</span></code>. This creates a sample notebook in the <code class="docutils literal notranslate"><span class="pre">src</span></code> directory within your bundle.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">Include</span> <span class="pre">a</span> <span class="pre">stub</span> <span class="pre">(sample)</span> <span class="pre">DLT</span> <span class="pre">pipeline</span></code>, select <code class="docutils literal notranslate"><span class="pre">no</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>. This instructs the Databricks CLI to not define a sample Delta Live Tables pipeline in your bundle.</p></li>
<li><p>For <code class="docutils literal notranslate"><span class="pre">Include</span> <span class="pre">a</span> <span class="pre">stub</span> <span class="pre">(sample)</span> <span class="pre">Python</span> <span class="pre">package</span></code>, select <code class="docutils literal notranslate"><span class="pre">no</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>. This instructs the Databricks CLI to not add sample Python wheel package files or related build instructions to your bundle.</p></li>
</ol>
</div>
<div class="section" id="step-3-explore-the-bundle">
<h3>Step 3: Explore the bundle<a class="headerlink" href="#step-3-explore-the-bundle" title="Permalink to this headline"> </a></h3>
<p>To view the files that the template generated, switch to the root directory of your newly created bundle and open this directory with your preferred IDE, for example Visual Studio Code. Files of particular interest include the following:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">databricks.yml</span></code>: This file specifies the bundle’s programmatic name, includes a reference to the job definition, and specifies settings about the target workspace.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">resources/&lt;project-name&gt;_job.yml</span></code>: This file specifies the job’s settings.</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">src/notebook.ipynb</span></code>: This file is a notebook that, when run, simply initializes an RDD that contains the numbers 1 through 10.</p></li>
</ul>
<p>For customizing jobs, the mappings within a job declaration correspond to the create job operation’s request payload as defined in <a class="reference external" href="https://docs.databricks.com/api/workspace/jobs/create">POST /api/2.1/jobs/create</a> in the REST API reference, expressed in YAML format.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can define, combine, and override the settings for new job clusters in bundles by using the techniques described in <a class="reference internal" href="../../../dev-tools/bundles/cluster-override.html"><span class="doc">Override cluster settings in Databricks Asset Bundles</span></a>.</p>
</div>
</div>
<div class="section" id="step-4-validate-the-projects-bundle-configuration-file">
<h3>Step 4: Validate the project’s bundle configuration file<a class="headerlink" href="#step-4-validate-the-projects-bundle-configuration-file" title="Permalink to this headline"> </a></h3>
<p>In this step, you check whether the bundle configuration is valid.</p>
<ol class="arabic">
<li><p>From the root directory, use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">validate</span></code> command, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>validate
</pre></div>
</div>
</li>
<li><p>If a JSON representation of the bundle configuration is returned, then the validation succeeded. If any errors are returned, fix the errors, and then repeat this step.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat this step to check whether your bundle configuration is still valid.</p>
</div>
<div class="section" id="step-5-deploy-the-local-project-to-the-remote-workspace">
<h3>Step 5: Deploy the local project to the remote workspace<a class="headerlink" href="#step-5-deploy-the-local-project-to-the-remote-workspace" title="Permalink to this headline"> </a></h3>
<p>In this step, you deploy the local notebook to your remote Databricks workspace and create the Databricks job within your workspace.</p>
<ol class="arabic">
<li><p>From the bundle root, use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">deploy</span></code> command as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>deploy<span class="w"> </span>-t<span class="w"> </span>dev
</pre></div>
</div>
</li>
<li><p>Check whether the local notebook was deployed: In your Databricks workspace’s sidebar, click <strong>Workspace</strong>.</p></li>
<li><p>Click into the <strong>Users &gt; <code class="docutils literal notranslate"><span class="pre">&lt;your-username&gt;</span></code> &gt; .bundle &gt; <code class="docutils literal notranslate"><span class="pre">&lt;project-name&gt;</span></code> &gt; dev &gt; files &gt; src</strong> folder. The notebook should be in this folder.</p></li>
<li><p>Check whether the job was created: In your Databricks workspace’s sidebar, click <strong>Workflows</strong>.</p></li>
<li><p>On the <strong>Jobs</strong> tab, click <strong>[dev <code class="docutils literal notranslate"><span class="pre">&lt;your-username&gt;</span></code>] <code class="docutils literal notranslate"><span class="pre">&lt;project-name&gt;_job</span></code></strong>.</p></li>
<li><p>Click the <strong>Tasks</strong> tab. There should be one task: <strong>notebook_task</strong>.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat steps 4-5 to check whether your bundle configuration is still valid and then redeploy the project.</p>
</div>
<div class="section" id="step-6-run-the-deployed-project">
<h3>Step 6: Run the deployed project<a class="headerlink" href="#step-6-run-the-deployed-project" title="Permalink to this headline"> </a></h3>
<p>In this step, you run the Databricks job in your workspace.</p>
<ol class="arabic">
<li><p>From the root directory, use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">run</span></code> command, as follows, replacing <code class="docutils literal notranslate"><span class="pre">&lt;project-name&gt;</span></code> with the name of your project from Step 2:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>run<span class="w"> </span>-t<span class="w"> </span>dev<span class="w"> </span>&lt;project-name&gt;_job
</pre></div>
</div>
</li>
<li><p>Copy the value of <code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">URL</span></code> that appears in your terminal and paste this value into your web browser to open your Databricks workspace.</p></li>
<li><p>In your Databricks workspace, after the job task completes successfully and shows a green title bar, click the job task to see the results.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat steps 4-6 to check whether your bundle configuration is still valid, redeploy the project, and run the redeployed project.</p>
</div>
<div class="section" id="step-7-clean-up">
<h3>Step 7: Clean up<a class="headerlink" href="#step-7-clean-up" title="Permalink to this headline"> </a></h3>
<p>In this step, you delete the deployed notebook and the job from your workspace.</p>
<ol class="arabic">
<li><p>From the root directory, use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">destroy</span></code> command, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>destroy
</pre></div>
</div>
</li>
<li><p>Confirm the job deletion request: When prompted to permanently destroy resources, type <code class="docutils literal notranslate"><span class="pre">y</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>.</p></li>
<li><p>Confirm the notebook deletion request: When prompted to permanently destroy the previously deployed folder and all of its files, type <code class="docutils literal notranslate"><span class="pre">y</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>.</p></li>
<li><p>If you also want to delete the bundle from your development machine, you can now delete the local directory from Step 2.</p></li>
</ol>
<p>You have reached the end of the steps for creating a bundle by using a template.</p>
</div>
</div>
<div class="section" id="create-the-bundle-manually">
<h2>Create the bundle manually<a class="headerlink" href="#create-the-bundle-manually" title="Permalink to this headline"> </a></h2>
<p>In these steps, you create the bundle from the beginning. These steps guide you to create a bundle that consists of two notebooks and the definition of a Databricks job to run these notebooks. You then validate, deploy, and run the deployed notebooks from the job within your Databricks workspace. These steps automate the quickstart titled <a class="reference internal" href="../jobs-quickstart.html"><span class="doc">Create your first workflow with a Databricks job</span></a>.</p>
<div class="section" id="step-1-create-the-bundle">
<h3>Step 1: Create the bundle<a class="headerlink" href="#step-1-create-the-bundle" title="Permalink to this headline"> </a></h3>
<p>A bundle contains the artifacts you want to deploy and the settings for the resources you want to run.</p>
<ol class="arabic simple">
<li><p>Create or identify an empty directory on your development machine.</p></li>
<li><p>Switch to the empty directory in your terminal, or open the empty directory in your IDE.</p></li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>Your empty directory could be associated with a cloned repository that is managed by a Git provider. This enables you to manage your bundle with external version control and to more easily collaborate with other developers and IT professionals on your project. However, to help simplify this demonstration, a cloned repo is not used here.</p>
<p>If you choose to clone a repo for this demo, Databricks recommends that the repo is empty or has only basic files in it such as <code class="docutils literal notranslate"><span class="pre">README</span></code> and <code class="docutils literal notranslate"><span class="pre">.gitignore</span></code>. Otherwise, any pre-existing files in the repo might be unnecessarily synchronized to your Databricks workspace.</p>
</div>
</div>
<div class="section" id="step-2-add-notebooks-to-the-project">
<h3>Step 2: Add notebooks to the project<a class="headerlink" href="#step-2-add-notebooks-to-the-project" title="Permalink to this headline"> </a></h3>
<p>In this step, you add two notebooks to your project. The first notebook gets a list of trending baby names since 2007 from the New York State Department of Health’s public data sources. See <a class="reference external" href="https://health.data.ny.gov/Health/Baby-Names-Beginning-2007/myeu-hzra">Baby Names: Trending by Name: Beginning 2007</a> on the department’s website. This first notebook then saves this data within your Databricks workspace’s <code class="docutils literal notranslate"><span class="pre">FileStore</span></code> folder in DBFS. The second notebook queries the saved data and displays aggregated counts of the baby names by first name and sex for 2014.</p>
<ol class="arabic">
<li><p>From the directory’s root, create the first notebook, a file named <code class="docutils literal notranslate"><span class="pre">retrieve-baby-names.py</span></code>.</p></li>
<li><p>Add the following code to the <code class="docutils literal notranslate"><span class="pre">retrieve-baby-names.py</span></code> file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Databricks notebook source</span>
<span class="kn">import</span> <span class="nn">requests</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s1">&#39;http://health.data.ny.gov/api/views/myeu-hzra/rows.csv&#39;</span><span class="p">)</span>
<span class="n">csvfile</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">content</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="s1">&#39;utf-8&#39;</span><span class="p">)</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">put</span><span class="p">(</span><span class="s2">&quot;dbfs:/FileStore/babynames.csv&quot;</span><span class="p">,</span> <span class="n">csvfile</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>Create the second notebook, a file named <code class="docutils literal notranslate"><span class="pre">filter-baby-names.py</span></code>, in the same directory.</p></li>
<li><p>Add the following code to the <code class="docutils literal notranslate"><span class="pre">filter-baby-names.py</span></code> file:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Databricks notebook source</span>
<span class="n">babynames</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;csv&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;header&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">option</span><span class="p">(</span><span class="s2">&quot;inferSchema&quot;</span><span class="p">,</span> <span class="s2">&quot;true&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;dbfs:/FileStore/babynames.csv&quot;</span><span class="p">)</span>
<span class="n">babynames</span><span class="o">.</span><span class="n">createOrReplaceTempView</span><span class="p">(</span><span class="s2">&quot;babynames_table&quot;</span><span class="p">)</span>
<span class="n">years</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">sql</span><span class="p">(</span><span class="s2">&quot;select distinct(Year) from babynames_table&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">rdd</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">row</span> <span class="p">:</span> <span class="n">row</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span><span class="o">.</span><span class="n">collect</span><span class="p">()</span>
<span class="n">years</span><span class="o">.</span><span class="n">sort</span><span class="p">()</span>
<span class="n">dbutils</span><span class="o">.</span><span class="n">widgets</span><span class="o">.</span><span class="n">dropdown</span><span class="p">(</span><span class="s2">&quot;year&quot;</span><span class="p">,</span> <span class="s2">&quot;2014&quot;</span><span class="p">,</span> <span class="p">[</span><span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">years</span><span class="p">])</span>
<span class="n">display</span><span class="p">(</span><span class="n">babynames</span><span class="o">.</span><span class="n">filter</span><span class="p">(</span><span class="n">babynames</span><span class="o">.</span><span class="n">Year</span> <span class="o">==</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">widgets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="s2">&quot;year&quot;</span><span class="p">)))</span>
</pre></div>
</div>
</li>
</ol>
</div>
<div class="section" id="step-3-add-a-bundle-configuration-schema-file-to-the-project">
<h3>Step 3: Add a bundle configuration schema file to the project<a class="headerlink" href="#step-3-add-a-bundle-configuration-schema-file-to-the-project" title="Permalink to this headline"> </a></h3>
<p>If you are using an IDE such as Visual Studio Code, PyCharm Professional, or IntelliJ IDEA Ultimate that provides support for YAML files and JSON schema files, you can use your IDE to not only create the bundle configuration schema file but to check your project’s bundle configuration file syntax and formatting and provide code completion hints, as follows. Note that while the bundle configuration file that you will create later in Step 5 is YAML-based, the bundle configuration schema file in this step is JSON-based.</p>
<div class="js-code-language-tabs compound">
<div class="compound-first compound" lang="Visual&amp;nbsp;Studio&amp;nbsp;Code">
<ol class="arabic">
<li><p>Add YAML language server support to Visual Studio Code, for example by installing the <a class="reference external" href="https://marketplace.visualstudio.com/items?itemName=redhat.vscode-yaml">YAML</a> extension from the Visual Studio Code Marketplace.</p></li>
<li><p>Generate the Databricks Asset Bundle configuration JSON schema file by using the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">schema</span></code> command and redirect the output to a JSON file. For example, generate a file named <code class="docutils literal notranslate"><span class="pre">bundle_config_schema.json</span></code> within the current directory, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>schema<span class="w"> </span>&gt;<span class="w"> </span>bundle_config_schema.json
</pre></div>
</div>
</li>
<li><p>Note that later in Step 5, you will add the following comment to the beginning of your bundle configuration file, which associates your bundle configuration file with the specified JSON schema file:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># yaml-language-server: $schema=bundle_config_schema.json</span>
</pre></div>
</div>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In the preceding comment, if your Databricks Asset Bundle configuration JSON schema file is in a different path, replace <code class="docutils literal notranslate"><span class="pre">bundle_config_schema.json</span></code> with the full path to your schema file.</p>
</div>
</li>
</ol>
</div>
<div class="compound-middle compound" lang="PyCharm&amp;nbsp;Professsional">
<ol class="arabic">
<li><p>Generate the Databricks Asset Bundle configuration JSON schema file by using the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">schema</span></code> command and redirect the output to a JSON file. For example, generate a file named <code class="docutils literal notranslate"><span class="pre">bundle_config_schema.json</span></code> within the current directory, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>schema<span class="w"> </span>&gt;<span class="w"> </span>bundle_config_schema.json
</pre></div>
</div>
</li>
<li><p>Configure PyCharm to recognize the bundle configuration JSON schema file, and then complete the JSON schema mapping, by following the instructions in <a class="reference external" href="https://www.jetbrains.com/help/pycharm/json.html#ws_json_schema_add_custom_procedure">Configure a custom JSON schema</a>.</p></li>
<li><p>Note that later in Step 5, you will use PyCharm to create or open a bundle configuration file. By convention, this file is named <code class="docutils literal notranslate"><span class="pre">databricks.yml</span></code>.</p></li>
</ol>
</div>
<div class="compound-last compound" lang="IntelliJ&amp;nbsp;IDEA&amp;nbsp;Ultimate">
<ol class="arabic">
<li><p>Generate the Databricks Asset Bundle configuration JSON schema file by using the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">schema</span></code> command and redirect the output to a JSON file. For example, generate a file named <code class="docutils literal notranslate"><span class="pre">bundle_config_schema.json</span></code> within the current directory, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>schema<span class="w"> </span>&gt;<span class="w"> </span>bundle_config_schema.json
</pre></div>
</div>
</li>
<li><p>Configure IntelliJ IDEA to recognize the bundle configuration JSON schema file, and then complete the JSON schema mapping, by following the instructions in <a class="reference external" href="https://www.jetbrains.com/help/idea/json.html#ws_json_schema_add_custom_procedure">Configure a custom JSON schema</a>.</p></li>
<li><p>Note that later in Step 5, you will use IntelliJ IDEA to create or open a bundle configuration file. By convention, this file is named <code class="docutils literal notranslate"><span class="pre">databricks.yml</span></code>.</p></li>
</ol>
</div>
</div>
</div>
<div class="section" id="step-4-set-up-authentication">
<h3>Step 4: Set up authentication<a class="headerlink" href="#step-4-set-up-authentication" title="Permalink to this headline"> </a></h3>
<p>In this step, you set up authentication between the Databricks CLI on your development machine and your Databricks workspace. This article assumes that you want to use a Databricks personal access token and a corresponding Databricks configuration profile for authentication. For additional authentication types you can use instead, see <a class="reference internal" href="../../../dev-tools/auth/index.html#auth-types"><span class="std std-ref">Supported Databricks authentication types</span></a>.</p>
<p>To create a personal access token, do the following:</p>
<ol class="arabic simple">
<li><p>In your Databricks workspace, click your Databricks username in the top bar, and then select <strong>User Settings</strong> from the drop down.</p></li>
<li><p>Click <strong>Developer</strong>.</p></li>
<li><p>Next to <strong>Access tokens</strong>, click <strong>Manage</strong>.</p></li>
<li><p>Click <strong>Generate new token</strong>.</p></li>
<li><p>(Optional) Enter a comment that helps you to identify this token in the future, and change the token’s default lifetime of 90 days. To create a token with no lifetime (not recommended), leave the <strong>Lifetime (days)</strong> box empty (blank).</p></li>
<li><p>Click <strong>Generate</strong>.</p></li>
<li><p>Copy the displayed token to a secure location, and then click <strong>Done</strong>.</p></li>
</ol>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Be sure to save the copied token in a secure location. Do not share your copied token with others. If you lose the copied token, you cannot regenerate that exact same token. Instead, you must repeat this procedure to create a new token. If you lose the copied token, or you believe that the token has been compromised, Databricks strongly recommends that you immediately delete that token from your workspace by clicking the trash can (<strong>Revoke</strong>) icon next to the token on the <strong>Access tokens</strong> page.</p>
<p>If you are not able to create or use tokens in your workspace, this might be because your workspace administrator has disabled tokens or has not given you permission to create or use tokens. See your workspace administrator or the following:</p>
<ul class="simple">
<li><p><a class="reference internal" href="../../../administration-guide/access-control/tokens.html#enable-tokens"><span class="std std-ref">Enable or disable personal access token authentication for the workspace</span></a></p></li>
<li><p><a class="reference internal" href="../../../security/auth-authz/api-access-permissions.html#pat"><span class="std std-ref">Personal access token permissions</span></a></p></li>
</ul>
</div>
<p>To create a configuration profile that uses this personal access token, do the following:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following procedure uses the <a class="reference internal" href="../../../dev-tools/cli/install.html"><span class="doc">Databricks CLI</span></a> to create a Databricks <a class="reference internal" href="../../../dev-tools/auth/index.html#config-profiles"><span class="std std-ref">configuration profile</span></a> with the name <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code>. If you already have a <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile, this procedure overwrites your existing <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile.</p>
<p>To check whether you already have a <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> configuration profile, and to view this profile’s settings if it exists, use the Databricks CLI to run the command <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">auth</span> <span class="pre">env</span> <span class="pre">--profile</span> <span class="pre">DEFAULT</span></code>.</p>
<p>To create a configuration profile with a name other than <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code>, replace the <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> part of <code class="docutils literal notranslate"><span class="pre">--profile</span> <span class="pre">DEFAULT</span></code> in the following <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">configure</span></code> command with a different name for the configuration profile.</p>
</div>
<ol class="arabic">
<li><p>Use the <a class="reference internal" href="../../../dev-tools/cli/install.html"><span class="doc">Databricks CLI</span></a> to create a Databricks <a class="reference internal" href="../../../dev-tools/auth/index.html#config-profiles"><span class="std std-ref">configuration profile</span></a> named <code class="docutils literal notranslate"><span class="pre">DEFAULT</span></code> that uses Databricks personal access token authentication. To do this, run the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>configure<span class="w"> </span>--profile<span class="w"> </span>DEFAULT
</pre></div>
</div>
</li>
<li><p>For the prompt <strong>Databricks Host</strong>, enter your Databricks <a class="reference internal" href="../../../workspace/workspace-details.html#workspace-url"><span class="std std-ref">workspace instance URL</span></a>, for example <code class="docutils literal notranslate"><span class="pre">https://dbc-a1b2345c-d6e7.cloud.databricks.com</span></code>.</p></li>
<li><p>For the prompt <strong>Personal Access Token</strong>, enter the Databricks personal access token for your workspace.</p></li>
</ol>
</div>
<div class="section" id="step-5-add-a-bundle-configuration-file-to-the-project">
<h3>Step 5: Add a bundle configuration file to the project<a class="headerlink" href="#step-5-add-a-bundle-configuration-file-to-the-project" title="Permalink to this headline"> </a></h3>
<p>In this step, you define how you want to deploy and run the two notebooks. For this demo, you want to use a Databricks job to run the first notebook and then the second notebook. Because the first notebook saves the data and the second notebook queries the saved data, you want the first notebook to finish running before the second notebook starts. You model these objectives within a bundle configuration file in your project.</p>
<ol class="arabic simple">
<li><p>From the directory’s root, create the bundle configuration file, a file named <code class="docutils literal notranslate"><span class="pre">databricks.yml</span></code>.</p></li>
<li><p>Add the following code to the <code class="docutils literal notranslate"><span class="pre">databricks.yml</span></code> file, replacing <code class="docutils literal notranslate"><span class="pre">&lt;workspace-url&gt;</span></code> with your <a class="reference internal" href="../../../workspace/workspace-details.html#workspace-url"><span class="std std-ref">workspace URL</span></a>, for example <code class="docutils literal notranslate"><span class="pre">https://dbc-a1b2345c-d6e7.cloud.databricks.com</span></code>. This URL must match the one in your <code class="docutils literal notranslate"><span class="pre">.databrickscfg</span></code> file:</p></li>
</ol>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>The first line, starting with <code class="docutils literal notranslate"><span class="pre">#</span> <span class="pre">yaml-language-server</span></code>, is required only if your IDE supports it. See Step 3 earlier for details.</p>
</div>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="c1"># yaml-language-server: $schema=bundle_config_schema.json</span>
<span class="nt">bundle</span><span class="p">:</span>
<span class="w">  </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">baby-names</span>

<span class="nt">resources</span><span class="p">:</span>
<span class="w">  </span><span class="nt">jobs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">retrieve-filter-baby-names-job</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">retrieve-filter-baby-names-job</span>
<span class="w">      </span><span class="nt">job_clusters</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">job_cluster_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">common-cluster</span>
<span class="w">          </span><span class="nt">new_cluster</span><span class="p">:</span>
<span class="w">            </span><span class="nt">spark_version</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">12.2.x-scala2.12</span>
<span class="w">            </span><span class="nt">node_type_id</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">i3.xlarge</span>
<span class="w">            </span><span class="nt">num_workers</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">1</span>
<span class="w">      </span><span class="nt">tasks</span><span class="p">:</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">task_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">retrieve-baby-names-task</span>
<span class="w">          </span><span class="nt">job_cluster_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">common-cluster</span>
<span class="w">          </span><span class="nt">notebook_task</span><span class="p">:</span>
<span class="w">            </span><span class="nt">notebook_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./retrieve-baby-names</span>
<span class="w">        </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">task_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">filter-baby-names-task</span>
<span class="w">          </span><span class="nt">depends_on</span><span class="p">:</span>
<span class="w">            </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">task_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">retrieve-baby-names-task</span>
<span class="w">          </span><span class="nt">job_cluster_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">common-cluster</span>
<span class="w">          </span><span class="nt">notebook_task</span><span class="p">:</span>
<span class="w">            </span><span class="nt">notebook_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./filter-baby-names</span>

<span class="nt">targets</span><span class="p">:</span>
<span class="w">  </span><span class="nt">development</span><span class="p">:</span>
<span class="w">    </span><span class="nt">workspace</span><span class="p">:</span>
<span class="w">      </span><span class="nt">host</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">&lt;workspace-url&gt;</span>
</pre></div>
</div>
<p>For customizing jobs, the mappings within a job declaration correspond to the create job operation’s request payload as defined in <a class="reference external" href="https://docs.databricks.com/api/workspace/jobs/create">POST /api/2.1/jobs/create</a> in the REST API reference, expressed in YAML format.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>You can define, combine, and override the settings for new job clusters in bundles by using the techniques described in <a class="reference internal" href="../../../dev-tools/bundles/cluster-override.html"><span class="doc">Override cluster settings in Databricks Asset Bundles</span></a>.</p>
</div>
</div>
<div class="section" id="step-6-validate-the-projects-bundle-configuration-file">
<h3>Step 6: Validate the project’s bundle configuration file<a class="headerlink" href="#step-6-validate-the-projects-bundle-configuration-file" title="Permalink to this headline"> </a></h3>
<p>In this step, you check whether the bundle configuration is valid.</p>
<ol class="arabic">
<li><p>Use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">validate</span></code> command, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>validate
</pre></div>
</div>
</li>
<li><p>If a JSON representation of the bundle configuration is returned, then the validation succeeded. If any errors are returned, fix the errors, and then repeat this step.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat this step to check whether your bundle configuration is still valid.</p>
</div>
<div class="section" id="step-7-deploy-the-local-project-to-the-remote-workspace">
<h3>Step 7: Deploy the local project to the remote workspace<a class="headerlink" href="#step-7-deploy-the-local-project-to-the-remote-workspace" title="Permalink to this headline"> </a></h3>
<p>In this step, you deploy the two local notebooks to your remote Databricks workspace and create the Databricks job within your workspace.</p>
<ol class="arabic">
<li><p>Use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">deploy</span></code> command as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>deploy<span class="w"> </span>-t<span class="w"> </span>development
</pre></div>
</div>
</li>
<li><p>Check whether the two local notebooks were deployed: In your Databricks workspace’s sidebar, click <strong>Workspace</strong>.</p></li>
<li><p>Click into the <strong>Users &gt; <code class="docutils literal notranslate"><span class="pre">&lt;your-username&gt;</span></code> &gt; .bundle &gt; baby-names &gt; development &gt; files</strong> folder. The two notebooks should be in this folder.</p></li>
<li><p>Check whether the job was created: In your Databricks workspace’s sidebar, click <strong>Workflows</strong>.</p></li>
<li><p>On the <strong>Jobs</strong> tab, click <strong>retrieve-filter-baby-names-job</strong>.</p></li>
<li><p>Click the <strong>Tasks</strong> tab. There should be two tasks: <strong>retrieve-baby-names-task</strong> and <strong>filter-baby-names-task</strong>.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat steps 6-7 to check whether your bundle configuration is still valid and then redeploy the project.</p>
</div>
<div class="section" id="step-8-run-the-deployed-project">
<h3>Step 8: Run the deployed project<a class="headerlink" href="#step-8-run-the-deployed-project" title="Permalink to this headline"> </a></h3>
<p>In this step, you run the Databricks job in your workspace.</p>
<ol class="arabic">
<li><p>Use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">run</span></code> command, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>run<span class="w"> </span>-t<span class="w"> </span>development<span class="w"> </span>retrieve-filter-baby-names-job
</pre></div>
</div>
</li>
<li><p>Copy the value of <code class="docutils literal notranslate"><span class="pre">Run</span> <span class="pre">URL</span></code> that appears in your terminal and paste this value into your web browser to open your Databricks workspace.</p></li>
<li><p>In your Databricks workspace, after the two tasks complete successfully and show green title bars, click the <strong>filter-baby-names-task</strong> task to see the query results.</p></li>
</ol>
<p>If you make any changes to your bundle after this step, you should repeat steps 6-8 to check whether your bundle configuration is still valid, redeploy the project, and run the redeployed project.</p>
</div>
<div class="section" id="step-9-clean-up">
<h3>Step 9: Clean up<a class="headerlink" href="#step-9-clean-up" title="Permalink to this headline"> </a></h3>
<p>In this step, you delete the two deployed notebooks and the job from your workspace.</p>
<ol class="arabic">
<li><p>Use the Databricks CLI to run the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">destroy</span></code> command, as follows:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>destroy
</pre></div>
</div>
</li>
<li><p>Confirm the job deletion request: When prompted to permanently destroy resources, type <code class="docutils literal notranslate"><span class="pre">y</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>.</p></li>
<li><p>Confirm the notebooks deletion request: When prompted to permanently destroy the previously deployed folder and all of its files, type <code class="docutils literal notranslate"><span class="pre">y</span></code> and press <code class="docutils literal notranslate"><span class="pre">Enter</span></code>.</p></li>
</ol>
<p>Running the <code class="docutils literal notranslate"><span class="pre">bundle</span> <span class="pre">destroy</span></code> command deletes only the deployed job and the folder containing the two deployed notebooks. This command does not delete any side effects, such as the <code class="docutils literal notranslate"><span class="pre">babynames.csv</span></code> file that the first notebook created. To delete the <code class="docutils literal notranslate"><span class="pre">babybnames.csv</span></code> file, do the following:</p>
<ol class="arabic simple">
<li><p>In the sidebar of your Databricks workspace, click <strong>Catalog</strong>.</p></li>
<li><p>Click <strong>Browse DBFS</strong>.</p></li>
<li><p>Click the <strong>FileStore</strong> folder.</p></li>
<li><p>Click the dropdown arrow next to <strong>babynames.csv</strong>, and click <strong>Delete</strong>.</p></li>
<li><p>If you also want to delete the bundle from your development machine, you can now delete the local directory from Step 1.</p></li>
</ol>
</div>
</div>
<div class="section" id="add-an-existing-job-definition-to-a-bundle">
<span id="existing-job"></span><h2>Add an existing job definition to a bundle<a class="headerlink" href="#add-an-existing-job-definition-to-a-bundle" title="Permalink to this headline"> </a></h2>
<p>You can use an existing job definition as a basis to define a new job in a bundle configuration file. To do this, complete the following steps.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The following steps create a new job that has the same settings as the existing job. However, the new job has a different job ID than the existing job. You cannot automatically import an existing job ID into a bundle.</p>
</div>
<div class="section" id="step-1-get-the-existing-job-definition-in-yaml-format">
<h3>Step 1: Get the existing job definition in YAML format<a class="headerlink" href="#step-1-get-the-existing-job-definition-in-yaml-format" title="Permalink to this headline"> </a></h3>
<p>In this step, use the Databricks workspace user interface to get the YAML representation of the existing job definition.</p>
<ol class="arabic simple">
<li><p>In your Databricks workspace’s sidebar, click <strong>Workflows</strong>.</p></li>
<li><p>On the <strong>Jobs</strong> tab, click your job’s <strong>Name</strong> link.</p></li>
<li><p>Next to the <strong>Run now</strong> button, click the ellipses, and then click <strong>View YAML</strong>.</p></li>
<li><p>On the <strong>Create</strong> tab, copy the job definition’s YAML to your local clipboard by clicking <strong>Copy</strong>.</p></li>
</ol>
</div>
<div class="section" id="step-2-add-the-job-definition-yaml-to-a-bundle-configuration-file">
<h3>Step 2: Add the job definition YAML to a bundle configuration file<a class="headerlink" href="#step-2-add-the-job-definition-yaml-to-a-bundle-configuration-file" title="Permalink to this headline"> </a></h3>
<p>In your bundle configuration file, add the YAML that you copied from the previous step to one of the following locations labelled <code class="docutils literal notranslate"><span class="pre">&lt;job-yaml-can-go-here&gt;</span></code> in your bundle configuration files, as follows:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">resources</span><span class="p">:</span>
<span class="w">  </span><span class="nt">jobs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">&lt;some-unique-programmatic-identifier-for-this-job&gt;</span><span class="p">:</span>
<span class="w">      </span><span class="l l-Scalar l-Scalar-Plain">&lt;job-yaml-can-go-here&gt;</span>

<span class="nt">targets</span><span class="p">:</span>
<span class="w">  </span><span class="nt">&lt;some-unique-programmatic-identifier-for-this-target&gt;</span><span class="p">:</span>
<span class="w">    </span><span class="nt">resources</span><span class="p">:</span>
<span class="w">      </span><span class="nt">jobs</span><span class="p">:</span>
<span class="w">        </span><span class="nt">&lt;some-unique-programmatic-identifier-for-this-job&gt;</span><span class="p">:</span>
<span class="w">          </span><span class="l l-Scalar l-Scalar-Plain">&lt;job-yaml-can-go-here&gt;</span>
</pre></div>
</div>
</div>
<div class="section" id="step-3-add-notebooks-python-files-and-other-artifacts-to-the-bundle">
<h3>Step 3: Add notebooks, Python files, and other artifacts to the bundle<a class="headerlink" href="#step-3-add-notebooks-python-files-and-other-artifacts-to-the-bundle" title="Permalink to this headline"> </a></h3>
<p>Any Python files and notebooks that are referenced in the existing job should be moved to the bundle’s sources.</p>
<p>For better compatibility with bundles, notebooks should use the IPython notebook format (<code class="docutils literal notranslate"><span class="pre">.ipynb</span></code>). If you develop the bundle locally, you can export an existing notebook from a Databricks workspace into the <code class="docutils literal notranslate"><span class="pre">.ipynb</span></code> format by clicking <strong>File &gt; Export &gt; IPython Notebook</strong> from the Databricks notebook user interface. By convention, you should then put the downloaded notebook into the <code class="docutils literal notranslate"><span class="pre">src/</span></code> directory in your bundle.</p>
<p>After you add your notebooks, Python files, and other artifacts to the bundle, make sure that your job definition references them. For example, for a notebook with the filename of <code class="docutils literal notranslate"><span class="pre">hello.ipynb</span></code> that is in a <code class="docutils literal notranslate"><span class="pre">src/</span></code> directory, and the <code class="docutils literal notranslate"><span class="pre">src/</span></code> directory is in the same folder as the bundle configuration file that references the <code class="docutils literal notranslate"><span class="pre">src/</span></code> directory, the job definition might be expressed as follows:</p>
<div class="highlight-yaml notranslate"><div class="highlight"><pre><span></span><span class="nt">resources</span><span class="p">:</span>
<span class="w">  </span><span class="nt">jobs</span><span class="p">:</span>
<span class="w">    </span><span class="nt">hello-job</span><span class="p">:</span>
<span class="w">      </span><span class="nt">name</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hello-job</span>
<span class="w">      </span><span class="nt">tasks</span><span class="p">:</span>
<span class="w">      </span><span class="p p-Indicator">-</span><span class="w"> </span><span class="nt">task_key</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">hello-task</span>
<span class="w">        </span><span class="nt">notebook_task</span><span class="p">:</span>
<span class="w">          </span><span class="nt">notebook_path</span><span class="p">:</span><span class="w"> </span><span class="l l-Scalar l-Scalar-Plain">./src/hello.ipynb</span>
</pre></div>
</div>
</div>
<div class="section" id="step-4-validate-deploy-and-run-the-new-job">
<h3>Step 4: Validate, deploy, and run the new job<a class="headerlink" href="#step-4-validate-deploy-and-run-the-new-job" title="Permalink to this headline"> </a></h3>
<ol class="arabic">
<li><p>Validate that the bundle’s configuration files are syntactically correct by running the following command:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>validate
</pre></div>
</div>
</li>
<li><p>Deploy the bundle by running the following command. In this command, replace <code class="docutils literal notranslate"><span class="pre">&lt;target-identifier&gt;</span></code> with the unique programmatic identifier for the target from the bundle configuration:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>deploy<span class="w"> </span>-t<span class="w"> </span>&lt;target-identifier&gt;
</pre></div>
</div>
</li>
<li><p>Run the job by running the following command. In this command, replace the following:</p>
<ul class="simple">
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">&lt;target-identifier&gt;</span></code> with the unique programmatic identifier for the target from the bundle configuration.</p></li>
<li><p>Replace <code class="docutils literal notranslate"><span class="pre">&lt;job-identifier&gt;</span></code> with unique programmatic identifier for the job from the bundle configuration.</p></li>
</ul>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>bundle<span class="w"> </span>run<span class="w"> </span>-t<span class="w"> </span>&lt;target-identifier&gt;<span class="w"> </span>&lt;job-identifier&gt;
</pre></div>
</div>
</li>
</ol>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>