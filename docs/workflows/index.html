

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to orchestrate data processing, machine learning, and data analysis workflows on the Databricks Data Intelligence Platform." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Introduction to Databricks Workflows">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Introduction to Databricks Workflows &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/workflows/index.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/workflows/index.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/workflows/index.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/workflows/index.html" class="notranslate">English</option>
    <option value="../../ja/workflows/index.html" class="notranslate">日本語</option>
    <option value="../../pt/workflows/index.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Introduction to Databricks Workflows</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="introduction-to-databricks-workflows">
<h1>Introduction to Databricks Workflows<a class="headerlink" href="#introduction-to-databricks-workflows" title="Permalink to this headline"> </a></h1>
<p>Databricks Workflows orchestrates data processing, machine learning, and analytics pipelines on the Databricks Data Intelligence Platform. Workflows has fully managed orchestration services integrated with the Databricks platform, including Databricks Jobs to run non-interactive code in your Databricks workspace and Delta Live Tables to build reliable and maintainable ETL pipelines.</p>
<p>To learn more about the benefits of orchestrating your workflows with the Databricks platform, see <a class="reference external" href="https://www.databricks.com/product/workflows">Databricks Workflows</a>.</p>
<div class="section" id="an-example-databricks-workflow">
<h2>An example Databricks workflow<a class="headerlink" href="#an-example-databricks-workflow" title="Permalink to this headline"> </a></h2>
<p>The following diagram illustrates a workflow that is orchestrated by a Databricks job to:</p>
<ol class="arabic simple">
<li><p>Run a Delta Live Tables pipeline that ingests raw clickstream data from cloud storage, cleans and prepares the data, sessionizes the data, and persists the final sessionized data set to Delta Lake.</p></li>
<li><p>Run a Delta Live Tables pipeline that ingests order data from cloud storage, cleans and transforms the data for processing, and persist the final data set to Delta Lake.</p></li>
<li><p>Join the order and sessionized clickstream data to create a new data set for analysis.</p></li>
<li><p>Extract features from the prepared data.</p></li>
<li><p>Perform tasks in parallel to persist the features and train a machine learning model.</p></li>
</ol>
<div class="figure align-default">
<img alt="Diagram illustrating an example workflow" src="../_images/example-workflow-diagram.png" />
</div>
</div>
<div class="section" id="what-is-databricks-jobs">
<span id="what-is-jobs"></span><h2>What is Databricks Jobs?<a class="headerlink" href="#what-is-databricks-jobs" title="Permalink to this headline"> </a></h2>
<p>A Databricks job is a way to run your data processing and analysis applications in a Databricks workspace. Your job can consist of a single task or can be a large, multi-task workflow with complex dependencies. Databricks manages the task orchestration, cluster management, monitoring, and error reporting for all of your jobs. You can run your jobs immediately, periodically through an easy-to-use scheduling system, whenever new files arrive in an external location, or continuously to ensure an instance of the job is always running. You can also run jobs interactively in the <a class="reference internal" href="../notebooks/index.html"><span class="doc">notebook UI</span></a>.</p>
<p>You can create and run a job using the Jobs UI, the Databricks CLI, or by invoking the Jobs API. You can repair and re-run a failed or canceled job using the UI or API. You can monitor job run results using the UI, CLI, API, and notifications (for example, email, webhook destination, or Slack notifications).</p>
<p>To learn about using the Databricks CLI, see <a class="reference internal" href="../archive/dev-tools/cli/jobs-cli.html"><span class="doc">Jobs CLI (legacy)</span></a>. To learn about using the Jobs API, see the <a class="reference external" href="https://docs.databricks.com/api/workspace/jobs">Jobs API</a>.</p>
<p>The following sections cover important features of Databricks Jobs.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<ul class="simple">
<li><p>A workspace is limited to 1000 concurrent task runs. A <code class="docutils literal notranslate"><span class="pre">429</span> <span class="pre">Too</span> <span class="pre">Many</span> <span class="pre">Requests</span></code> response is returned when you request a run that cannot start immediately.</p></li>
<li><p>The number of jobs a workspace can create in an hour is limited to 10000 (includes “runs submit”). This limit also affects jobs created by the REST API and notebook workflows.</p></li>
</ul>
</div>
<p></p>
<div class="section" id="implement-data-processing-and-analysis-with-job-tasks">
<h3>Implement data processing and analysis with job tasks<a class="headerlink" href="#implement-data-processing-and-analysis-with-job-tasks" title="Permalink to this headline"> </a></h3>
<p>You implement your data processing and analysis workflow using <em>tasks</em>. A job is composed of one or more tasks. You can create job tasks that run notebooks, JARS, Delta Live Tables pipelines, or Python, Scala, Spark submit, and Java applications. Your job tasks can also orchestrate Databricks SQL queries, alerts and dashboards to create analyses and visualizations, or you can use the dbt task to run dbt transformations in your workflow. Legacy Spark Submit applications are also supported.</p>
<p>You can also add a task to a job that runs a different job. This feature allows you to break a large process into multiple smaller jobs, or create generalized modules that can be reused by multiple jobs.</p>
<p>You control the execution order of tasks by specifying dependencies between the tasks. You can configure tasks to run in sequence or parallel.</p>
</div>
<div class="section" id="run-jobs-interactively-continuously-or-using-job-triggers">
<h3>Run jobs interactively, continuously, or using job triggers<a class="headerlink" href="#run-jobs-interactively-continuously-or-using-job-triggers" title="Permalink to this headline"> </a></h3>
<p>You can run your jobs interactively from the Jobs UI, API, or CLI or you can run a <a class="reference internal" href="jobs/schedule-jobs.html#continuous-jobs"><span class="std std-ref">continuous job</span></a>. You can <a class="reference internal" href="jobs/schedule-jobs.html#job-schedule"><span class="std std-ref">create a schedule</span></a> to run your job periodically or run your job when <a class="reference internal" href="jobs/file-arrival-triggers.html"><span class="doc">new files arrive</span></a> in an external location such as Amazon S3 or Azure storage.</p>
</div>
<div class="section" id="monitor-job-progress-with-notifications">
<h3>Monitor job progress with notifications<a class="headerlink" href="#monitor-job-progress-with-notifications" title="Permalink to this headline"> </a></h3>
<p>You can receive notifications when a job or task starts, completes, or fails. You can send notifications to one or more email addresses or system destinations (for example, webhook destinations or Slack). See <a class="reference internal" href="jobs/job-notifications.html"><span class="doc">Add email and system notifications for job events</span></a>.</p>
</div>
<div class="section" id="run-your-jobs-with-databricks-compute-resources">
<h3>Run your jobs with Databricks compute resources<a class="headerlink" href="#run-your-jobs-with-databricks-compute-resources" title="Permalink to this headline"> </a></h3>
<p>Databricks clusters and SQL warehouses provide the computation resources for your jobs. You can run your jobs with a job cluster, an all-purpose cluster, or a SQL warehouse:</p>
<ul class="simple">
<li><p>A job cluster is a dedicated cluster for your job or individual job tasks. Your job can use a job cluster that’s shared by all tasks or you can configure a cluster for individual tasks when you create or edit a task. An job cluster is created when the job or task starts and terminated when the job or task ends.</p></li>
<li><p>An all-purpose cluster is a shared cluster that is manually started and terminated and can be shared by multiple users and jobs.</p></li>
</ul>
<p>To optimize resource usage, Databricks recommends using a job cluster for your jobs. To reduce the time spent waiting for cluster startup, consider using an all-purpose cluster. See <a class="reference internal" href="jobs/use-compute.html"><span class="doc">Use Databricks compute with your jobs</span></a>.</p>
<p>You use a SQL warehouse to run Databricks SQL tasks such as queries, dashboards, or alerts. You can also use a SQL warehouse to run dbt transformations with the dbt task.</p>
</div>
<div class="section" id="next-steps">
<h3>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline"> </a></h3>
<p>To get started with Databricks Jobs:</p>
<ul class="simple">
<li><p>Create your first Databricks jobs workflow with the <a class="reference internal" href="jobs/jobs-quickstart.html"><span class="doc">quickstart</span></a>.</p></li>
<li><p>Learn how to create and run workflows with the Databricks Jobs <a class="reference internal" href="jobs/create-run-jobs.html"><span class="doc">user interface</span></a>.</p></li>
<li><p>Learn about <a class="reference internal" href="jobs/create-run-jobs.html"><span class="doc">monitoring job runs</span></a> in the Databricks Jobs user interface.</p></li>
<li><p>Learn about <a class="reference internal" href="jobs/settings.html"><span class="doc">configuration options</span></a> for jobs.</p></li>
</ul>
<p>Learn more about building, managing, and troubleshooting workflows with Databricks Jobs:</p>
<ul class="simple">
<li><p>Learn how to communicate information between tasks in a Databricks job with <a class="reference internal" href="jobs/share-task-context.html"><span class="doc">task values</span></a>.</p></li>
<li><p>Learn how to pass context about job runs into job tasks with <a class="reference internal" href="jobs/parameter-value-references.html"><span class="doc">task parameter variables</span></a>.</p></li>
<li><p>Learn how to configure your job tasks to run <a class="reference internal" href="jobs/conditional-tasks.html"><span class="doc">conditionally</span></a> based on the status of the task’s dependencies.</p></li>
<li><p>Learn how to <a class="reference internal" href="jobs/repair-job-failures.html"><span class="doc">troubleshoot and fix failed</span></a> jobs.</p></li>
<li><p>Get notified when your job runs start, complete or fail with <a class="reference internal" href="jobs/job-notifications.html"><span class="doc">job run notifications</span></a>.</p></li>
<li><p>Trigger your jobs on a <a class="reference internal" href="jobs/schedule-jobs.html"><span class="doc">custom schedule or run a continuous job</span></a>.</p></li>
<li><p>Learn how to run your Databricks job when new data arrives with <a class="reference internal" href="jobs/file-arrival-triggers.html"><span class="doc">file arrival triggers</span></a>.</p></li>
<li><p>Learn how to use <a class="reference internal" href="jobs/use-compute.html"><span class="doc">Databricks compute resources</span></a> to run your jobs.</p></li>
<li><p>Learn about <a class="reference internal" href="jobs/jobs-api-updates.html"><span class="doc">updates to the Jobs API</span></a> to support creating and managing workflows with Databricks jobs.</p></li>
<li><p>Use <a class="reference internal" href="jobs/how-to/index.html"><span class="doc">how-to guides and tutorials</span></a> to learn more about implementing data workflows with Databricks Jobs.</p></li>
</ul>
</div>
</div>
<div class="section" id="what-is-delta-live-tables">
<span id="what-is-dlt-1"></span><span id="what-is-dlt"></span><h2>What is Delta Live Tables?<a class="headerlink" href="#what-is-delta-live-tables" title="Permalink to this headline"> </a></h2>
<p>Delta Live Tables is a framework that simplifies ETL and streaming data processing. Delta Live Tables provides efficient ingestion of data with built-in support for <a class="reference internal" href="../ingestion/auto-loader/index.html"><span class="doc">Auto Loader</span></a>, SQL and Python interfaces that support declarative implementation of data transformations, and support for writing transformed data to Delta Lake. You define the transformations to perform on your data, and Delta Live Tables manages task orchestration, cluster management, monitoring, data quality, and error handling.</p>
<p>To get started, see <a class="reference internal" href="../delta-live-tables/index.html"><span class="doc">What is Delta Live Tables?</span></a>.</p>
</div>
<div class="section" id="databricks-jobs-and-delta-live-tables">
<span id="databricks-jobs-and-dlt"></span><span id="jobs-vs-dlt"></span><h2>Databricks Jobs and Delta Live Tables<a class="headerlink" href="#databricks-jobs-and-delta-live-tables" title="Permalink to this headline"> </a></h2>
<p>Databricks Jobs and Delta Live Tables provide a comprehensive framework for building and deploying end-to-end data processing and analysis workflows.</p>
<p>Use Delta Live Tables for all ingestion and transformation of data. Use Databricks Jobs to orchestrate workloads composed of a single task or multiple data processing and analysis tasks on the Databricks platform, including Delta Live Tables ingestion and transformation.</p>
<p>As a workflow orchestration system, Databricks Jobs also supports:</p>
<ul class="simple">
<li><p>Running jobs on a triggered basis, for example, running a workflow on a schedule.</p></li>
<li><p>Data analysis through SQL queries, machine learning and data analysis with notebooks, scripts, or external libraries, and so forth.</p></li>
<li><p>Running a job composed of a single task, for example, running an Apache Spark job packaged in a JAR.</p></li>
</ul>
</div>
<div class="section" id="workflow-orchestration-with-apache-airflow">
<span id="orchestration-with-airflow"></span><h2>Workflow orchestration with Apache AirFlow<a class="headerlink" href="#workflow-orchestration-with-apache-airflow" title="Permalink to this headline"> </a></h2>
<p>Although Databricks recommends using Databricks Jobs to orchestrate your data workflows, you can also use <a class="reference external" href="https://airflow.apache.org/">Apache Airflow</a> to manage and schedule your data workflows. With Airflow, you define your workflow in a Python file, and Airflow manages scheduling and running the workflow. See <a class="reference internal" href="jobs/how-to/use-airflow-with-jobs.html"><span class="doc">Orchestrate Databricks jobs with Apache Airflow</span></a>.</p>
<p></p>
<div class="toctree-wrapper compound">
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>