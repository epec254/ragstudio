

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to enable optimizations for LLMs on Databricks Model Serving." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Optimized large language model (LLM) serving">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Optimized large language model (LLM) serving &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/machine-learning/model-serving/llm-optimized-model-serving.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/machine-learning/model-serving/llm-optimized-model-serving.html" class="notranslate">English</option>
    <option value="../../../ja/machine-learning/model-serving/llm-optimized-model-serving.html" class="notranslate">日本語</option>
    <option value="../../../pt/machine-learning/model-serving/llm-optimized-model-serving.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Optimized large language model (LLM) serving</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="optimized-large-language-model-llm-serving">
<h1>Optimized large language model (LLM) serving<a class="headerlink" href="#optimized-large-language-model-llm-serving" title="Permalink to this headline"> </a></h1>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>This feature is in <a class="reference internal" href="../../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The code examples in this guide use deprecated APIs. Databricks recommends using the <a class="reference internal" href="../foundation-models/deploy-prov-throughput-foundation-model-apis.html"><span class="doc">provisioned throughput</span></a> experience for optimized inference of LLMs. See <a class="reference internal" href="migrate-provisioned-throughput.html"><span class="doc">Migrate optimized LLM serving endpoints to provisioned throughput</span></a>.</p>
</div>
<p>This article demonstrates how to enable optimizations for large language models (LLMs) on Databricks Model Serving.</p>
<p>Optimized LLM serving provides throughput and latency improvements in the range of 3-5 times better compared to traditional serving approaches. The following table summarizes the supported LLM families and their variants.</p>
<p>Databricks recommends installing foundation models using <a class="reference external" href="https://marketplace.databricks.com">Databricks Marketplace</a>. You can search for a model family and from the model page, select <strong>Get access</strong> and provide login credentials to install the model to Unity Catalog.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 9%" />
<col style="width: 91%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model family</p></th>
<th class="head"><p>Install from Marketplace</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Llama 2</p></td>
<td><p> <a class="reference external" href="https://marketplace.databricks.com/details/46527194-66f5-4ea1-9619-d7ec6be6a2fa/Databricks_Llama-2-Models">Llama 2 Models</a></p></td>
</tr>
<tr class="row-odd"><td><p> MPT</p></td>
<td></td>
</tr>
<tr class="row-even"><td><p> Mistral</p></td>
<td><p> <a class="reference external" href="https://marketplace.databricks.com/details/65870958-ea16-4ec8-8580-2011fab37a72/Databricks_Mistral-Models">Mistral models</a></p></td>
</tr>
</tbody>
</table>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul>
<li><p>Optimized LLM serving is supported as part of the Public Preview of <a class="reference internal" href="create-manage-serving-endpoints.html#gpu"><span class="std std-ref">GPU deployments</span></a>.</p></li>
<li><p>Your model must be logged using MLflow 2.4 and above or Databricks Runtime 13.2 ML and above.</p></li>
<li><p>Databricks recommends using models in Unity Catalog for faster upload and download of large models.</p></li>
<li><p>When deploying models, it’s essential to match your model’s parameter size with the appropriate compute size. See the table below for recommendations. For models with 50 billion or more parameters, please reach out to your Databricks account team to access the necessary GPUs.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 32%" />
<col style="width: 41%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Model parameter size</p></th>
<th class="head"><p>Recommended compute size</p></th>
<th class="head"><p>GPU type</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>7 billion</p></td>
<td><p> 1xA10</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">GPU_MEDIUM</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>13 billion</p></td>
<td><p>        4xA10</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">MULTIGPU_MEDIUM</span></code></p></td>
</tr>
<tr class="row-even"><td><p>30-34 billion</p></td>
<td><p>     4xA10</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">MULTIGPU_MEDIUM</span></code></p></td>
</tr>
<tr class="row-odd"><td><p>70 billion</p></td>
<td><p>        8xA10 or 8xA100</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">GPU_MEDIUM_8</span></code> or <code class="docutils literal notranslate"><span class="pre">GPU_LARGE_8</span></code></p></td>
</tr>
</tbody>
</table>
</li>
</ul>
</div>
<div class="section" id="log-your-large-language-model">
<h2>Log your large language model<a class="headerlink" href="#log-your-large-language-model" title="Permalink to this headline"> </a></h2>
<p>First, log your model with the MLflow <code class="docutils literal notranslate"><span class="pre">transformers</span></code> flavor and specify the task field in the MLflow metadata with <code class="docutils literal notranslate"><span class="pre">metadata</span> <span class="pre">=</span> <span class="pre">{&quot;task&quot;:</span> <span class="pre">&quot;llm/v1/completions&quot;}</span></code>. This specifies the API signature used for the model serving endpoint.</p>
<p>Optimized LLM serving is compatible with the route types supported by Databricks AI Gateway; currently, <code class="docutils literal notranslate"><span class="pre">llm/v1/completions</span></code>. If there is a model family or task type you want to serve that is not supported, reach out to your Databricks account team.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForCausalLM</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;mosaicml/mpt-7b-instruct&quot;</span><span class="p">,</span><span class="n">torch_dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">bfloat16</span><span class="p">,</span> <span class="n">trust_remote_code</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="s2">&quot;mosaicml/mpt-7b-instruct&quot;</span><span class="p">)</span>
<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">():</span>
    <span class="n">components</span> <span class="o">=</span> <span class="p">{</span>
        <span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">model</span><span class="p">,</span>
        <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">,</span>
    <span class="p">}</span>
    <span class="n">mlflow</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;model&quot;</span><span class="p">,</span>
        <span class="n">transformers_model</span><span class="o">=</span><span class="n">components</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.</span><span class="se">\n\n</span><span class="s2">### Instruction:</span><span class="se">\n</span><span class="s2">What is Apache Spark?</span><span class="se">\n\n</span><span class="s2">### Response:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">],</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;task&quot;</span><span class="p">:</span> <span class="s2">&quot;llm/v1/completions&quot;</span><span class="p">},</span>
        <span class="n">registered_model_name</span><span class="o">=</span><span class="s1">&#39;mpt&#39;</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>After your model is logged you can register your models in Unity Catalog with the following where you replace <code class="docutils literal notranslate"><span class="pre">CATALOG.SCHEMA.MODEL_NAME</span></code> with the three-level name of the model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">mlflow</span><span class="o">.</span><span class="n">set_registry_uri</span><span class="p">(</span><span class="s2">&quot;databricks-uc&quot;</span><span class="p">)</span>

<span class="n">registered_model_name</span><span class="o">=</span><span class="n">CATALOG</span><span class="o">.</span><span class="n">SCHEMA</span><span class="o">.</span><span class="n">MODEL_NAME</span>
</pre></div>
</div>
</div>
<div class="section" id="create-your-model-serving-endpoint">
<h2>Create your model serving endpoint<a class="headerlink" href="#create-your-model-serving-endpoint" title="Permalink to this headline"> </a></h2>
<p>Next, create your model serving endpoint. If your model is supported by Optimized LLM serving, Databricks automatically creates an optimized model serving endpoint when you try to serve it.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># Set the name of the MLflow endpoint</span>
<span class="n">endpoint_name</span> <span class="o">=</span> <span class="s2">&quot;llama2-3b-chat&quot;</span>

<span class="c1"># Name of the registered MLflow model</span>
<span class="n">model_name</span> <span class="o">=</span> <span class="s2">&quot;ml.llm-catalog.llama-13b&quot;</span>

<span class="c1"># Get the latest version of the MLflow model</span>
<span class="n">model_version</span> <span class="o">=</span> <span class="mi">3</span>

<span class="c1"># Specify the type of compute (CPU, GPU_SMALL, GPU_MEDIUM, etc.)</span>
<span class="n">workload_type</span> <span class="o">=</span> <span class="s2">&quot;GPU_MEDIUM&quot;</span>

<span class="c1"># Specify the scale-out size of compute (Small, Medium, Large, etc.)</span>
<span class="n">workload_size</span> <span class="o">=</span> <span class="s2">&quot;Small&quot;</span>

<span class="c1"># Specify Scale to Zero (only supported for CPU endpoints)</span>
<span class="n">scale_to_zero</span> <span class="o">=</span> <span class="kc">False</span>

<span class="c1"># Get the API endpoint and token for the current notebook context</span>
<span class="n">API_ROOT</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">entry_point</span><span class="o">.</span><span class="n">getDbutils</span><span class="p">()</span><span class="o">.</span><span class="n">notebook</span><span class="p">()</span><span class="o">.</span><span class="n">getContext</span><span class="p">()</span><span class="o">.</span><span class="n">apiUrl</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>
<span class="n">API_TOKEN</span> <span class="o">=</span> <span class="n">dbutils</span><span class="o">.</span><span class="n">notebook</span><span class="o">.</span><span class="n">entry_point</span><span class="o">.</span><span class="n">getDbutils</span><span class="p">()</span><span class="o">.</span><span class="n">notebook</span><span class="p">()</span><span class="o">.</span><span class="n">getContext</span><span class="p">()</span><span class="o">.</span><span class="n">apiToken</span><span class="p">()</span><span class="o">.</span><span class="n">get</span><span class="p">()</span>

<span class="c1"># send the POST request to create the serving endpoint</span>

<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;name&quot;</span><span class="p">:</span> <span class="n">endpoint_name</span><span class="p">,</span>
    <span class="s2">&quot;config&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;served_models&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="p">{</span>
                <span class="s2">&quot;model_name&quot;</span><span class="p">:</span> <span class="n">model_name</span><span class="p">,</span>
                <span class="s2">&quot;model_version&quot;</span><span class="p">:</span> <span class="n">model_version</span><span class="p">,</span>
                <span class="s2">&quot;workload_size&quot;</span><span class="p">:</span> <span class="n">workload_size</span><span class="p">,</span>
                <span class="s2">&quot;scale_to_zero_enabled&quot;</span><span class="p">:</span> <span class="n">scale_to_zero</span><span class="p">,</span>
                <span class="s2">&quot;workload_type&quot;</span><span class="p">:</span> <span class="n">workload_type</span><span class="p">,</span>
            <span class="p">}</span>
        <span class="p">]</span>
    <span class="p">},</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Context-Type&quot;</span><span class="p">:</span> <span class="s2">&quot;text/json&quot;</span><span class="p">,</span> <span class="s2">&quot;Authorization&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Bearer </span><span class="si">{</span><span class="n">API_TOKEN</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">API_ROOT</span><span class="si">}</span><span class="s2">/api/2.0/serving-endpoints&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">(),</span> <span class="n">indent</span><span class="o">=</span><span class="mi">4</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="input-and-output-schema-format">
<h2>Input and output schema format<a class="headerlink" href="#input-and-output-schema-format" title="Permalink to this headline"> </a></h2>
<p>An optimized LLM serving endpoint has an input and output schemas that Databricks controls. Four different formats are supported.</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">dataframe_split</span></code> is JSON-serialized Pandas Dataframe in the <code class="docutils literal notranslate"><span class="pre">split</span></code> orientation.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;dataframe_split&quot;</span><span class="p">:{</span>
<span class="w">    </span><span class="nt">&quot;columns&quot;</span><span class="p">:[</span><span class="s2">&quot;prompt&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;index&quot;</span><span class="p">:[</span><span class="mi">0</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;data&quot;</span><span class="p">:[[</span><span class="s2">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instructions:\nWhat is Apache Spark?\n\n### Response:\n&quot;</span><span class="p">]]</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;max_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;stop&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;word1&quot;</span><span class="p">,</span><span class="s2">&quot;word2&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;candidate_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">dataframe_records</span></code> is JSON-serialized Pandas Dataframe in the <code class="docutils literal notranslate"><span class="pre">records</span></code> orientation.</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;dataframe_records&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instructions:\nWhat is Apache Spark?\n\n### Response:\n&quot;</span><span class="p">}],</span>
<span class="w">  </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;max_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;stop&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;word1&quot;</span><span class="p">,</span><span class="s2">&quot;word2&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;candidate_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>instances</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;instances&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span>
<span class="w">   </span><span class="p">{</span>
<span class="w">     </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instructions:\nWhat is Apache Spark?\n\n### Response:\n&quot;</span>
<span class="w">   </span><span class="p">}</span>
<span class="w">  </span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;max_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;stop&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;word1&quot;</span><span class="p">,</span><span class="s2">&quot;word2&quot;</span><span class="p">],</span>
<span class="w">  </span><span class="nt">&quot;candidate_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
<li><p>inputs</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;inputs&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;prompt&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;Below is an instruction that describes a task. Write a response that appropriately completes the request.\n\n### Instructions:\nWhat is Apache Spark?\n\n### Response:\n&quot;</span>
<span class="w">  </span><span class="p">},</span>
<span class="w">  </span><span class="nt">&quot;params&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span>
<span class="w">    </span><span class="nt">&quot;temperature&quot;</span><span class="p">:</span><span class="w"> </span><span class="mf">0.5</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;max_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">100</span><span class="p">,</span>
<span class="w">    </span><span class="nt">&quot;stop&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">&quot;word1&quot;</span><span class="p">,</span><span class="s2">&quot;word2&quot;</span><span class="p">],</span>
<span class="w">    </span><span class="nt">&quot;candidate_count&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">1</span>
<span class="w">  </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="query-your-endpoint">
<h2>Query your endpoint<a class="headerlink" href="#query-your-endpoint" title="Permalink to this headline"> </a></h2>
<p>After your endpoint is ready, you can query it by making an API request. Depending on the model size and complexity, it can take 30 minutes or more for the endpoint to get ready.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span>
<span class="n">data</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;inputs&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;prompt&quot;</span><span class="p">:</span> <span class="p">[</span>
            <span class="s2">&quot;Hello, I&#39;m a language model,&quot;</span>
        <span class="p">]</span>
    <span class="p">},</span>
    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="p">{</span>
        <span class="s2">&quot;max_tokens&quot;</span><span class="p">:</span> <span class="mi">100</span><span class="p">,</span>
        <span class="s2">&quot;temperature&quot;</span><span class="p">:</span> <span class="mf">0.0</span>
    <span class="p">}</span>
<span class="p">}</span>

<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span><span class="s2">&quot;Context-Type&quot;</span><span class="p">:</span> <span class="s2">&quot;text/json&quot;</span><span class="p">,</span> <span class="s2">&quot;Authorization&quot;</span><span class="p">:</span> <span class="sa">f</span><span class="s2">&quot;Bearer </span><span class="si">{</span><span class="n">API_TOKEN</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">}</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">post</span><span class="p">(</span>
    <span class="n">url</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">API_ROOT</span><span class="si">}</span><span class="s2">/serving-endpoints/</span><span class="si">{</span><span class="n">endpoint_name</span><span class="si">}</span><span class="s2">/invocations&quot;</span><span class="p">,</span> <span class="n">json</span><span class="o">=</span><span class="n">data</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span>
<span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">json</span><span class="o">.</span><span class="n">dumps</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">json</span><span class="p">()))</span>
</pre></div>
</div>
</div>
<div class="section" id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Given the increased installation requirements for models served on GPU, container image creation for GPU serving takes longer than image creation for CPU serving.</p>
<ul>
<li><p>Model size also impacts image creation. For example, models that have 30 billion parameters or more can take at least an hour to build.</p></li>
<li><p>Databricks reuses the same container the next time the same version of the model is deployed, so subsequent deployments will take less time.</p></li>
</ul>
</li>
<li><p>Autoscaling for GPU serving takes longer than for CPU serving, due to increased set up time for models served on GPU compute. Databricks recommends over-provisioning to avoid requests time-outs.</p></li>
</ul>
</div>
<div class="section" id="notebook-example">
<h2>Notebook example<a class="headerlink" href="#notebook-example" title="Permalink to this headline"> </a></h2>
<p>The following notebook shows how to create an optimized serving endpoint:</p>
<div class="embedded-notebook-section section" id="optimized-llm-serving-for-llama2-model-notebook">
<span id="optimized-llama-serving"></span><h3>Optimized LLM serving for Llama2 model notebook<a class="headerlink" href="#optimized-llm-serving-for-llama2-model-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/large-language-models/optimized-llama-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/large-language-models/optimized-llama-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/large-language-models/optimized-llama-serving.html"            id="53c32eae1297d20bbf57a09748b75601c1d33ecf669a685afa38fcf555859079" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
<div class="embedded-notebook-section section" id="optimized-llm-serving-for-mpt-model-notebook">
<span id="optimized-mpt-serving"></span><h3>Optimized LLM serving for MPT model notebook<a class="headerlink" href="#optimized-llm-serving-for-mpt-model-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/large-language-models/optimized-mpt-serving.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/large-language-models/optimized-mpt-serving.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/large-language-models/optimized-mpt-serving.html"            id="1835a0a136a61bd6f49654908a1fb609b203240b99a6ff4c10bb3136ee8d88a7" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>