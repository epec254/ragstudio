

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to create a Ray cluster and run Ray applications in Databricks with the Ray on Spark API." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Use Ray on Databricks">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Use Ray on Databricks &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/machine-learning/ray-integration.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/machine-learning/ray-integration.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/machine-learning/ray-integration.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/machine-learning/ray-integration.html" class="notranslate">English</option>
    <option value="../../ja/machine-learning/ray-integration.html" class="notranslate">日本語</option>
    <option value="../../pt/machine-learning/ray-integration.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Use Ray on Databricks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="use-ray-on-databricks">
<h1>Use Ray on Databricks<a class="headerlink" href="#use-ray-on-databricks" title="Permalink to this headline"> </a></h1>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>This feature is in <a class="reference internal" href="../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<p>Ray 2.3.0 and above supports creating
Ray clusters and running Ray applications on Apache Spark clusters with Databricks.
For information about getting started with machine learning on Ray, including tutorials and examples, see the
<a class="reference external" href="https://docs.ray.io/en/latest/">Ray documentation</a>.
For more information about the Ray and Apache Spark integration, see the
<a class="reference external" href="https://docs.ray.io/en/latest/cluster/vms/user-guides/community/spark.html#ray-on-spark-apis">Ray on Spark API documentation</a>.</p>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Databricks Runtime 12.0 ML and above.</p></li>
<li><p>Databricks Runtime cluster access mode must be either “assigned” mode or “no isolation shared” mode.</p></li>
</ul>
</div>
<div class="section" id="install-ray">
<h2>Install Ray<a class="headerlink" href="#install-ray" title="Permalink to this headline"> </a></h2>
<p>Use the following command to install Ray. The <code class="docutils literal notranslate"><span class="pre">[default]</span></code> extension is required by the Ray dashboard component.</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">ray</span><span class="p">[</span><span class="n">default</span><span class="p">]</span><span class="o">&gt;=</span><span class="mf">2.3.0</span>
</pre></div>
</div>
</div>
<div class="section" id="create-a-ray-cluster">
<h2>Create a Ray cluster<a class="headerlink" href="#create-a-ray-cluster" title="Permalink to this headline"> </a></h2>
<p>To create a Ray cluster, use the <a class="reference external" href="https://docs.ray.io/en/latest/cluster/vms/user-guides/community/spark.html#ray.util.spark.setup_ray_cluster">ray.util.spark.setup_ray_cluster</a> API.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">ray.util.spark</span> <span class="kn">import</span> <span class="n">setup_ray_cluster</span><span class="p">,</span> <span class="n">shutdown_ray_cluster</span>

<span class="n">setup_ray_cluster</span><span class="p">(</span>
  <span class="n">num_worker_nodes</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
  <span class="n">num_cpus_per_node</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span>
  <span class="n">collect_log_to_path</span><span class="o">=</span><span class="s2">&quot;/dbfs/path/to/ray_collected_logs&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">ray.util.spark.setup_ray_cluster</span></code> API creates a Ray cluster on Spark. Internally, it creates a background
Spark job. Each Spark task in the job creates a Ray worker node, and the Ray head node is created
on the driver. The argument <code class="docutils literal notranslate"><span class="pre">num_worker_nodes</span></code> represents the number of Ray worker nodes to
create. To specify the number of CPU or GPU cores assigned to each Ray worker node, set the argument
<code class="docutils literal notranslate"><span class="pre">num_cpus_per_node</span></code> or <code class="docutils literal notranslate"><span class="pre">num_gpus_per_node</span></code>.</p>
<p>After a Ray cluster is created, you can run any Ray application code directly in your notebook.
An HTML link <strong>Open Ray Cluster Dashboard in a new tab</strong> is also displayed, allowing you to view
the Ray dashboard for the cluster.</p>
<div class="admonition tip">
<p class="admonition-title">Tip</p>
<p>If you’re using a Databricks single user cluster, you can set <code class="docutils literal notranslate"><span class="pre">num_worker_nodes</span></code> to
<code class="docutils literal notranslate"><span class="pre">ray.util.spark.MAX_NUM_WORKER_NODES</span></code> in order to use all available resources for your Ray cluster.</p>
<div class="highlight-diff notranslate"><div class="highlight"><pre><span></span>setup_ray_cluster(
<span class="w"> </span># ...
<span class="w"> </span>num_worker_nodes=ray.util.spark.MAX_NUM_WORKER_NODES,
)
</pre></div>
</div>
</div>
<p>You can set the argument <code class="docutils literal notranslate"><span class="pre">collect_log_to_path</span></code> to specify the destination path where you want to collect the Ray cluster logs. Log collection runs after the Ray cluster is shut down. Databricks recommends that you set a path starting with <code class="docutils literal notranslate"><span class="pre">/dbfs/</span></code> so that the logs are preserved even if you terminate the Spark cluster. Otherwise, your logs are not recoverable since the local storage on the cluster is deleted when the cluster is shut down.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Calling <code class="docutils literal notranslate"><span class="pre">ray.util.spark.setup_ray_cluster</span></code> sets the <code class="docutils literal notranslate"><span class="pre">RAY_ADDRESS</span></code> environment variable
to the address of the created Ray cluster, so your Ray application automatically uses
this Ray cluster. You can specify an alternative cluster address using the <code class="docutils literal notranslate"><span class="pre">address</span></code> argument
of the <a class="reference external" href="https://docs.ray.io/en/latest/ray-core/package-ref.html?highlight=init#ray-init">ray.init</a> API.</p>
</div>
</div>
<div class="section" id="run-a-ray-application">
<h2>Run a Ray application<a class="headerlink" href="#run-a-ray-application" title="Permalink to this headline"> </a></h2>
<p>After the Ray cluster has been created, you can run any Ray application code in a Databricks notebook.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Databricks recommends that you install any necessary libraries for your application with  <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">&lt;your-library-dependency&gt;</span></code> to ensure they are available to your Ray cluster and application accordingly. Specifying dependencies in the Ray init function call installs the dependencies in a location inaccessible to the Spark worker nodes, which results in version incompatibilities and import errors.</p>
</div>
<p>For example, you can run a simple Ray application in a Databricks notebook as follows:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">from</span> <span class="nn">fractions</span> <span class="kn">import</span> <span class="n">Fraction</span>

<span class="n">ray</span><span class="o">.</span><span class="n">init</span><span class="p">()</span>

<span class="nd">@ray</span><span class="o">.</span><span class="n">remote</span>
<span class="k">def</span> <span class="nf">pi4_sample</span><span class="p">(</span><span class="n">sample_count</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;pi4_sample runs sample_count experiments, and returns the</span>
<span class="sd">    fraction of time it was inside the circle.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">in_count</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">sample_count</span><span class="p">):</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="n">y</span> <span class="o">=</span> <span class="n">random</span><span class="o">.</span><span class="n">random</span><span class="p">()</span>
        <span class="k">if</span> <span class="n">x</span><span class="o">*</span><span class="n">x</span> <span class="o">+</span> <span class="n">y</span><span class="o">*</span><span class="n">y</span> <span class="o">&lt;=</span> <span class="mi">1</span><span class="p">:</span>
            <span class="n">in_count</span> <span class="o">+=</span> <span class="mi">1</span>
    <span class="k">return</span> <span class="n">Fraction</span><span class="p">(</span><span class="n">in_count</span><span class="p">,</span> <span class="n">sample_count</span><span class="p">)</span>

<span class="n">SAMPLE_COUNT</span> <span class="o">=</span> <span class="mi">1000</span> <span class="o">*</span> <span class="mi">1000</span>
<span class="n">start</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">future</span> <span class="o">=</span> <span class="n">pi4_sample</span><span class="o">.</span><span class="n">remote</span><span class="p">(</span><span class="n">sample_count</span><span class="o">=</span><span class="n">SAMPLE_COUNT</span><span class="p">)</span>
<span class="n">pi4</span> <span class="o">=</span> <span class="n">ray</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">future</span><span class="p">)</span>
<span class="n">end</span> <span class="o">=</span> <span class="n">time</span><span class="o">.</span><span class="n">time</span><span class="p">()</span>
<span class="n">dur</span> <span class="o">=</span> <span class="n">end</span> <span class="o">-</span> <span class="n">start</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;Running </span><span class="si">{</span><span class="n">SAMPLE_COUNT</span><span class="si">}</span><span class="s1"> tests took </span><span class="si">{</span><span class="n">dur</span><span class="si">}</span><span class="s1"> seconds&#39;</span><span class="p">)</span>

<span class="n">pi</span> <span class="o">=</span> <span class="n">pi4</span> <span class="o">*</span> <span class="mi">4</span>
<span class="nb">print</span><span class="p">(</span><span class="nb">float</span><span class="p">(</span><span class="n">pi</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="load-data-from-a-spark-dataframe">
<h2>Load data from a Spark DataFrame<a class="headerlink" href="#load-data-from-a-spark-dataframe" title="Permalink to this headline"> </a></h2>
<p>To load a Spark DataFrame as a Ray Dataset, firstly you need to save the spark DataFrame to DBFS
using Parquet or Delta format. In order to control DBFS access securely, Databricks recommends that you <a class="reference internal" href="../dbfs/mounts.html"><span class="doc">mount cloud object storage to DBFS</span></a>. Then, you can create a <code class="docutils literal notranslate"><span class="pre">ray.data.Dataset</span></code> instance from the saved Spark DataFrame path using the following helper method:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">ray</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">from</span> <span class="nn">urllib.parse</span> <span class="kn">import</span> <span class="n">urlparse</span>


<span class="k">def</span> <span class="nf">create_ray_dataset_from_spark_dataframe</span><span class="p">(</span><span class="n">spark_dataframe</span><span class="p">,</span> <span class="n">dbfs_tmp_path</span><span class="p">):</span>
    <span class="n">spark_dataframe</span><span class="o">.</span><span class="n">write</span><span class="o">.</span><span class="n">mode</span><span class="p">(</span><span class="s1">&#39;overwrite&#39;</span><span class="p">)</span><span class="o">.</span><span class="n">parquet</span><span class="p">(</span><span class="n">dbfs_tmp_path</span><span class="p">)</span>
    <span class="n">fuse_path</span> <span class="o">=</span> <span class="s2">&quot;/dbfs&quot;</span> <span class="o">+</span> <span class="n">urlparse</span><span class="p">(</span><span class="n">dbfs_tmp_path</span><span class="p">)</span><span class="o">.</span><span class="n">path</span>
    <span class="k">return</span> <span class="n">ray</span><span class="o">.</span><span class="n">data</span><span class="o">.</span><span class="n">read_parquet</span><span class="p">(</span><span class="n">fuse_path</span><span class="p">)</span>

<span class="c1"># For example, read a Delta Table as a Spark DataFrame</span>
<span class="n">spark_df</span> <span class="o">=</span> <span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;diviner_demo.diviner_pedestrians_data_500&quot;</span><span class="p">)</span>

<span class="c1"># Provide a dbfs location to write the table to</span>
<span class="n">data_location_2</span> <span class="o">=</span> <span class="p">(</span>
    <span class="s2">&quot;dbfs:/home/example.user@databricks.com/data/ray_test/test_data_2&quot;</span>
<span class="p">)</span>

<span class="c1"># Convert the Spark DataFrame to a Ray dataset</span>
<span class="n">ray_dataset</span> <span class="o">=</span> <span class="n">create_ray_dataset_from_spark_dataframe</span><span class="p">(</span>
    <span class="n">spark_dataframe</span><span class="o">=</span><span class="n">spark_df</span><span class="p">,</span>
    <span class="n">dbfs_tmp_path</span><span class="o">=</span><span class="n">data_location_2</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="tune-the-ray-cluster-configuration">
<h2>Tune the Ray cluster configuration<a class="headerlink" href="#tune-the-ray-cluster-configuration" title="Permalink to this headline"> </a></h2>
<p>The recommended configuration for each Ray worker node is:</p>
<ul class="simple">
<li><p>Minimum 4 CPU cores per Ray worker node.</p></li>
<li><p>Minimum 10GB heap memory for each Ray worker node.</p></li>
</ul>
<p>So, when calling <code class="docutils literal notranslate"><span class="pre">ray.util.spark.setup_ray_cluster</span></code>, Databricks recommends setting <code class="docutils literal notranslate"><span class="pre">num_cpus_per_node</span></code> to a value &gt;=4.</p>
<p>See <a class="reference internal" href="#ray-memory"><span class="std std-ref">Memory allocation for Ray worker nodes</span></a> for details about tuning heap memory for each Ray worker node.</p>
<div class="section" id="memory-allocation-for-ray-worker-nodes">
<span id="ray-memory"></span><h3>Memory allocation for Ray worker nodes<a class="headerlink" href="#memory-allocation-for-ray-worker-nodes" title="Permalink to this headline"> </a></h3>
<p>Each Ray worker node uses two types of memory: heap memory and object store memory. The allocated memory size for each type is determined as described below.</p>
<p>The total memory allocated to each Ray worker node is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RAY_WORKER_NODE_TOTAL_MEMORY</span> <span class="o">=</span> <span class="p">(</span><span class="n">SPARK_WORKER_NODE_PHYSICAL_MEMORY</span> <span class="o">/</span> <span class="n">MAX_NUMBER_OF_LOCAL_RAY_WORKER_NODES</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">MAX_NUMBER_OF_LOCAL_RAY_WORKER_NODES</span></code> is the maximum number of Ray worker nodes that can be launched on the Spark worker node. This is determined by the argument <code class="docutils literal notranslate"><span class="pre">num_cpus_per_node</span></code> or <code class="docutils literal notranslate"><span class="pre">num_gpus_per_node</span></code>.</p>
<p>If you do not set the argument <code class="docutils literal notranslate"><span class="pre">object_store_memory_per_node</span></code>, then the heap memory size and
object store memory size allocated to each Ray worker node are:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RAY_WORKER_NODE_HEAP_MEMORY</span> <span class="o">=</span> <span class="n">RAY_WORKER_NODE_TOTAL_MEMORY</span> <span class="o">*</span> <span class="mf">0.7</span>
<span class="n">OBJECT_STORE_MEMORY_PER_NODE</span> <span class="o">=</span> <span class="n">RAY_WORKER_NODE_TOTAL_MEMORY</span> <span class="o">*</span> <span class="mf">0.3</span>
</pre></div>
</div>
<p>If you do set the argument <code class="docutils literal notranslate"><span class="pre">object_store_memory_per_node</span></code>:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">RAY_WORKER_NODE_HEAP_MEMORY</span> <span class="o">=</span> <span class="n">RAY_WORKER_NODE_TOTAL_MEMORY</span> <span class="o">-</span> <span class="n">argument_object_store_memory_per_node</span>
</pre></div>
</div>
<p>In addition, the object store memory size per Ray worker node is limited by the shared memory of the operating system. The maximum value is:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">OBJECT_STORE_MEMORY_PER_NODE_CAP</span> <span class="o">=</span> <span class="p">(</span><span class="n">SPARK_WORKER_NODE_OS_SHARED_MEMORY</span> <span class="o">/</span> <span class="n">MAX_NUMBER_OF_LOCAL_RAY_WORKER_NODES</span> <span class="o">*</span> <span class="mf">0.8</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">SPARK_WORKER_NODE_OS_SHARED_MEMORY</span></code> is the <code class="docutils literal notranslate"><span class="pre">/dev/shm</span></code> disk size configured for the Spark worker node.</p>
</div>
</div>
<div class="section" id="enable-stack-traces-and-flame-graphs-on-the-ray-dashboard-actors-page">
<h2>Enable stack traces and flame graphs on the Ray Dashboard Actors page<a class="headerlink" href="#enable-stack-traces-and-flame-graphs-on-the-ray-dashboard-actors-page" title="Permalink to this headline"> </a></h2>
<p>On the Ray <strong>Dashboard Actors</strong> page, you can view stack traces and flame graphs for active Ray actors.
To view this information, use the following command to install “py-spy” before you starting the Ray cluster:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="n">pip</span> <span class="n">install</span> <span class="n">py</span><span class="o">-</span><span class="n">spy</span>
</pre></div>
</div>
</div>
<div class="section" id="shut-down-a-ray-cluster">
<h2>Shut down a Ray cluster<a class="headerlink" href="#shut-down-a-ray-cluster" title="Permalink to this headline"> </a></h2>
<p>To shut down a Ray cluster running on Databricks, you can call the
<a class="reference external" href="https://docs.ray.io/en/master/cluster/vms/user-guides/community/spark.html#ray.util.spark.shutdown_ray_cluster">ray.utils.spark.shutdown_ray_cluster</a> API.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Ray clusters also shut down when:</p>
<ul class="simple">
<li><p>You detach your interactive notebook from your Databricks cluster.</p></li>
<li><p>Your Databricks <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">job</span></a> completes.</p></li>
<li><p>Your Databricks cluster is restarted or terminated.</p></li>
<li><p>There’s no activity for the specified idle time.</p></li>
</ul>
</div>
</div>
<div class="section" id="example-notebook">
<h2>Example notebook<a class="headerlink" href="#example-notebook" title="Permalink to this headline"> </a></h2>
<p>The following notebook demonstrates how to create a Ray cluster and run a Ray application on Databricks.</p>
<div class="embedded-notebook-section section" id="ray-on-spark-starter-notebook">
<span id="ray-starter-notebook"></span><h3>Ray on Spark starter notebook<a class="headerlink" href="#ray-on-spark-starter-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/machine-learning/ray-starter-notebook.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/machine-learning/ray-starter-notebook.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/machine-learning/ray-starter-notebook.html"            id="ddfc9361276c746e1b4f430d480257d479a92438c763e66eddefccda04e4e7cd" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
<div class="section" id="limitations">
<h2>Limitations<a class="headerlink" href="#limitations" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Ray cluster autoscaling is not supported yet. The API <code class="docutils literal notranslate"><span class="pre">ray.util.spark.setup_ray_cluster</span></code> can only start Ray cluster with fixed number of Ray worker nodes.</p></li>
<li><p>Multi-user shared Databricks clusters (isolation mode enabled) are not supported.</p></li>
<li><p>When using %pip to install packages, the Ray cluster will shut down. Make sure to start Ray after you’re done installing all of your libraries with %pip.</p></li>
<li><p>Using integrations that override the configuration from <code class="docutils literal notranslate"><span class="pre">ray.util.spark.setup_ray_cluster</span></code> can cause the Ray cluster to become unstable and can crash the Ray context. For example, using the <code class="docutils literal notranslate"><span class="pre">xgboost_ray</span></code> package and setting <code class="docutils literal notranslate"><span class="pre">RayParams</span></code> with an actor or <code class="docutils literal notranslate"><span class="pre">cpus_per_actor</span></code> configuration in excess of the Ray cluster configuration can silently crash the Ray cluster.</p></li>
</ul>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>