

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="This article describes the state-of-the-art open models that are supported by the Databricks Foundation Model APIs. It also provides example query requests and responses for each model." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Databricks Foundation Model APIs supported models">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Databricks Foundation Model APIs supported models &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/machine-learning/foundation-models/supported-models.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/machine-learning/foundation-models/supported-models.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/machine-learning/foundation-models/supported-models.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/machine-learning/foundation-models/supported-models.html" class="notranslate">English</option>
    <option value="../../../ja/machine-learning/foundation-models/supported-models.html" class="notranslate">日本語</option>
    <option value="../../../pt/machine-learning/foundation-models/supported-models.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Databricks Foundation Model APIs supported models</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="databricks-foundation-model-apis-supported-models">
<h1>Databricks Foundation Model APIs supported models<a class="headerlink" href="#databricks-foundation-model-apis-supported-models" title="Permalink to this headline"> </a></h1>
<div class="preview admonition">
<p class="admonition-title">Preview</p>
<p>This feature is in <a class="reference internal" href="../../release-notes/release-types.html"><span class="doc">Public Preview</span></a>.</p>
</div>
<p>This article describes the state-of-the-art open models that are supported by the <a class="reference internal" href="index.html"><span class="doc">Databricks Foundation Model APIs</span></a>. It also provides example query requests and responses for each model.</p>
<p>You can interact with these supported models using the <a class="reference internal" href="#playground"><span class="std std-ref">AI Playground</span></a>.</p>
<div class="section" id="llama-2-70b-chat">
<span id="llama2-70b"></span><h2>Llama 2 70B Chat<a class="headerlink" href="#llama-2-70b-chat" title="Permalink to this headline"> </a></h2>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>Llama 2 is licensed under the <a class="reference external" href="https://ai.meta.com/llama/license/">LLAMA 2 Community License</a>, Copyright © Meta Platforms, Inc. All Rights Reserved. Customers are responsible for ensuring compliance with applicable model licenses.</p>
</div>
<p>Llama-2-70B-Chat is a state-of-the-art 70B parameter language model with a context length of 4,096 tokens, trained by Meta. It excels at interactive applications that require strong reasoning capabilities, including summarization, question-answering, and chat applications.</p>
<p>Compared to other models with smaller parameter counts, Llama-2 demonstrates the strongest performance out-of-the-box across traditional natural language understanding benchmarks. Similar to other large language models, Llama-2-70B’s output may omit some facts and occasionally produce false information. Databricks recommends using retrieval augmented generation (RAG) in scenarios where accuracy is especially important.</p>
<div class="section" id="query-example-and-response">
<h3>Query example and response<a class="headerlink" href="#query-example-and-response" title="Permalink to this headline"> </a></h3>
<p>The serving endpoint for this model is <code class="docutils literal notranslate"><span class="pre">databricks-llama-2-70b-chat</span></code>. For parameters and syntax, see <a class="reference internal" href="api-reference.html#chat"><span class="std std-ref">Chat task</span></a>.</p>
<p>The following is a query example.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="se">\</span>
-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_TOKEN</span><span class="w"> </span><span class="se">\</span>
-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;messages&quot;: [</span>
<span class="s1">    {</span>
<span class="s1">      &quot;role&quot;: &quot;user&quot;,</span>
<span class="s1">      &quot;content&quot;: &quot;Hello! What is a fun fact about llamas?&quot;</span>
<span class="s1">    }</span>
<span class="s1">  ],</span>
<span class="s1">  &quot;max_tokens&quot;: 128</span>
<span class="s1">}&#39;</span><span class="w"> </span><span class="se">\</span>
https://&lt;workspace_host&gt;.databricks.com/serving-endpoints/databricks-llama-2-70b-chat/invocations<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>The following is an example response:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">  </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="s2">&quot;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="s2">&quot;chat.completion&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="mi">1698916461</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="s2">&quot;llama-2-70b-chat-hf&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="nt">&quot;choices&quot;</span><span class="p">:[{</span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
<span class="w">              </span><span class="nt">&quot;message&quot;</span><span class="p">:{</span>
<span class="w">                        </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
<span class="w">                        </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="s2">&quot; Llamas have a unique way of communicating with each other through a series of ear and body postures, as well as a distinctive \&quot;llama language\&quot; that sounds like a mixture of humming and grunting.&quot;</span><span class="p">},</span>
<span class="w">              </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="s2">&quot;stop&quot;</span><span class="p">}],</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:{</span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="mi">47</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="mi">49</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="mi">96</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model</span></code> field in the response gives the exact model version being used.</p>
</div>
</div>
<div class="section" id="mixtral-8x7b-instruct">
<span id="mixtral-8x7b"></span><h2>Mixtral-8x7B Instruct<a class="headerlink" href="#mixtral-8x7b-instruct" title="Permalink to this headline"> </a></h2>
<p>Mixtral-8x7B Instruct is a high-quality sparse mixture of experts model (SMoE) trained by Mistral AI. Mixtral-8x7B Instruct can be used for a variety of tasks such as question-answering, summarization, and extraction.</p>
<p>Mixtral can handle context lengths up to 32k tokens. Mixtral can process English, French, Italian, German, and Spanish. Mixtral matches or outperforms Llama 2 70B and GPT3.5, on most benchmarks (<a class="reference external" href="https://mistral.ai/news/mixtral-of-experts/">Mixtral performance</a>), while being four times faster than LLaMA 70B during inference.</p>
<p>Similar to other large language models, Mixtral-8x7B Instruct model should not be relied on to produce factually accurate information. While great efforts have been taken to clean the pretraining data, it is possible that this model could generate lewd, biased or otherwise offensive outputs. To reduce risk, Databricks defaults to using a variant of Mistral’s <a class="reference external" href="https://docs.mistral.ai/platform/guardrailing/">safe mode system prompt</a>.</p>
<div class="section" id="query-example-and-response">
<span id="query-example-and-response-1"></span><h3>Query example and response<a class="headerlink" href="#query-example-and-response" title="Permalink to this headline"> </a></h3>
<p>The serving endpoint for this model is <code class="docutils literal notranslate"><span class="pre">databricks-mixtral-8x7b-instruct</span></code>. For parameters and syntax, see <a class="reference internal" href="api-reference.html#chat"><span class="std std-ref">Chat task</span></a>.</p>
<p>The following is a query example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="se">\</span>
-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_TOKEN</span><span class="w"> </span><span class="se">\</span>
-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
-d<span class="w"> </span><span class="s1">&#39;{</span>
<span class="s1">  &quot;messages&quot;: [</span>
<span class="s1">    {</span>
<span class="s1">      &quot;role&quot;: &quot;user&quot;,</span>
<span class="s1">      &quot;content&quot;: &quot;Hello! What is an MoE model?&quot;</span>
<span class="s1">    }</span>
<span class="s1">  ],</span>
<span class="s1">  &quot;max_tokens&quot;: 300</span>
<span class="s1">}&#39;</span><span class="w"> </span><span class="se">\</span>
https://&lt;workspace_host&gt;.databricks.com/serving-endpoints/databricks-mixtral-8x7b-instruct/invocations<span class="w"> </span><span class="se">\</span>
</pre></div>
</div>
<p>The following is an example response:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span>
<span class="w">   </span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="s2">&quot;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="s2">&quot;chat.completion&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;created&quot;</span><span class="p">:</span><span class="mi">1702685137</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="s2">&quot;mixtral-8x7b-instruct-v0.1&quot;</span><span class="p">,</span>
<span class="w">   </span><span class="nt">&quot;choices&quot;</span><span class="p">:[</span>
<span class="w">      </span><span class="p">{</span>
<span class="w">         </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
<span class="w">         </span><span class="nt">&quot;message&quot;</span><span class="p">:{</span>
<span class="w">            </span><span class="nt">&quot;role&quot;</span><span class="p">:</span><span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;content&quot;</span><span class="p">:</span><span class="s2">&quot; Hello! An \&quot;MoE\&quot; model stands for \&quot;Mixture of Experts\&quot; model. It is a type of machine learning model that combines the predictions of multiple expert models, each of which is trained on a different subset of the data. The idea behind MoE models is to allow the model to specialize on different parts of the input space, thus enabling more accurate and efficient predictions.\n\nIn an MoE model, the input is first passed through a gating network, which determines the weight or probability of each expert model being used for that input. The outputs from the selected expert models are then combined, often using a weighted sum or product, to produce the final prediction.\n\nMoE models have been shown to be effective in a variety of applications, including natural language processing, computer vision, and speech recognition. They can also be used to scale up models to handle very large datasets or high-dimensional input spaces, by distributing the computation across multiple experts. However, MoE models can be computationally expensive and challenging to train, due to the need to balance the load across the experts and ensure that they specialize appropriately.&quot;</span>
<span class="w">         </span><span class="p">},</span>
<span class="w">         </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="s2">&quot;stop&quot;</span>
<span class="w">      </span><span class="p">}</span>
<span class="w">   </span><span class="p">],</span>
<span class="w">   </span><span class="nt">&quot;usage&quot;</span><span class="p">:{</span>
<span class="w">      </span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="mi">20</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="mi">237</span><span class="p">,</span>
<span class="w">      </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="mi">257</span>
<span class="w">   </span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model</span></code> field in the response gives the exact model version being used.</p>
</div>
</div>
<div class="section" id="mpt-7b-instruct">
<span id="mpt-7b"></span><h2>MPT 7B Instruct<a class="headerlink" href="#mpt-7b-instruct" title="Permalink to this headline"> </a></h2>
<p>MPT-7B-8K-Instruct is a 6.7B parameter model trained by MosaicML for long-form instruction following, especially question-answering on and summarization of longer documents. The model is pre-trained for 1.5T tokens on a mixture of datasets, and fine-tuned on a dataset derived from the Databricks Dolly-15k and the Anthropic Helpful and Harmless (HH-RLHF) datasets The model name you see in the product is <code class="docutils literal notranslate"><span class="pre">mpt-7b-instruct</span></code> but the model specifically being used is the newer version of the model.</p>
<p>MPT-7B-8K-Instruct can be used for a variety of tasks such as question-answering, summarization, and extraction. It is very fast relative to Llama-2-70B but might generate lower quality responses. This model supports a context length of 8 thousand tokens. <a class="reference external" href="https://www.mosaicml.com/blog/long-context-mpt-7b-8k">Learn more about the MPT-7B-8k-Instruct model</a>.</p>
<p>Similar to other language models of this size, MPT-7B-8K-Instruct should not be relied on to produce factually accurate information. This model was trained on various public datasets. While great efforts have been taken to clean the pretraining data, it is possible that this model could generate lewd, biased or otherwise offensive outputs.</p>
<div class="section" id="query-example-and-response">
<span id="query-example-and-response-2"></span><h3>Query example and response<a class="headerlink" href="#query-example-and-response" title="Permalink to this headline"> </a></h3>
<p>The serving endpoint for this model is <code class="docutils literal notranslate"><span class="pre">databricks-mpt-7b-instruct</span></code>. For the parameters and syntax, see <a class="reference internal" href="api-reference.html#completion"><span class="std std-ref">Completion task</span></a>.</p>
<p>The following is a query example.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="se">\</span>
<span class="w"> </span>-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_TOKEN</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
<span class="w"> </span>-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
<span class="w"> </span>-d<span class="w"> </span><span class="s1">&#39;{&quot;prompt&quot;: &quot;What is a quoll?&quot;, &quot;max_tokens&quot;: 64}&#39;</span><span class="w"> </span><span class="se">\</span>
https://&lt;workspace_host&gt;.databricks.com/serving-endpoints/databricks-mpt-7b-instruct/invocations
</pre></div>
</div>
<p>The following is an example response:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="s2">&quot;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;text_completion&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;mpt-7b-8k-instruct&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;choices&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">[{</span><span class="nt">&quot;text&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot; A quoll is a carnivorous mammal native to Australia. The species is sometimes known as a “marsupial predator.”&quot;</span><span class="p">,</span>
<span class="w">              </span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">0</span><span class="p">,</span>
<span class="w">              </span><span class="nt">&quot;logprobs&quot;</span><span class="p">:</span><span class="w"> </span><span class="kc">null</span><span class="p">,</span>
<span class="w">              </span><span class="nt">&quot;finish_reason&quot;</span><span class="p">:</span><span class="w"> </span><span class="s2">&quot;stop&quot;</span><span class="p">}],</span>
<span class="w">  </span><span class="nt">&quot;usage&quot;</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">35</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;completion_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">29</span><span class="p">,</span>
<span class="w">            </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="w"> </span><span class="mi">64</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model</span></code> field in the response gives the exact model version.</p>
</div>
</div>
<div class="section" id="mpt-30b-instruct">
<span id="mpt-30b"></span><h2>MPT 30B Instruct<a class="headerlink" href="#mpt-30b-instruct" title="Permalink to this headline"> </a></h2>
<p>MPT-30B-Instruct is a 30B parameter model for instruction following trained by MosaicML. The model is pre-trained for 1T tokens on a mixture of English text and code, and then further instruction fine-tuned on a dataset derived from Databricks Dolly-15k, Anthropic Helpful and Harmless (HH-RLHF), CompetitionMath, DuoRC, CoT GSM8k, QASPER, QuALITY, SummScreen, and Spider datasets.</p>
<p>MPT-30B-Instruct can be used for a variety of tasks such as question-answering, summarization, and extraction. It is very fast relative to Llama-2-70B but might generate lower quality responses and does not support multi-turn chat. This model supports a context length of 8,192 tokens. <a class="reference external" href="https://www.mosaicml.com/blog/mpt-30b">Learn more about the MPT-30B-Instruct model</a>.</p>
<p>Similar to other language models of this size, MPT-30B-Instruct should not be relied on to produce factually accurate information. This model was trained on various public datasets. While great efforts have been taken to clean the pre-training data, it is possible that this model could generate lewd, biased, or otherwise offensive outputs.</p>
<div class="section" id="query-example-and-response">
<span id="query-example-and-response-3"></span><h3>Query example and response<a class="headerlink" href="#query-example-and-response" title="Permalink to this headline"> </a></h3>
<p>The following is a query example and response. For the parameters and syntax, see <a class="reference internal" href="api-reference.html#completion"><span class="std std-ref">Completion task</span></a>.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span>https://<span class="o">{</span>domain<span class="o">}</span>/serving-endpoints/databricks-mpt-30b-instruct/invocations<span class="w"> </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">&quot;Authorization: &lt;API_KEY&gt;&quot;</span><span class="w"> </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
-d<span class="w"> </span><span class="s1">&#39;{&quot;prompt&quot;: &quot;Write 3 reasons why you should train an AI model on domain specific data set.&quot;, &quot;stream&quot;: true}&#39;</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="bge-large-en">
<span id="bge-large"></span><h2>BGE Large (En)<a class="headerlink" href="#bge-large-en" title="Permalink to this headline"> </a></h2>
<p><a class="reference external" href="https://huggingface.co/BAAI/bge-large-en-v1.5">BAAI General Embedding (BGE)</a> is a text embedding model that can map any text to a 1024-dimension embedding vector. These vectors can be used in vector databases for LLMs, as well as tasks like retrieval, classification, question-answering, clustering, or semantic search. This endpoint serves the English version of the model.</p>
<p>Embedding models are especially effective when used in tandem with LLMs for retrieval augmented generation (RAG) use cases. BGE can be used to find relevant text snippets in large chunks of documents that can be used in the context of an LLM.</p>
<p>In RAG applications, you may be able to improve the performance of your retrieval system by including an instruction parameter. The BGE authors recommend trying the instruction <code class="docutils literal notranslate"><span class="pre">&quot;Represent</span> <span class="pre">this</span> <span class="pre">sentence</span> <span class="pre">for</span> <span class="pre">searching</span> <span class="pre">relevant</span> <span class="pre">passages:&quot;</span></code> for query embeddings, though its performance impact is domain dependent.</p>
<div class="section" id="query-example-and-response">
<span id="query-example-and-response-4"></span><h3>Query example and response<a class="headerlink" href="#query-example-and-response" title="Permalink to this headline"> </a></h3>
<p>The serving endpoint for this model is <code class="docutils literal notranslate"><span class="pre">databricks-bge-large-en</span></code>. For parameters and syntax, see <a class="reference internal" href="api-reference.html#embedding"><span class="std std-ref">Embedding task</span></a>.</p>
<p>The following is a query example.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>curl<span class="w"> </span><span class="se">\</span>
-u<span class="w"> </span>token:<span class="nv">$DATABRICKS_TOKEN</span><span class="w"> </span><span class="se">\</span>
-X<span class="w"> </span>POST<span class="w"> </span><span class="se">\</span>
-H<span class="w"> </span><span class="s2">&quot;Content-Type: application/json&quot;</span><span class="w"> </span><span class="se">\</span>
-d<span class="w">  </span><span class="s1">&#39;{ &quot;input&quot;: &quot;Embed this sentence!&quot;}&#39;</span><span class="w"> </span><span class="se">\</span>
https://&lt;workspace_host&gt;.databricks.com/serving-endpoints/databricks-bge-large-en/invocations
</pre></div>
</div>
<p>The following is an example response:</p>
<div class="highlight-json notranslate"><div class="highlight"><pre><span></span><span class="p">{</span><span class="nt">&quot;id&quot;</span><span class="p">:</span><span class="s2">&quot;xxxxxxxx-xxxx-xxxx-xxxx-xxxxxxxxxxxx&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="s2">&quot;list&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;model&quot;</span><span class="p">:</span><span class="s2">&quot;bge-large-en-v1.5&quot;</span><span class="p">,</span>
<span class="w"> </span><span class="nt">&quot;data&quot;</span><span class="p">:[{</span><span class="nt">&quot;index&quot;</span><span class="p">:</span><span class="mi">0</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;object&quot;</span><span class="p">:</span><span class="s2">&quot;embedding&quot;</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;embedding&quot;</span><span class="p">:[</span><span class="mf">0.0167999267578125</span><span class="p">,</span>
<span class="w">                       </span><span class="mf">0.01250457763671875</span><span class="p">,</span>
<span class="w">                       </span><span class="c1">// ...</span>
<span class="w">                       </span><span class="mf">0.000004649162292480469</span><span class="p">]</span>
<span class="w">        </span><span class="p">}],</span>
<span class="w"> </span><span class="nt">&quot;usage&quot;</span><span class="p">:{</span><span class="nt">&quot;prompt_tokens&quot;</span><span class="p">:</span><span class="mi">7</span><span class="p">,</span>
<span class="w">          </span><span class="nt">&quot;total_tokens&quot;</span><span class="p">:</span><span class="mi">7</span><span class="p">}</span>
<span class="p">}</span>
</pre></div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">model</span></code> field in the response gives the exact model version.</p>
</div>
</div>
<div class="section" id="chat-with-supported-llms-using-ai-playground">
<span id="playground"></span><h2>Chat with supported LLMs using AI Playground<a class="headerlink" href="#chat-with-supported-llms-using-ai-playground" title="Permalink to this headline"> </a></h2>
<p>You can interact with supported large language models using the AI Playground. The AI Playground is a chat-like environment where you can test, prompt, and compare LLMs. This functionality is available in your Databricks workspace.</p>
<div class="figure align-default">
<img alt="AI playground" src="../../_images/ai-playground.png" />
</div>
</div>
<div class="section" id="additional-resources">
<h2>Additional resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><a class="reference internal" href="query-foundation-model-apis.html"><span class="doc">How to query Foundation Model APIs with the Python SDK</span></a></p></li>
<li><p><a class="reference internal" href="api-reference.html"><span class="doc">Foundation Model APIs reference</span></a></p></li>
<li><p><a class="reference internal" href="index.html"><span class="doc">Databricks Foundation Model APIs</span></a></p></li>
</ul>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>