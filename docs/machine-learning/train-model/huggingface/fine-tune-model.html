

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to fine-tune a natural language processing model with Hugging Face Transformers on a single node GPU." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Fine-tune Hugging Face models for a single GPU">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Fine-tune Hugging Face models for a single GPU &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/machine-learning/train-model/huggingface/fine-tune-model.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/machine-learning/train-model/huggingface/fine-tune-model.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/machine-learning/train-model/huggingface/fine-tune-model.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../../genindex.html" />
  <link rel="search" title="Search" href="../../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../../en/machine-learning/train-model/huggingface/fine-tune-model.html" class="notranslate">English</option>
    <option value="../../../../ja/machine-learning/train-model/huggingface/fine-tune-model.html" class="notranslate">日本語</option>
    <option value="../../../../pt/machine-learning/train-model/huggingface/fine-tune-model.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Fine-tune Hugging Face models for a single GPU</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="fine-tune-hugging-face-models-for-a-single-gpu">
<h1>Fine-tune Hugging Face models for a single GPU<a class="headerlink" href="#fine-tune-hugging-face-models-for-a-single-gpu" title="Permalink to this headline"> </a></h1>
<p>This article describes how to fine-tune a Hugging Face model with the Hugging Face <code class="docutils literal notranslate"><span class="pre">transformers</span></code> library on a single GPU. It also includes Databricks-specific recommendations for loading data from the lakehouse and logging models to MLflow, which enables you to use and govern your models on Databricks.</p>
<p>The Hugging Face <code class="docutils literal notranslate"><span class="pre">transformers</span></code> library provides the <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer">Trainer</a> utility and <a class="reference external" href="https://huggingface.co/docs/transformers/model_doc/auto">Auto Model</a> classes that enable loading and fine-tuning Transformers models.</p>
<p>These tools are available for the following tasks with simple modifications:</p>
<ul class="simple">
<li><p>Loading models to fine-tune.</p></li>
<li><p>Constructing the configuration for the Hugging Face Transformers Trainer utility.</p></li>
<li><p>Performing training on a single GPU.</p></li>
</ul>
<p>See <a class="reference internal" href="index.html"><span class="doc">What are Hugging Face Transformers?</span></a></p>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>A single-node <a class="reference internal" href="../../../compute/configure.html"><span class="doc">cluster</span></a> with one GPU on the driver.</p></li>
<li><p>The GPU version of Databricks Runtime 13.0 ML and above.</p>
<ul>
<li><p>This example for fine-tuning requires the 🤗 Transformers, 🤗 Datasets, and 🤗 Evaluate packages which are included in Databricks Runtime 13.0 ML and above.</p></li>
</ul>
</li>
<li><p>MLflow 2.3.</p></li>
<li><p><a class="reference internal" href="load-data.html"><span class="doc">Data prepared and loaded for fine-tuning a model with transformers</span></a>.</p></li>
</ul>
</div>
<div class="section" id="tokenize-a-hugging-face-dataset">
<h2>Tokenize a Hugging Face dataset<a class="headerlink" href="#tokenize-a-hugging-face-dataset" title="Permalink to this headline"> </a></h2>
<p>Hugging Face Transformers models expect tokenized input, rather than the text in the downloaded data. To ensure compatibility with the base model, use an <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/autoclass_tutorial#autotokenizer">AutoTokenizer</a> loaded from the base model. Hugging Face <code class="docutils literal notranslate"><span class="pre">datasets</span></code> allows you to directly apply the tokenizer consistently to both the training and testing data.</p>
<p>For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoTokenizer</span>

<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">AutoTokenizer</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">base_model</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">tokenize_function</span><span class="p">(</span><span class="n">examples</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">tokenizer</span><span class="p">(</span><span class="n">examples</span><span class="p">[</span><span class="s2">&quot;text&quot;</span><span class="p">],</span> <span class="n">padding</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">truncation</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

<span class="n">train_test_tokenized</span> <span class="o">=</span> <span class="n">train_test_dataset</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">tokenize_function</span><span class="p">,</span> <span class="n">batched</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="set-up-the-training-configuration">
<h2>Set up the training configuration<a class="headerlink" href="#set-up-the-training-configuration" title="Permalink to this headline"> </a></h2>
<p>Hugging Face training configuration tools can be used to configure a <a class="reference external" href="https://huggingface.co/docs/transformers/main_classes/trainer">Trainer</a>. The Trainer classes require the user to provide:</p>
<ul class="simple">
<li><p>Metrics</p></li>
<li><p>A base model</p></li>
<li><p>A training configuration</p></li>
</ul>
<p>You can configure evaluation metrics in addition to the default <code class="docutils literal notranslate"><span class="pre">loss</span></code> metric that the <code class="docutils literal notranslate"><span class="pre">Trainer</span></code> computes. The following example demonstrates adding <code class="docutils literal notranslate"><span class="pre">accuracy</span></code> as a metric:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">evaluate</span>
<span class="n">metric</span> <span class="o">=</span> <span class="n">evaluate</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;accuracy&quot;</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">compute_metrics</span><span class="p">(</span><span class="n">eval_pred</span><span class="p">):</span>
    <span class="n">logits</span><span class="p">,</span> <span class="n">labels</span> <span class="o">=</span> <span class="n">eval_pred</span>
    <span class="n">predictions</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">argmax</span><span class="p">(</span><span class="n">logits</span><span class="p">,</span> <span class="n">axis</span><span class="o">=-</span><span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">metric</span><span class="o">.</span><span class="n">compute</span><span class="p">(</span><span class="n">predictions</span><span class="o">=</span><span class="n">predictions</span><span class="p">,</span> <span class="n">references</span><span class="o">=</span><span class="n">labels</span><span class="p">)</span>
</pre></div>
</div>
<p>Use the <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/auto#natural-language-processing">Auto Model classes for NLP</a> to load the appropriate model for your task.</p>
<p>For text classification, use <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/model_doc/auto#transformers.AutoModelForSequenceClassification">AutoModelForSequenceClassification</a> to load a base model for text classification. When creating the model, provide the number of classes and the label mappings created during dataset preparation.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">AutoModelForSequenceClassification</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span>
        <span class="n">base_model</span><span class="p">,</span>
        <span class="n">num_labels</span><span class="o">=</span><span class="nb">len</span><span class="p">(</span><span class="n">label2id</span><span class="p">),</span>
        <span class="n">label2id</span><span class="o">=</span><span class="n">label2id</span><span class="p">,</span>
        <span class="n">id2label</span><span class="o">=</span><span class="n">id2label</span>
        <span class="p">)</span>
</pre></div>
</div>
<p>Next, create the training configuration. The <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> class allows you to specify the output directory, evaluation strategy, learning rate, and other parameters.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">TrainingArguments</span><span class="p">,</span> <span class="n">Trainer</span>
<span class="n">training_args</span> <span class="o">=</span> <span class="n">TrainingArguments</span><span class="p">(</span><span class="n">output_dir</span><span class="o">=</span><span class="n">training_output_dir</span><span class="p">,</span> <span class="n">evaluation_strategy</span><span class="o">=</span><span class="s2">&quot;epoch&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>Using a <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/data_collator">data collator</a> batches input in training and evaluation datasets. <a class="reference external" href="https://huggingface.co/docs/transformers/v4.26.1/en/main_classes/data_collator#transformers.DataCollatorWithPadding">DataCollatorWithPadding</a> gives good baseline performance for text classification.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">DataCollatorWithPadding</span>
<span class="n">data_collator</span> <span class="o">=</span> <span class="n">DataCollatorWithPadding</span><span class="p">(</span><span class="n">tokenizer</span><span class="p">)</span>
</pre></div>
</div>
<p>With all of these parameters constructed, you can now create a <code class="docutils literal notranslate"><span class="pre">Trainer</span></code>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">trainer</span> <span class="o">=</span> <span class="n">Trainer</span><span class="p">(</span>
    <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">args</span><span class="o">=</span><span class="n">training_args</span><span class="p">,</span>
    <span class="n">train_dataset</span><span class="o">=</span><span class="n">train_test_dataset</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">],</span>
    <span class="n">eval_dataset</span><span class="o">=</span><span class="n">train_test_dataset</span><span class="p">[</span><span class="s2">&quot;test&quot;</span><span class="p">],</span>
    <span class="n">compute_metrics</span><span class="o">=</span><span class="n">compute_metrics</span><span class="p">,</span>
    <span class="n">data_collator</span><span class="o">=</span><span class="n">data_collator</span><span class="p">,</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="train-and-log-to-mlflow">
<h2>Train and log to MLflow<a class="headerlink" href="#train-and-log-to-mlflow" title="Permalink to this headline"> </a></h2>
<p>Hugging Face interfaces well with MLflow and automatically logs metrics during model training using the <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/main_classes/callback#transformers.integrations.MLflowCallback">MLflowCallback</a>. However, you must log the trained model yourself.</p>
<p>Wrap training in an MLflow run. This constructs a Transformers pipeline from the tokenizer and the trained model, and writes it to local disk. Finally, log the model to MLflow with <a class="reference external" href="https://mlflow.org/docs/latest/models.html#transformers-transformers-experimental">mlflow.transformers.log_model</a>.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">transformers</span> <span class="kn">import</span> <span class="n">pipeline</span>

<span class="k">with</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">start_run</span><span class="p">()</span> <span class="k">as</span> <span class="n">run</span><span class="p">:</span>
  <span class="n">trainer</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
  <span class="n">trainer</span><span class="o">.</span><span class="n">save_model</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">)</span>
  <span class="n">pipe</span> <span class="o">=</span> <span class="n">pipeline</span><span class="p">(</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span> <span class="n">model</span><span class="o">=</span><span class="n">AutoModelForSequenceClassification</span><span class="o">.</span><span class="n">from_pretrained</span><span class="p">(</span><span class="n">model_output_dir</span><span class="p">),</span> <span class="n">batch_size</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">tokenizer</span><span class="o">=</span><span class="n">tokenizer</span><span class="p">)</span>
  <span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
        <span class="n">transformers_model</span><span class="o">=</span><span class="n">pipe</span><span class="p">,</span>
        <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;classification&quot;</span><span class="p">,</span>
        <span class="n">input_example</span><span class="o">=</span><span class="s2">&quot;Hi there!&quot;</span><span class="p">,</span>
    <span class="p">)</span>
</pre></div>
</div>
<p>If you don’t need to create a pipeline, you can submit the components that are used in training into a dictionary:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">model_info</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">transformers</span><span class="o">.</span><span class="n">log_model</span><span class="p">(</span>
  <span class="n">transformers_model</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;model&quot;</span><span class="p">:</span> <span class="n">trainer</span><span class="o">.</span><span class="n">model</span><span class="p">,</span> <span class="s2">&quot;tokenizer&quot;</span><span class="p">:</span> <span class="n">tokenizer</span><span class="p">},</span>
  <span class="n">task</span><span class="o">=</span><span class="s2">&quot;text-classification&quot;</span><span class="p">,</span>
  <span class="n">artifact_path</span><span class="o">=</span><span class="s2">&quot;text_classifier&quot;</span><span class="p">,</span>
  <span class="n">input_example</span><span class="o">=</span><span class="p">[</span><span class="s2">&quot;MLflow is great!&quot;</span><span class="p">,</span> <span class="s2">&quot;MLflow on Databricks is awesome!&quot;</span><span class="p">],</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="load-the-model-for-inference">
<h2>Load the model for inference<a class="headerlink" href="#load-the-model-for-inference" title="Permalink to this headline"> </a></h2>
<p>When your model is logged and ready, loading the model for inference is the same as loading the MLflow wrapped pre-trained model.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">logged_model</span> <span class="o">=</span> <span class="s2">&quot;runs:/</span><span class="si">{run_id}</span><span class="s2">/</span><span class="si">{model_artifact_path}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">run_id</span><span class="o">=</span><span class="n">run</span><span class="o">.</span><span class="n">info</span><span class="o">.</span><span class="n">run_id</span><span class="p">,</span> <span class="n">model_artifact_path</span><span class="o">=</span><span class="n">model_artifact_path</span><span class="p">)</span>

<span class="c1"># Load model as a Spark UDF. Override result_type if the model does not return double values.</span>
<span class="n">loaded_model_udf</span> <span class="o">=</span> <span class="n">mlflow</span><span class="o">.</span><span class="n">pyfunc</span><span class="o">.</span><span class="n">spark_udf</span><span class="p">(</span><span class="n">spark</span><span class="p">,</span> <span class="n">model_uri</span><span class="o">=</span><span class="n">logged_model</span><span class="p">,</span> <span class="n">result_type</span><span class="o">=</span><span class="s1">&#39;string&#39;</span><span class="p">)</span>

<span class="n">test</span> <span class="o">=</span> <span class="n">test</span><span class="o">.</span><span class="n">select</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">text</span><span class="p">,</span> <span class="n">test</span><span class="o">.</span><span class="n">label</span><span class="p">,</span> <span class="n">loaded_model_udf</span><span class="p">(</span><span class="n">test</span><span class="o">.</span><span class="n">text</span><span class="p">)</span><span class="o">.</span><span class="n">alias</span><span class="p">(</span><span class="s2">&quot;prediction&quot;</span><span class="p">))</span>
<span class="n">display</span><span class="p">(</span><span class="n">test</span><span class="p">)</span>
</pre></div>
</div>
<p>See <a class="reference internal" href="../../model-serving/index.html"><span class="doc">Model serving with Databricks</span></a> for more information.</p>
</div>
<div class="section" id="troubleshoot-common-cuda-errors">
<h2>Troubleshoot common CUDA errors<a class="headerlink" href="#troubleshoot-common-cuda-errors" title="Permalink to this headline"> </a></h2>
<p>This section describes common CUDA errors and guidance on how to resolve them.</p>
<div class="section" id="outofmemoryerror-cuda-out-of-memory">
<h3>OutOfMemoryError: CUDA out of memory<a class="headerlink" href="#outofmemoryerror-cuda-out-of-memory" title="Permalink to this headline"> </a></h3>
<p>When training large models, a common error you may encounter is the CUDA out of memory error.</p>
<p>Example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">OutOfMemoryError: CUDA out of memory. Tried to allocate 20.00 MiB (GPU 0; 14.76 GiB total capacity; 666.34 MiB already allocated; 17.75 MiB free; 720.00 MiB reserved in total by PyTorch) If reserved memory is &gt;&gt; allocated memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and PYTORCH_CUDA_ALLOC_CONF.</span>
</pre></div>
</div>
<p>Try the following recommendations to resolve this error:</p>
<ul>
<li><p>Reduce the batch size for training. You can reduce the <code class="docutils literal notranslate"><span class="pre">per_device_train_batch_size</span></code> value in <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>.</p></li>
<li><p>Use lower precision training. You can set <code class="docutils literal notranslate"><span class="pre">fp16=True</span></code> in <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a>.</p></li>
<li><p>Use gradient_accumulation_steps in <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/main_classes/trainer#transformers.TrainingArguments">TrainingArguments</a> to effectively increase overall batch size.</p></li>
<li><p>Use <a class="reference external" href="https://huggingface.co/docs/transformers/main/en/perf_train_gpu_one#8bit-adam">8-bit Adam optimizer</a>.</p></li>
<li><p>Clean up the GPU memory before training. Sometimes, GPU memory may be occupied by some unused code.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">numba</span> <span class="kn">import</span> <span class="n">cuda</span>
<span class="n">device</span> <span class="o">=</span> <span class="n">cuda</span><span class="o">.</span><span class="n">get_current_device</span><span class="p">()</span>
<span class="n">device</span><span class="o">.</span><span class="n">reset</span><span class="p">()</span>
</pre></div>
</div>
</li>
</ul>
</div>
<div class="section" id="cuda-kernel-errors">
<h3>CUDA kernel errors<a class="headerlink" href="#cuda-kernel-errors" title="Permalink to this headline"> </a></h3>
<p>When running the training, you may get CUDA kernel errors.</p>
<p>Example:</p>
<div class="highlight-console notranslate"><div class="highlight"><pre><span></span><span class="go">CUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.</span>

<span class="go">For debugging, consider passing CUDA_LAUNCH_BLOCKING=1.</span>
</pre></div>
</div>
<p>To troubleshoot:</p>
<ul>
<li><p>Try running the code on CPU to see if the error is reproducible.</p></li>
<li><p>Another option is to get a better traceback by setting <code class="docutils literal notranslate"><span class="pre">CUDA_LAUNCH_BLOCKING=1</span></code>:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">os</span>
<span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;CUDA_LAUNCH_BLOCKING&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;1&quot;</span>
</pre></div>
</div>
</li>
</ul>
</div>
</div>
<div class="section" id="notebook-fine-tune-text-classification-on-a-single-gpu">
<h2>Notebook: Fine-tune text classification on a single GPU<a class="headerlink" href="#notebook-fine-tune-text-classification-on-a-single-gpu" title="Permalink to this headline"> </a></h2>
<p>To get started quickly with example code, this example notebook provides an end-to-end example for fine-tuning a model for text classification. The subsequent sections of this article go into more detail around using Hugging Face for fine-tuning on Databricks.</p>
<div class="embedded-notebook-section section" id="fine-tuning-hugging-face-text-classification-models-notebook">
<span id="tune-classification-model-hugging-face-transformers"></span><h3>Fine-tuning Hugging Face text classification models notebook<a class="headerlink" href="#fine-tuning-hugging-face-text-classification-models-notebook" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/deep-learning/tune-classification-model-hugging-face-transformers.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/deep-learning/tune-classification-model-hugging-face-transformers.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/deep-learning/tune-classification-model-hugging-face-transformers.html"            id="8c16f99a25614a214d2390e3d16093c287d2df98340df688d8256a9129d3d1bb" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
<div class="section" id="additional-resources">
<h2>Additional resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline"> </a></h2>
<p>Learn more about Hugging Face on Databricks.</p>
<ul class="simple">
<li><p><a class="reference internal" href="index.html"><span class="doc">What are Hugging Face Transformers?</span></a></p></li>
<li><p>You can use Hugging Face Transformers models on Spark to scale out your NLP batch applications, see <a class="reference internal" href="model-inference-nlp.html"><span class="doc">Model inference using Hugging Face Transformers for natural language processing (NLP)</span></a>.</p></li>
</ul>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>