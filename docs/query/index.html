

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to query data from the lakehouse and external systems from Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Query data">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Query data &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/query/index.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/query/index.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/query/index.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/query/index.html" class="notranslate">English</option>
    <option value="../../ja/query/index.html" class="notranslate">日本語</option>
    <option value="../../pt/query/index.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Query data</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="query-data">
<h1>Query data<a class="headerlink" href="#query-data" title="Permalink to this headline"> </a></h1>
<p>Querying data is the foundational step for performing nearly all data-driven tasks in Databricks. Regardless of the language or tool used, workloads start by defining a query against a table or other data source and then performing actions to gain insights from the data. This article outlines the core concepts and procedures for running queries across various Databricks product offerings, and includes code examples you can adapt for your use case.</p>
<p>You can query data interactively using:</p>
<ul class="simple">
<li><p>Notebooks</p></li>
<li><p>SQL editor</p></li>
<li><p>File editor</p></li>
<li><p>Dashboards</p></li>
</ul>
<p>You can also run queries as part of Delta Live Tables pipelines or workflows.</p>
<p>For an overview of streaming queries on Databricks, see <a class="reference internal" href="streaming.html"><span class="doc">Query streaming data</span></a>.</p>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="what-data-can-you-query-with-databricks">
<span id="lakehouse-external"></span><h2>What data can you query with Databricks?<a class="headerlink" href="#what-data-can-you-query-with-databricks" title="Permalink to this headline"> </a></h2>
<p>Databricks supports querying data in multiple formats and enterprise systems. The data you query using Databricks falls into one of two broad categories: data in a Databricks lakehouse and external data.</p>
<div class="section" id="what-data-is-in-a-databricks-lakehouse">
<h3>What data is in a Databricks lakehouse?<a class="headerlink" href="#what-data-is-in-a-databricks-lakehouse" title="Permalink to this headline"> </a></h3>
<p>The Databricks Data Intelligence Platform stores all of your data in a Databricks lakehouse by default.</p>
<p>This means that when you run a basic <code class="docutils literal notranslate"><span class="pre">CREATE</span> <span class="pre">TABLE</span></code> statement to make a new table, you have created a lakehouse table. Lakehouse data has the following properties:</p>
<ul class="simple">
<li><p>Stored in the Delta Lake format.</p></li>
<li><p>Stored in cloud object storage.</p></li>
<li><p>Governed by Unity Catalog.</p></li>
</ul>
<p>Most lakehouse data on Databricks is registered in Unity Catalog as managed tables. Managed tables provide the easiest syntax and behave like other tables in most relational database management systems. Managed tables are recommended for most use cases and are suitable for all users who don’t want to worry about the implementation details of data storage.</p>
<p>An <em>unmanaged table</em>, or <em>external table</em>, is a table registered with a <code class="docutils literal notranslate"><span class="pre">LOCATION</span></code> specified. The term <em>external</em> can be misleading, as external Delta tables are still lakehouse data. Unmanaged tables might be preferred by users who directly access tables from other Delta reader clients. For an overview of differences in table semantics, see <a class="reference internal" href="../lakehouse/data-objects.html#table"><span class="std std-ref">What is a table?</span></a>.</p>
<p>Some legacy workloads might exclusively interact with Delta Lake data through file paths and not register tables at all. This data is still lakehouse data, but can be more difficult to discover because it’s not registered to Unity Catalog.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Your workspace administrator might not have upgraded your data governance to use Unity Catalog. You can still get many of the benefits of a Databricks lakehouse without Unity Catalog, but not all functionality listed in this article or throughout the Databricks documentation is supported.</p>
</div>
</div>
<div class="section" id="what-data-is-considered-external">
<h3>What data is considered external?<a class="headerlink" href="#what-data-is-considered-external" title="Permalink to this headline"> </a></h3>
<p>Any data that isn’t in a Databricks lakehouse can be considered external data. Some examples of external data include the following:</p>
<ul class="simple">
<li><p>Foreign tables registered with Lakehouse Federation.</p></li>
<li><p>Tables in the Hive metastore backed by Parquet.</p></li>
<li><p>External tables in Unity Catalog backed by JSON.</p></li>
<li><p>CSV data stored in cloud object storage.</p></li>
<li><p>Streaming data read from Kafka.</p></li>
</ul>
<p>Databricks supports configuring connections to many data sources. See <a class="reference internal" href="../connect/index.html"><span class="doc">Connect to data sources</span></a>.</p>
<p>While you can use Unity Catalog to govern access to and define tables against data stored in multiple formats and external systems, Delta Lake is a requirement for data to be considered in the lakehouse.</p>
<p>Delta Lake provides all of the transactional guarantees in Databricks, which are crucial for maintaining data integrity and consistency.  If you want to learn more about transactional guarantees on Databricks data and why they’re important, see <a class="reference internal" href="../lakehouse/acid.html"><span class="doc">What are ACID guarantees on Databricks?</span></a>.</p>
<p>Most Databricks users query a combination of lakehouse data and external data. Connecting with external data is always the first step for data ingestion and ETL pipelines that bring data into the lakehouse. For information about ingesting data, see <a class="reference internal" href="../ingestion/index.html"><span class="doc">Load data into a Databricks lakehouse</span></a>.</p>
</div>
</div>
<div class="section" id="query-tables-by-name">
<span id="tables"></span><h2>Query tables by name<a class="headerlink" href="#query-tables-by-name" title="Permalink to this headline"> </a></h2>
<p>For all data registered as a table, Databricks recommends querying using the table name.</p>
<p>If you’re using Unity Catalog, tables use a three-tier namespace with the following format: <code class="docutils literal notranslate"><span class="pre">&lt;catalog-name&gt;.&lt;schema-name&gt;.&lt;table-name&gt;</span></code>.</p>
<p>Without Unity Catalog, table identifiers use the format <code class="docutils literal notranslate"><span class="pre">&lt;schema-name&gt;.&lt;table-name&gt;</span></code>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Databricks inherits much of its SQL syntax from Apache Spark, which does not differentiate between <code class="docutils literal notranslate"><span class="pre">SCHEMA</span></code> and <code class="docutils literal notranslate"><span class="pre">DATABASE</span></code>.</p>
</div>
<p>Querying by table name is supported in all Databricks execution contexts and supported languages.</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="k">catalog_name</span><span class="p">.</span><span class="k">schema_name</span><span class="p">.</span><span class="k">table_name</span>
</pre></div>
</div>
<div class="compound-last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">table</span><span class="p">(</span><span class="s2">&quot;catalog_name.schema_name.table_name&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="query-data-by-path">
<span id="paths"></span><h2>Query data by path<a class="headerlink" href="#query-data-by-path" title="Permalink to this headline"> </a></h2>
<p>You can query structured, semi-structured, and unstructured data using file paths. Most files on Databricks are backed by cloud object storage. See <a class="reference internal" href="../files/index.html"><span class="doc">Work with files on Databricks</span></a>.</p>
<p>Databricks recommends configuring all access to cloud object storage using Unity Catalog and defining volumes for object storage locations that are directly queried. Volumes provide human-readable aliases to locations and files in cloud objects storage using catalog and schema names for the filepath. See <a class="reference internal" href="../connect/unity-catalog/index.html"><span class="doc">Connect to cloud object storage using Unity Catalog</span></a>.</p>
<p>The following examples demonstrate how to use Unity Catalog volume paths to read JSON data:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`/</span><span class="n">Volumes</span><span class="o">/</span><span class="k">catalog_name</span><span class="o">/</span><span class="k">schema_name</span><span class="o">/</span><span class="n">volume_name</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="k">to</span><span class="o">/</span><span class="k">data</span><span class="o">`</span>
</pre></div>
</div>
<div class="compound-last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;/Volumes/catalog_name/schema_name/volume_name/path/to/data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<p>For cloud locations that aren’t configured as Unity Catalog volumes, you can query data directly using URIs. You must configure access to cloud object storage to query data with URIs. See <a class="reference internal" href="../connect/storage/index.html"><span class="doc">Configure access to cloud object storage for Databricks</span></a>.</p>
<p>The following examples demonstrate how to use URIs to query JSON data in Azure Data Lake Storage Gen2, GCS, and S3:</p>
<div class="js-code-language-tabs js-code-language-tabs--literal compound">
<div class="compound-first highlight-sql notranslate"><div class="highlight"><pre><span></span><span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="n">abfss</span><span class="p">:</span><span class="o">//</span><span class="n">container</span><span class="o">-</span><span class="n">name</span><span class="o">@</span><span class="k">storage</span><span class="o">-</span><span class="n">account</span><span class="o">-</span><span class="n">name</span><span class="p">.</span><span class="n">dfs</span><span class="p">.</span><span class="n">core</span><span class="p">.</span><span class="n">windows</span><span class="p">.</span><span class="n">net</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="k">to</span><span class="o">/</span><span class="k">data</span><span class="o">`</span><span class="p">;</span>

<span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="n">gs</span><span class="p">:</span><span class="o">//</span><span class="n">bucket_name</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="k">to</span><span class="o">/</span><span class="k">data</span><span class="o">`</span><span class="p">;</span>

<span class="k">SELECT</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="k">FROM</span><span class="w"> </span><span class="n">json</span><span class="p">.</span><span class="o">`</span><span class="n">s3</span><span class="p">:</span><span class="o">//</span><span class="n">bucket_name</span><span class="o">/</span><span class="n">path</span><span class="o">/</span><span class="k">to</span><span class="o">/</span><span class="k">data</span><span class="o">`</span><span class="p">;</span>
</pre></div>
</div>
<div class="compound-last highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;abfss://container-name@storage-account-name.dfs.core.windows.net/path/to/data&quot;</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;gs://bucket_name/path/to/data&quot;</span><span class="p">)</span>

<span class="n">spark</span><span class="o">.</span><span class="n">read</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="s2">&quot;json&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">load</span><span class="p">(</span><span class="s2">&quot;s3://bucket_name/path/to/data&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="query-data-using-sql-warehouses">
<h2>Query data using SQL warehouses<a class="headerlink" href="#query-data-using-sql-warehouses" title="Permalink to this headline"> </a></h2>
<p>Databricks uses SQL warehouses for compute in the following interfaces:</p>
<ul class="simple">
<li><p>SQL editor</p></li>
<li><p>Databricks SQL queries</p></li>
<li><p>Lakeview dashboards</p></li>
<li><p>Databricks SQL dashboards</p></li>
<li><p>SQL alerts</p></li>
</ul>
<p>You can optionally use SQL warehouses with the following products:</p>
<ul class="simple">
<li><p>Databricks notebooks</p></li>
<li><p>Databricks file editor</p></li>
<li><p>Databricks workflows</p></li>
</ul>
<p>When you query data with SQL warehouses, you can use only SQL syntax. Other programming languages and APIs are not supported.</p>
<p>For workspaces that are enabled for Unity Catalog, SQL warehouses always use Unity Catalog to manage access to data sources.</p>
<p>Most queries that are run on SQL warehouses target tables. Queries that target data files should leverage Unity Catalog volumes to manage access to storage locations.</p>
<p>Using URIs directly in queries run on SQL warehouses can lead to unexpected errors.</p>
</div>
<div class="section" id="query-data-using-all-purpose-compute-or-jobs-compute">
<h2>Query data using all purpose compute or jobs compute<a class="headerlink" href="#query-data-using-all-purpose-compute-or-jobs-compute" title="Permalink to this headline"> </a></h2>
<p>Most queries that you run from Databricks notebooks, workflows, and the file editor run against compute clusters configured with Databricks Runtime. You can configure these clusters to run interactively or deploy them as <em>jobs compute</em> that power workflows. Databricks recommends that you always use jobs compute for non-interactive workloads.</p>
<div class="section" id="interactive-versus-non-interactive-workloads">
<h3>Interactive versus non-interactive workloads<a class="headerlink" href="#interactive-versus-non-interactive-workloads" title="Permalink to this headline"> </a></h3>
<p>Many users find it helpful to view query results while transformations are processed during development. Moving an interactive workload from all-purpose compute to jobs compute, you can save time and processing costs by removing queries that display results.</p>
<p>Apache Spark uses lazy code execution, meaning that results are calculated only as necessary, and multiple transformations or queries against a data source can be optimized as a single query if you don’t force results. This contrasts with the eager execution mode used in pandas, which requires calculations to be processed in order before passing results to the next method.</p>
<p>If your goal is to save cleaned, transformed, aggregated data as a new dataset, you should remove queries that display results from your code before scheduling it to run.</p>
<p>For small operations and small datasets, the time and cost savings might be marginal. Still, with large operations, substantial time can be wasted calculating and printing results to a notebook that might not be manually inspected. The same results could likely be queried from the saved output at almost no cost after storing them.</p>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>