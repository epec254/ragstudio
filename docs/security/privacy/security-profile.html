

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn about Databricks the compliance security profile." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Enable the compliance security profile">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Enable the compliance security profile &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/security/privacy/security-profile.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/security/privacy/security-profile.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/security/privacy/security-profile.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../../genindex.html" />
  <link rel="search" title="Search" href="../../search.html" />
  <link rel="top" title="Databricks on AWS" href="../../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../../en/security/privacy/security-profile.html" class="notranslate">English</option>
    <option value="../../../ja/security/privacy/security-profile.html" class="notranslate">日本語</option>
    <option value="../../../pt/security/privacy/security-profile.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Enable the compliance security profile</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="enable-the-compliance-security-profile">
<h1>Enable the compliance security profile<a class="headerlink" href="#enable-the-compliance-security-profile" title="Permalink to this headline"> </a></h1>
<p></p>
<p>If a Databricks workspace has the <em>compliance security profile</em> enabled, the workspace has additional monitoring, enforced instance types for inter-node encryption, a hardened compute image, and other features and controls. For details, see <a class="reference internal" href="#features"><span class="std std-ref">Features and technical controls</span></a>.</p>
<p>The compliance security profile includes controls that help meet the applicable security requirements of some compliance standards.</p>
<p>Enabling the compliance security profile is required to use Databricks to process data that is regulated under the following compliance standards:</p>
<ul class="simple">
<li><p><a class="reference internal" href="pci.html"><span class="doc">PCI-DSS</span></a></p></li>
<li><p><a class="reference internal" href="hipaa.html"><span class="doc">HIPAA</span></a></p></li>
<li><p><a class="reference internal" href="fedramp.html"><span class="doc">FedRAMP Moderate</span></a></p></li>
<li><p><a class="reference internal" href="irap.html"><span class="doc">Infosec Registered Assessors Program (IRAP)</span></a></p></li>
</ul>
<p>You can choose to enable the compliance security profile for its enhanced security features without the need to conform to a compliance standards.</p>
<p>Contact your Databricks account team to enable the compliance security profile. Choose how you want to enable the compliance security profile:</p>
<ul>
<li><p><strong>Account level</strong>: You can choose to apply the compliance security profile to your account, in which case all existing and future workspaces in the account use the security profile.</p></li>
<li><p><strong>Workspace level</strong>: You can specify which workspaces for which security profiles are enabled.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If you create additional workspaces later, it is your responsibility to contact your Databricks account team to request enablement of the compliance security profile on your new workspaces if needed.</p>
</div>
</li>
</ul>
<p></p>
<div class="section" id="which-compute-resources-get-enhanced-security">
<span id="which-compute-resources"></span><h2>Which compute resources get enhanced security<a class="headerlink" href="#which-compute-resources-get-enhanced-security" title="Permalink to this headline"> </a></h2>
<p>The compliance security profile enhancements apply to compute resources in the <a class="reference internal" href="../../getting-started/overview.html"><span class="doc">classic compute plane</span></a>, such as clusters and non-serverless SQL warehouses. This applies in all regions.</p>
<p><a class="reference internal" href="../../serverless-compute/index.html"><span class="doc">Serverless SQL warehouse</span></a> support for the compliance security profile varies by region. See <a class="reference internal" href="../../compute/sql-warehouse/serverless.html#security-profile"><span class="std std-ref">Serverless SQL warehouses support the compliance security profile in some regions</span></a>.</p>
</div>
<div class="section" id="requirements">
<h2>Requirements<a class="headerlink" href="#requirements" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>Your Databricks account must include the Enhanced Security and Compliance add-on. For details, see the <a class="reference external" href="https://databricks.com/product/aws-pricing">pricing page</a>.</p></li>
<li><p>Your Databricks workspace is on the E2 version of the platform.</p></li>
<li><p>Your Databricks workspace is on the <a class="reference external" href="https://databricks.com/product/aws-pricing.md">Enterprise pricing tier</a>.</p></li>
<li><p><a class="reference internal" href="../../administration-guide/account-settings-e2/single-sign-on/index.html"><span class="doc">Single sign-on (SSO)</span></a> authentication is configured for the workspace.</p></li>
<li><p>Your Databricks workspace’s root S3 bucket cannot have a period character (<code class="docutils literal notranslate"><span class="pre">.</span></code>) in its name, such as <code class="docutils literal notranslate"><span class="pre">my-bucket-1.0</span></code>. If an existing workspace’s root S3 bucket has a period character in the name, contact your Databricks account team before enabling the compliance security profile.</p></li>
</ul>
</div>
<div class="section" id="enable-the-compliance-security-profile">
<span id="enable"></span><h2>Enable the compliance security profile<a class="headerlink" href="#enable-the-compliance-security-profile" title="Permalink to this headline"> </a></h2>
<ol class="arabic">
<li><p>Prepare any existing workspaces that will use the compliance security profile. See <a class="reference internal" href="#prepare"><span class="std std-ref">Prepare a workspace for the compliance security profile</span></a>.</p></li>
<li><p>Contact your Databricks account team and request enabling the compliance security profile.</p>
<p>Decide whether you want to enable it at the account level or just for some workspaces.</p>
<p>If you want to enable it just for some workspaces, send the list of workspace IDs for the workspaces that you would like to use for the profile. Get a workspace ID from the URL when you are using the workspace. Look for <code class="docutils literal notranslate"><span class="pre">o=</span></code> in the URL. The number after <code class="docutils literal notranslate"><span class="pre">o=</span></code> is the Databricks workspace ID. For example, if the URL is <code class="docutils literal notranslate"><span class="pre">https://&lt;databricks-instance&gt;/?o=6280049833385130</span></code>, the workspace ID is <code class="docutils literal notranslate"><span class="pre">6280049833385130</span></code>.</p>
</li>
<li><p>Wait for confirmation from Databricks that the profile is now enabled.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>After you receive notification that the profile is enabled, settings may take up to an additional six hours to propagate to all environments, including global regions and to downstream systems like billing. Workloads that are actively running continue with the settings that were active at the time of starting the cluster or other compute resource, and new settings will start applying the next time these workloads are started. This means that if a change is made late in the day or on the last day of the month, you might still see usage reported with the old settings early the next day or month. Please plan accordingly.</p>
</div>
</li>
<li><p>If any clusters or SQL warehouses were running, restart them. If you have many clusters running and only want to restart the ones that were started before enablement, you can use a script that Databricks provides to <a class="reference internal" href="#cluster-start-date-script"><span class="std std-ref">determine if the start time was before the enablement date</span></a>.</p>
<p>Now that profile setup is complete, create or use Databricks compute resources as desired.</p>
</li>
</ol>
<div class="section" id="long-running-clusters">
<span id="long-running"></span><h3>Long-running clusters<a class="headerlink" href="#long-running-clusters" title="Permalink to this headline"> </a></h3>
<p>If you enable the compliance security profile for your account or your workspace, long-running clusters automatically restart after 25 days by default. Databricks recommends that workspace admins regularly restart clusters before they run for 25 days and do so during a scheduled maintenance window. This reduces the risk of an auto-restart disrupting a scheduled job.</p>
<p>If you want to restart long running clusters manually, you can use a script that Databricks provides that can determine how long your clusters have been running, and optionally restart them. See <a class="reference internal" href="../../compute/clusters-manage.html#cluster-long-running-script"><span class="std std-ref">Notebook example: Find long-running clusters</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, the behavior is different. Compute resources automatically restart only if updates are needed. You can choose a <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">regular monthly or twice-monthly schedule</span></a>, in which case the 25-day limit does not apply and the legacy workspace setting <strong>Automatic Restart of Long Running Clusters</strong> is ignored.</p>
</div>
</div>
</div>
<div class="section" id="prepare-a-workspace-for-the-compliance-security-profile">
<span id="prepare"></span><h2>Prepare a workspace for the compliance security profile<a class="headerlink" href="#prepare-a-workspace-for-the-compliance-security-profile" title="Permalink to this headline"> </a></h2>
<p>Some steps are necessary to prepare a workspace for the compliance security profile. If you have not yet enabled the security profile, follow these steps <strong>before</strong> requesting to <a class="reference internal" href="#enable"><span class="std std-ref">enable the security profile</span></a>.</p>
<p>If the security profile is already enabled at an account level and you create any new workspaces, you must follow these steps after you create any new workspace.</p>
<ol class="arabic">
<li><p>If you enable the compliance security profile for your account or your workspace, long-running clusters are automatically restarted after 25 days. If any clusters were running 25 days or longer when the compliance security profile is enabled, the clusters immediately restart, which causes running jobs to fail. Instead, check for long-running clusters before you enable the security profile. This reduces the risk of an auto-restart disrupting a scheduled job. Check how long your clusters have been running and restart any that have been running longer than 20 days (not 25 days) to reduce the risk of clusters being auto-restarted after 25 days running when the security profile is enabled. See <a class="reference internal" href="../../compute/clusters-manage.html#cluster-start"><span class="std std-ref">Restart a cluster</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, the behavior is different. Compute resources automatically restart only if updates are needed. You can choose a <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">regular monthly or twice-monthly schedule</span></a>, in which case the 25-day limit does not apply and the legacy workspace setting <strong>Automatic Restart of Long Running Clusters</strong> is ignored.</p>
</div>
</li>
<li><p>Configure <a class="reference internal" href="../../administration-guide/account-settings-e2/single-sign-on/index.html"><span class="doc">Single sign-on (SSO) authentication</span></a>.</p></li>
<li><p>Add required network ports.</p>
<ul>
<li><p><strong>For workspaces with PrivateLink back-end connectivity</strong>: You must make a change to support FIPS encryption if the workspace uses a <a class="reference internal" href="../network/classic/privatelink.html"><span class="doc">PrivateLink</span></a> back-end connection for private connectivity between the classic compute plane in your AWS account and the Databricks control plane in the Databricks account.</p>
<p>One of the <a class="reference internal" href="../network/classic/privatelink.html#requirements"><span class="std std-ref">networking requirements for PrivateLink back-end connections</span></a> is to create a separate security group for the endpoint that allows HTTPS/443 and TCP/6666 with bidirectional access (from and to) for both the workspace subnets and the endpoint subnet itself. This configuration allows access for both REST APIs (port 443) and secure cluster connectivity (6666). You can then use the security group for both purposes.</p>
<p>To support the upcoming changes for FIPS encryption, update your network security group to <strong>additionally</strong> allow bidirectional access to port 2443 for FIPS connections. The total set of ports to allow bidirectional access are 443, 2443, and 6666.</p>
</li>
<li><p><strong>For workspaces with no PrivateLink back-end connectivity</strong>: If the workspace does not use a PrivateLink back-end connection for private connectivity but the workspace is configured to restrict outbound network access, you need to allow traffic to additional endpoints to support FIPS endpoints.</p>
<p>To support the upcoming changes for FIPS encryption, update your network security group (or firewall) to allow outbound access from the compute plane to the control plane on port 2443 for FIPS connections. This is in addition to outgoing port 443 access that you are required to allow already. For related information about related security group and firewall configuration for customer-managed VPCs, see <a class="reference internal" href="../network/classic/customer-managed-vpc.html#security-groups"><span class="std std-ref">Security groups</span></a> and <a class="reference internal" href="../network/classic/customer-managed-vpc.html#firewall"><span class="std std-ref">(Optional) Configure a firewall and outbound access</span></a>. </p>
</li>
</ul>
</li>
<li><p>If any workspace is in the US East Region, the US West Region, or Canada (Central) Region, and it’s configured to restrict outbound network access, you need to allow traffic to additional endpoints to support FIPS endpoints. Remember that if you use those regions and do not restrict outgoing access now, if you restrict outgoing access in the future, you will need to revisit this step.</p>
<p>For the S3 service only, you must ensure that your classic compute plane network in your AWS account allows outgoing traffic to the AWS endpoints for the cloud services for S3 and also the FIPS variant of the S3 service with the prefix <code class="docutils literal notranslate"><span class="pre">s3-fips</span></code>. This applies to the S3 service but not to STS and Kinesis endpoints.</p>
<ul class="simple">
<li><p>For S3, allow outgoing traffic to the endpoint <code class="docutils literal notranslate"><span class="pre">s3.&lt;region&gt;.amazonaws.com</span></code> and <code class="docutils literal notranslate"><span class="pre">s3-fips.&lt;region&gt;.amazonaws.com</span></code>. For example <code class="docutils literal notranslate"><span class="pre">s3.us-east-1.amazonaws.com</span></code> and <code class="docutils literal notranslate"><span class="pre">s3-fips.us-east-1.amazonaws.com</span></code>.</p></li>
<li><p>For STS, allow outgoing traffic to the endpoint <code class="docutils literal notranslate"><span class="pre">sts.&lt;region&gt;.amazonaws.com</span></code>.</p></li>
<li><p>For Kinesis, allow outgoing traffic to the endpoint <code class="docutils literal notranslate"><span class="pre">kinesis.&lt;region&gt;.amazonaws.com</span></code>.</p></li>
</ul>
</li>
<li><p>For every workspace that uses the profile, run the following tests to verify that the changes were correctly applied:</p>
<ol class="loweralpha">
<li><p>Launch a Databricks cluster with 1 driver and 1 worker, any DBR version, and any instance type.</p></li>
<li><p>Create a notebook attached to the cluster. Use this cluster for the following tests.</p></li>
<li><p>In the notebook, validate DBFS connectivity by running:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%fs<span class="w"> </span>ls<span class="w"> </span>/
%sh<span class="w"> </span>ls<span class="w"> </span>/dbfs
</pre></div>
</div>
<p>Confirm that a file listing appears without errors.</p>
</li>
<li><p>In the notebook, confirm access to the control plane instance for your region. Get the address from the table <a class="reference internal" href="../network/classic/customer-managed-vpc.html#allow-required-addresses"><span class="std std-ref">this section</span></a> and look for the Webapp endpoint for your VPC region.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>&lt;webapp-domain-name&gt;<span class="w"> </span><span class="m">443</span>
</pre></div>
</div>
<p>For example, for VPC region <code class="docutils literal notranslate"><span class="pre">us-west-2</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>oregon.cloud.databricks.com<span class="w"> </span><span class="m">443</span>
</pre></div>
</div>
<p>Confirm the result says it succeeded.</p>
</li>
<li><p>In the notebook, confirm access to the SCC relay for your region. Get the address from the table <a class="reference internal" href="../network/classic/customer-managed-vpc.html#allow-required-addresses"><span class="std std-ref">this section</span></a> and look for the SCC relay endpoint for your VPC region.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>&lt;scc-relay-domain-name&gt;<span class="w"> </span><span class="m">2443</span>
</pre></div>
</div>
<p>For example, for VPC region <code class="docutils literal notranslate"><span class="pre">us-west-1</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>tunnel.cloud.databricks.com<span class="w"> </span><span class="m">2443</span>
</pre></div>
</div>
<p>Confirm that the results says it succeeded.</p>
</li>
<li><p>In the notebook, confirm access to the S3, STS, and Kinesis FIPS endpoints for your region.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>For this step, FIPS endpoints for Canada apply only to the S3 service. AWS does not yet provide FIPS endpoints for STS and Kinesis.</p>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>&lt;bucket-name&gt;.s3-fips.&lt;region&gt;.amazonaws.com<span class="w"> </span><span class="m">443</span>
%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>sts.&lt;region&gt;.amazonaws.com<span class="w"> </span><span class="m">443</span>
%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>kinesis.&lt;region&gt;.amazonaws.com<span class="w"> </span><span class="m">443</span>
</pre></div>
</div>
<p>For example, for VPC region <code class="docutils literal notranslate"><span class="pre">us-west-1</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>acme-company-bucket.s3-fips.us-west-1.amazonaws.com<span class="w"> </span><span class="m">443</span>
%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>sts.us-west-1.amazonaws.com<span class="w"> </span><span class="m">443</span>
%sh<span class="w"> </span>nc<span class="w"> </span>-zv<span class="w"> </span>kinesis.us-west-1.amazonaws.com<span class="w"> </span><span class="m">443</span>
</pre></div>
</div>
<p>Confirm the results for all three commands indicate success.</p>
</li>
<li><p>In the same notebook, validate that the cluster Spark config points to the desired endpoints. For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>&gt;&gt;&gt;<span class="w"> </span>spark.conf.get<span class="o">(</span><span class="s2">&quot;fs.s3a.stsAssumeRole.stsEndpoint&quot;</span><span class="o">)</span>
<span class="s2">&quot;sts.us-west-1.amazonaws.com&quot;</span>

&gt;&gt;&gt;<span class="w"> </span>spark.conf.get<span class="o">(</span><span class="s2">&quot;fs.s3a.endpoint&quot;</span><span class="o">)</span>
<span class="s2">&quot;s3-fips.us-west-2.amazonaws.com&quot;</span>
</pre></div>
</div>
</li>
</ol>
</li>
<li><p>Confirm that all existing clusters and jobs in all affected workspaces use only the instance types that are supported by the compliance security profile. Confirm or change all clusters and jobs so that the instance types are one of the following: <code class="docutils literal notranslate"><span class="pre">C5a</span></code>, <code class="docutils literal notranslate"><span class="pre">C5ad</span></code>, <code class="docutils literal notranslate"><span class="pre">C5n</span></code>, <code class="docutils literal notranslate"><span class="pre">C6i</span></code>, <code class="docutils literal notranslate"><span class="pre">C6id</span></code>, <code class="docutils literal notranslate"><span class="pre">C6in</span></code>, <code class="docutils literal notranslate"><span class="pre">D3</span></code>, <code class="docutils literal notranslate"><span class="pre">D3en</span></code>, <code class="docutils literal notranslate"><span class="pre">G4dn</span></code>, <code class="docutils literal notranslate"><span class="pre">G5</span></code>, <code class="docutils literal notranslate"><span class="pre">I3en</span></code>, <code class="docutils literal notranslate"><span class="pre">I4i</span></code>, <code class="docutils literal notranslate"><span class="pre">M5dn</span></code>, <code class="docutils literal notranslate"><span class="pre">M5n</span></code>, <code class="docutils literal notranslate"><span class="pre">M5zn</span></code>, <code class="docutils literal notranslate"><span class="pre">M6i</span></code>, <code class="docutils literal notranslate"><span class="pre">M6id</span></code>, <code class="docutils literal notranslate"><span class="pre">M6idn</span></code>, <code class="docutils literal notranslate"><span class="pre">M6in</span></code>, <code class="docutils literal notranslate"><span class="pre">P3dn</span></code>, <code class="docutils literal notranslate"><span class="pre">R-fleet</span></code>, <code class="docutils literal notranslate"><span class="pre">R5dn</span></code>, <code class="docutils literal notranslate"><span class="pre">R5n</span></code>, <code class="docutils literal notranslate"><span class="pre">R6i</span></code>, <code class="docutils literal notranslate"><span class="pre">R6id</span></code>, <code class="docutils literal notranslate"><span class="pre">R6idn</span></code>, <code class="docutils literal notranslate"><span class="pre">R6in</span></code>, and Databricks fleet instance types <code class="docutils literal notranslate"><span class="pre">M-fleet</span></code>, <code class="docutils literal notranslate"><span class="pre">MD-fleet</span></code>, and <code class="docutils literal notranslate"><span class="pre">RD-fleet</span></code>..</p>
<p>Any workload with an instance type outside of the list above would result in clusters/jobs failing to startup with an <code class="docutils literal notranslate"><span class="pre">invalid_parameter_exception</span></code>.</p>
</li>
</ol>
</div>
<div class="section" id="features-and-technical-controls">
<span id="features"></span><h2>Features and technical controls<a class="headerlink" href="#features-and-technical-controls" title="Permalink to this headline"> </a></h2>
<p>The main enhancements of the compliance security profile affect the Databricks compute resources in your workspace’s <a class="reference internal" href="../../getting-started/overview.html"><span class="doc">classic compute plane</span></a>. For serverless SQL warehouses, <a class="reference internal" href="#which-compute-resources"><span class="std std-ref">support varies by region</span></a>.</p>
<p>Enhancements include:</p>
<ul>
<li><p>An enhanced disk image (a <a class="reference external" href="https://www.cisecurity.org/cis-hardened-images/">CIS-hardened</a> <a class="reference external" href="https://ubuntu.com/advantage">Ubuntu Advantage</a> worker image).</p></li>
<li><p>Clusters automatically restart after 25 days and get the latest AMI with the latest security updates. If you enable the compliance security profile for your account or your workspace, long-running clusters are automatically restarted after 25 days. Databricks recommends that workspace admins restart clusters that might be running for 25 days when the security profile is enabled and to do so during a scheduled maintenance window. This reduces the risk of an auto-restart disrupting a scheduled job. You can use a script that Databricks provides that can determine how long your clusters have been running, and optionally restart them. See <a class="reference internal" href="../../compute/clusters-manage.html#cluster-start"><span class="std std-ref">Restart a cluster</span></a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, the behavior is different. Compute resources automatically restart only if updates are needed. You can choose a <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">regular monthly or twice-monthly schedule</span></a>, in which case the 25-day limit does not apply and the legacy workspace setting <strong>Automatic Restart of Long Running Clusters</strong> is ignored.</p>
</div>
</li>
<li><p>Security monitoring agents that generate logs that you can review. Two monitor agents run on compute resources (cluster workers) in your workspace’s <a class="reference internal" href="../../getting-started/overview.html"><span class="doc">classic compute plane</span></a>, for clusters and also for <a class="reference internal" href="../../compute/sql-warehouse.html#warehouse-types"><span class="std std-ref">pro or classic SQL warehouses</span></a>. The monitors are for antivirus and file integrity monitoring.</p>
<p>To review the new log rows, set up <a class="reference internal" href="../../administration-guide/account-settings/audit-log-delivery.html"><span class="doc">audit log delivery</span></a>. For additional information about audit logs, see <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html"><span class="doc">Audit log reference</span></a>.</p>
</li>
<li><p>Enforced use of <a class="reference external" href="https://aws.amazon.com/ec2/nitro/">AWS Nitro</a> instance types in cluster and Databricks SQL SQL warehouses. Instance types are limited to those that provide both hardware-implemented network encryption between cluster nodes and encryption at rest for local disks. This applies to <a class="reference internal" href="../../compute/index.html"><span class="doc">clusters for notebooks and jobs</span></a> as well as <a class="reference internal" href="../../compute/sql-warehouse.html#warehouse-types"><span class="std std-ref">pro or classic SQL warehouses for use with Databricks SQL</span></a>. The supported instance types are <code class="docutils literal notranslate"><span class="pre">C5a</span></code>, <code class="docutils literal notranslate"><span class="pre">C5ad</span></code>, <code class="docutils literal notranslate"><span class="pre">C5n</span></code>, <code class="docutils literal notranslate"><span class="pre">C6i</span></code>, <code class="docutils literal notranslate"><span class="pre">C6id</span></code>, <code class="docutils literal notranslate"><span class="pre">C6in</span></code>, <code class="docutils literal notranslate"><span class="pre">D3</span></code>, <code class="docutils literal notranslate"><span class="pre">D3en</span></code>, <code class="docutils literal notranslate"><span class="pre">G4dn</span></code>, <code class="docutils literal notranslate"><span class="pre">G5</span></code>, <code class="docutils literal notranslate"><span class="pre">I3en</span></code>, <code class="docutils literal notranslate"><span class="pre">I4i</span></code>, <code class="docutils literal notranslate"><span class="pre">M5dn</span></code>, <code class="docutils literal notranslate"><span class="pre">M5n</span></code>, <code class="docutils literal notranslate"><span class="pre">M5zn</span></code>, <code class="docutils literal notranslate"><span class="pre">M6i</span></code>, <code class="docutils literal notranslate"><span class="pre">M6id</span></code>, <code class="docutils literal notranslate"><span class="pre">M6idn</span></code>, <code class="docutils literal notranslate"><span class="pre">M6in</span></code>, <code class="docutils literal notranslate"><span class="pre">P3dn</span></code>, <code class="docutils literal notranslate"><span class="pre">R-fleet</span></code>, <code class="docutils literal notranslate"><span class="pre">R5dn</span></code>, <code class="docutils literal notranslate"><span class="pre">R5n</span></code>, <code class="docutils literal notranslate"><span class="pre">R6i</span></code>, <code class="docutils literal notranslate"><span class="pre">R6id</span></code>, <code class="docutils literal notranslate"><span class="pre">R6idn</span></code>, <code class="docutils literal notranslate"><span class="pre">R6in</span></code>, and Databricks fleet instance types <code class="docutils literal notranslate"><span class="pre">M-fleet</span></code>, <code class="docutils literal notranslate"><span class="pre">MD-fleet</span></code>, and <code class="docutils literal notranslate"><span class="pre">RD-fleet</span></code>.. </p></li>
<li><p>Communications for egress use TLS 1.2 or higher, including connecting to the metastore.</p></li>
<li><p>Clusters are limited to the versions that the compliance security profile supports. Databricks limits the Databricks Runtime versions in the UI, and does not allow API requests for unsupported Databricks Runtime versions. Supported versions are Databricks Runtime 7.3 LTS and above.</p></li>
<li><p>A shield logo appears in the top-right of the page, just to the left of the workspace name. See <a class="reference internal" href="#verify"><span class="std std-ref">Confirm that the compliance security profile is enabled for a workspace</span></a>.</p></li>
</ul>
<p>Databricks runs two monitoring agents in the <a class="reference internal" href="../../getting-started/overview.html"><span class="doc">compute plane</span></a>:</p>
<ul class="simple">
<li><p>Antivirus</p></li>
<li><p>File integrity monitoring</p></li>
</ul>
<p>See <a class="reference internal" href="#monitors"><span class="std std-ref">Monitoring agents in Databricks compute images</span></a>.</p>
<p></p>
<p></p>
</div>
<div class="section" id="disk-image-with-enhanced-hardening">
<h2>Disk image with enhanced hardening<a class="headerlink" href="#disk-image-with-enhanced-hardening" title="Permalink to this headline"> </a></h2>
<p>While the compliance security profile is enabled, Databricks compute resources (cluster worker images) in your classic compute plane use an enhanced hardened operating system image based on <a class="reference external" href="https://ubuntu.com/advantage">Ubuntu Advantage</a>.</p>
<p>Ubuntu Advantage is a package of enterprise security and support for open source infrastructure and applications that includes the following:</p>
<ul class="simple">
<li><p>A <a class="reference external" href="https://www.cisecurity.org/cis-hardened-images">CIS Level 1</a> hardened image.</p></li>
<li><p><a class="reference external" href="https://csrc.nist.gov/publications/detail/fips/140/2/final">FIPS 140-2 Level 1</a> validated encryption modules.</p></li>
</ul>
<p></p>
</div>
<div class="section" id="monitoring-agents-in-databricks-compute-images">
<span id="monitors"></span><h2>Monitoring agents in Databricks compute images<a class="headerlink" href="#monitoring-agents-in-databricks-compute-images" title="Permalink to this headline"> </a></h2>
<p>While the compliance security profile is enabled, there are additional security monitoring agents, including two agents that are pre-installed in the images that are used for Databricks compute resource VMs. You cannot disable the monitoring agents that are in the enhanced disk image.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 33%" />
<col style="width: 33%" />
<col style="width: 33%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Monitoring agent</p></th>
<th class="head"><p>Description</p></th>
<th class="head"><p>How to get output</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p>File integrity monitoring</p></td>
<td><p>Monitors for file integrity and security boundary violations. This monitor agent runs on the worker VM in your cluster.</p></td>
<td><p>Enable the audit log <a class="reference internal" href="../../administration-guide/system-tables/index.html"><span class="doc">system table</span></a> and review logs for <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html#capsule8"><span class="std std-ref">new rows</span></a>.</p></td>
</tr>
<tr class="row-odd"><td><p>Antivirus and malware detection</p></td>
<td><p>Scans the filesystem for viruses daily. This monitor agent runs on the VMs in your compute resources such as clusters and pro or classic SQL warehouses. The antivirus and malware detection agent scans the entire host OS filesystem and the Databricks Runtime container filesystem. Anything outside the cluster VMs is outside of its scanning scope.</p></td>
<td><p>Enable the audit log <a class="reference internal" href="../../administration-guide/system-tables/index.html"><span class="doc">system table</span></a> and review logs for <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html#clamav"><span class="std std-ref">new rows</span></a>.</p></td>
</tr>
<tr class="row-even"><td><p>Vulnerability scanning</p></td>
<td><p>Scans the container host (VM) for certain known vulnerabilities and CVEs. The scanning happens in representative images in the Databricks environments.</p></td>
<td><p>Request scan reports on the image from your Databricks account team.</p></td>
</tr>
</tbody>
</table>
<div class="section" id="file-integrity-monitoring">
<h3>File integrity monitoring<a class="headerlink" href="#file-integrity-monitoring" title="Permalink to this headline"> </a></h3>
<p>The compute plane image includes a file integrity monitoring service that provides runtime visibility and threat detection for compute resources (cluster workers) in the classic compute plane in your workspace.</p>
<p>The file integrity monitor output is generated within your audit logs, which you can access with <a class="reference internal" href="../../administration-guide/system-tables/index.html"><span class="doc">system tables (Public Preview)</span></a>. For the JSON schema for new auditable events that are specific to file integrity monitoring, see <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html#capsule8"><span class="std std-ref">File integrity monitoring events</span></a>.</p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is your responsibility to review antivirus monitor logs. Databricks may, in its sole discretion, review these logs but does not make a commitment to do so. If the agent detects a malicious activity, it is your responsibility to triage these events and open a support ticket with Databricks if the resolution or remediation requires an action by Databricks. Databricks may take action on the basis of these logs, including suspending or terminating the resources, but does not make any commitment to do so.</p>
</div>
</div>
<div class="section" id="antivirus-and-malware-detection">
<h3>Antivirus and malware detection<a class="headerlink" href="#antivirus-and-malware-detection" title="Permalink to this headline"> </a></h3>
<p>The enhanced compute plane image includes an antivirus engine for detecting trojans, viruses, malware, and other malicious threats. The antivirus monitor scans the entire host OS filesystem and the Databricks Runtime container filesystem. Anything outside the cluster VMs is outside of its scanning scope.</p>
<p>The antivirus monitor output is generated within audit logs, which you can access with <a class="reference internal" href="../../administration-guide/system-tables/index.html"><span class="doc">system tables (Public Preview)</span></a>. For the JSON schema for new auditable events that are specific to antivirus monitoring, see <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html#clamav"><span class="std std-ref">Antivirus monitoring events</span></a>.</p>
<p>When a new virtual machine image is built, updated signature files are included within it.</p>
<p></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>It is your responsibility to review antivirus monitor logs. Databricks may, in its sole discretion, review these logs but does not make a commitment to do so. If the agent detects a malicious activity, it is your responsibility to triage these events and open a support ticket with Databricks if the resolution or remediation requires an action by Databricks. Databricks may take action on the basis of these logs, including suspending or terminating the resources, but does not make any commitment to do so.</p>
</div>
<p>When a new AMI image is built, updated signature files are included within the new AMI image.</p>
</div>
<div class="section" id="vulnerability-scanning">
<h3>Vulnerability scanning<a class="headerlink" href="#vulnerability-scanning" title="Permalink to this headline"> </a></h3>
<p>A vulnerability monitor agent performs vulnerability scans of the container host (VM) for certain known CVEs.</p>
<p></p>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>The scanning happens in representative images in the Databricks environments.</p>
</div>
<p>You can request the vulnerability scan reports from your Databricks account team.</p>
<p>When vulnerabilities are found with this agent, Databricks tracks them against its Vulnerability Management SLA and releases an updated image when available. It is your responsibility to restart all compute resources regularly to keep the image up-to-date with the latest image version.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, clusters restart only if needed during the scheduled maintenance windows.</p>
</div>
</div>
</div>
<div class="section" id="management-and-upgrade-of-monitoring-agents">
<h2>Management and upgrade of monitoring agents<a class="headerlink" href="#management-and-upgrade-of-monitoring-agents" title="Permalink to this headline"> </a></h2>
<p>The additional monitoring agents that are on the disk images used for the compute resources in the classic compute plane are part of the standard Databricks process for upgrading systems:</p>
<ul>
<li><p>The classic compute plane base disk image (AMI) is owned, managed, and patched by Databricks.</p></li>
<li><p>Databricks delivers and applies security patches by releasing new AMI disk images. The delivery schedule depends on new functionality and the SLA for discovered vulnerabilities. Typical delivery is every two to four weeks.</p></li>
<li><p>The base operating system for the compute plane is Ubuntu Advantage.</p></li>
<li><p>Databricks clusters and pro or classic SQL warehouses are ephemeral by default. Upon launch, clusters and pro or classic SQL warehouses use the latest available base image. Older versions that may have security vulnerabilities are unavailable for new clusters.</p>
<ul class="simple">
<li><p>You are responsible for <a class="reference internal" href="../../compute/clusters-manage.html#cluster-start"><span class="std std-ref">restarting clusters</span></a> (using the UI or API) regularly to ensure they use the latest patched host VM images.</p></li>
<li><p>Databricks can, upon request, share a Databricks notebook to identify your workspace’s running clusters and hosts older than a specified number of days and optionally, restart a cluster. </p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, clusters restart only if needed during the scheduled maintenance windows.</p>
</div>
</li>
</ul>
<div class="section" id="monitor-agent-termination">
<h3>Monitor agent termination<a class="headerlink" href="#monitor-agent-termination" title="Permalink to this headline"> </a></h3>
<p>If a monitor agent on the worker VM is found to be not running due to crash or other termination, the system will attempt to restart the agent.</p>
<p></p>
</div>
<div class="section" id="data-retention-policy-for-monitor-agent-data">
<span id="-data-retention-policy-for-monitor-agent-data"></span><h3> Data retention policy for monitor agent data<a class="headerlink" href="#data-retention-policy-for-monitor-agent-data" title="Permalink to this headline"> </a></h3>
<p>Monitoring logs are sent to the audit log system table or your own Amazon S3 bucket if you configured <a class="reference internal" href="../../administration-guide/account-settings/audit-logs.html"><span class="doc">audit log delivery</span></a>. Retention, ingestion, and analysis of these logs is your responsibility.</p>
<p>Vulnerability scanning reports and logs are retained for at least one year by Databricks. You can request the vulnerability reports from your Databricks account team.</p>
</div>
</div>
<div class="section" id="confirm-that-the-compliance-security-profile-is-enabled-for-a-workspace">
<span id="verify"></span><h2>Confirm that the compliance security profile is enabled for a workspace<a class="headerlink" href="#confirm-that-the-compliance-security-profile-is-enabled-for-a-workspace" title="Permalink to this headline"> </a></h2>
<p>To confirm that a workspace is using the compliance security profile, check that it has the <strong>yellow shield logo</strong> displayed in the user interface.</p>
<ul>
<li><p>A shield logo appears in the top-right of the page, to the left of the workspace name:</p>
<div class="figure align-default">
<img alt="Shield logo small." src="../../_images/shield-profile-logo-small.png" />
</div>
</li>
<li><p>If you click the workspace name, a menu shows a list of the workspaces that you have access to. The workspaces that enable the compliance security profile have a shield icon followed by the text “Compliance security profile”.</p>
<div class="figure align-default">
<img alt="Shield logo large." src="../../_images/shield-profile-logo-large.png" />
</div>
</li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>If the shield icons are missing for a workspace with the compliance security profile enabled, contact your Databricks account team.</p>
</div>
</div>
<div class="section" id="check-whether-any-existing-clusters-need-to-be-restarted-after-enablement">
<span id="cluster-start-date-script"></span><h2>Check whether any existing clusters need to be restarted after enablement<a class="headerlink" href="#check-whether-any-existing-clusters-need-to-be-restarted-after-enablement" title="Permalink to this headline"> </a></h2>
<p>After a workspace is enabled with the compliance security profile, you need to restart any clusters that were created before the time of enablement to ensure it is using the compliance security profile enhancements and controls.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>If your workspace is part of the <a class="reference internal" href="../../administration-guide/clusters/scheduled-cluster-updates.html"><span class="doc">public preview of automatic cluster update</span></a>, you might not need this script. Clusters restart automatically if needed during the scheduled maintenance windows.</p>
</div>
<p>If you have many clusters running and only want to restart the ones that were started before enablement, you can use this script to determine if the start time was before the enablement date. Given a workspace URL, a <a class="reference external" href="https://docs.databricks.com/api/workspace/tokenmanagement">personal access token for access REST APIs</a> on this workspace, and an enablement date/time, this script returns a list of clusters that were started and/or restarted before the enablement timestamp. The script prints the cluster ID and the cluster name.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">json</span>

<span class="c1"># This notebook requires a user-level Personal Access Token. This should be stored</span>
<span class="c1"># in the Databricks Secrets API (or similar) and shouldn&#39;t be hardcoded in a notebook.</span>
<span class="c1"># Add a secret using the Databricks CLI or API. CLI example:</span>
<span class="c1"># $ databricks secrets create-scope YOUR_SCOPE_NAME</span>
<span class="c1"># $ databricks secrets put-secret splunk_env YOUR_KEY_NAME</span>
<span class="c1"># Configure your scope and key name below.</span>

<span class="c1">#====== UPDATE THE FOLLOWING BELOW</span>

<span class="n">WORKSPACE_URL</span><span class="o">=</span><span class="s2">&quot;&lt;WORKSPACE-URL-HERE&gt;&quot;</span>
<span class="n">TOKEN</span><span class="o">=</span><span class="n">dbutils</span><span class="o">.</span><span class="n">secrets</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">scope</span><span class="o">=</span><span class="s2">&quot;YOUR_SCOPE_NAME&quot;</span><span class="p">,</span> <span class="n">key</span><span class="o">=</span><span class="s2">&quot;YOUR_KEY_NAME&quot;</span><span class="p">)</span>
<span class="c1"># One of the below should be configured:</span>
<span class="n">WORKSPACE_ENABLEMENT_TIME_UTC_MILLIS</span><span class="o">=&lt;</span><span class="n">TIME</span><span class="o">-</span><span class="n">IN</span><span class="o">-</span><span class="n">UTC</span><span class="o">&gt;</span> <span class="c1"># note millis, e.g. 1651366230000</span>
<span class="n">WORKSPACE_ENABLEMENT_TIME_FORMATTED</span><span class="o">=</span><span class="kc">None</span> <span class="c1"># Format YYYY-MM-DD HH:MM:SS -0000</span>
                                         <span class="c1"># Example &quot;2022-06-01 15:01:01 -0700&quot;</span>
<span class="c1">#====== UPDATE THE ABOVE</span>

<span class="k">if</span> <span class="n">WORKSPACE_ENABLEMENT_TIME_FORMATTED</span> <span class="o">!=</span> <span class="kc">None</span><span class="p">:</span>
  <span class="n">WORKSPACE_ENABLEMENT_TIME_UTC_MILLIS</span><span class="o">=</span><span class="n">datetime</span><span class="o">.</span><span class="n">strptime</span><span class="p">(</span>
              <span class="n">WORKSPACE_ENABLEMENT_TIME_FORMATTED</span><span class="p">,</span>
              <span class="s2">&quot;%Y-%m-</span><span class="si">%d</span><span class="s2"> %H:%M:%S %z&quot;</span><span class="p">)</span><span class="o">.</span><span class="n">timestamp</span><span class="p">()</span><span class="o">*</span><span class="mi">1000</span>
<span class="n">headers</span> <span class="o">=</span> <span class="p">{</span>
  <span class="s1">&#39;Authorization&#39;</span><span class="p">:</span> <span class="s1">&#39;Bearer &#39;</span> <span class="o">+</span> <span class="n">TOKEN</span>
<span class="p">}</span>
<span class="n">url</span> <span class="o">=</span> <span class="n">WORKSPACE_URL</span> <span class="o">+</span> <span class="s2">&quot;/api/2.0/clusters/list&quot;</span>

<span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">request</span><span class="p">(</span><span class="s2">&quot;GET&quot;</span><span class="p">,</span> <span class="n">url</span><span class="p">,</span> <span class="n">headers</span><span class="o">=</span><span class="n">headers</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="p">{})</span>

<span class="n">clusters</span> <span class="o">=</span> <span class="n">json</span><span class="o">.</span><span class="n">loads</span><span class="p">(</span><span class="n">response</span><span class="o">.</span><span class="n">text</span><span class="p">)[</span><span class="s2">&quot;clusters&quot;</span><span class="p">]</span>
<span class="n">need_restart</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">c</span> <span class="ow">in</span> <span class="n">clusters</span><span class="p">:</span>
  <span class="n">start_time</span> <span class="o">=</span> <span class="n">c</span><span class="p">[</span><span class="s2">&quot;start_time&quot;</span><span class="p">]</span>
  <span class="n">last_start</span> <span class="o">=</span> <span class="n">start_time</span>
  <span class="k">if</span> <span class="s2">&quot;last_restarted_time&quot;</span> <span class="ow">in</span> <span class="n">c</span><span class="p">:</span>
    <span class="n">last_start</span> <span class="o">=</span> <span class="nb">max</span><span class="p">(</span><span class="n">start_time</span><span class="p">,</span> <span class="n">c</span><span class="p">[</span><span class="s2">&quot;last_restarted_time&quot;</span><span class="p">])</span>
  <span class="k">if</span> <span class="n">last_start</span> <span class="o">&lt;=</span> <span class="n">WORKSPACE_ENABLEMENT_TIME_UTC_MILLIS</span><span class="p">:</span>
    <span class="n">need_restart</span><span class="o">.</span><span class="n">append</span><span class="p">((</span><span class="n">c</span><span class="p">[</span><span class="s2">&quot;cluster_id&quot;</span><span class="p">],</span> <span class="n">c</span><span class="p">[</span><span class="s2">&quot;cluster_name&quot;</span><span class="p">]))</span>

<span class="k">if</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">need_restart</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">):</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;All clusters have been restarted since </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">WORKSPACE_ENABLEMENT_TIME_UTC_MILLIS</span><span class="p">))</span>
<span class="k">else</span><span class="p">:</span>
  <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;The following clusters still need to be restarted to remain in compliance&quot;</span><span class="p">)</span>
  <span class="k">for</span> <span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span> <span class="ow">in</span> <span class="n">need_restart</span><span class="p">:</span>
    <span class="nb">print</span><span class="p">(</span><span class="s2">&quot;Cluster </span><span class="si">{}</span><span class="s2">, </span><span class="si">{}</span><span class="s2">&quot;</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="nb">id</span><span class="p">,</span> <span class="n">name</span><span class="p">))</span>
</pre></div>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../../_static/jquery.js"></script>
  <script type="text/javascript" src="../../_static/underscore.js"></script>
  <script type="text/javascript" src="../../_static/doctools.js"></script>
  <script type="text/javascript" src="../../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../../_static/js/localized.js"></script>
  <script type="text/javascript" src="../../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>