

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Quick start: Evaluation sets">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Quick start: Evaluation sets &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/rag-temp/getting-started-3.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/rag-temp/getting-started-3.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/rag-temp/getting-started-3.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" />
  <link rel="up" title="Introduction to RAG Studio" href="index.html" />
  <link rel="next" title="Quick start: Creating a new version" href="getting-started-4.html" />
  <link rel="prev" title="Quick start: Collecting assessments &amp; viewing metrics" href="getting-started-2.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/rag-temp/getting-started-3.html" class="notranslate">English</option>
    <option value="../../ja/rag-temp/getting-started-3.html" class="notranslate">日本語</option>
    <option value="../../pt/rag-temp/getting-started-3.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul class="current">
<li class="toctree-l1 current"><a class="reference internal" href="index.html">RAG Studio</a><ul class="current">
<li class="toctree-l2"><a class="reference internal" href="getting-started-1.html">Quick start (1): Deploy a RAG app</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started-2.html">Quick start (2): Collecting assessments &amp; viewing metrics</a></li>
<li class="toctree-l2 current"><a class="current reference internal" href="#">Quick start (3): Creating Evaluation Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started-4.html">Quick start (4): Creating Evaluation Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started-5.html">Quick start (5): Creating Evaluation Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="rag_configyml.html">Concepts: Configuration (rag_config.yml)</a></li>
<li class="toctree-l2"><a class="reference internal" href="environments.html">Concepts: Environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started-walkthrough.html">Tutorial: Creating your first app</a></li>
<li class="toctree-l2"><a class="reference internal" href="getting-started-evaluation.html">Tutorial: Offline Evaluation &amp; Evaluation Sets</a></li>
<li class="toctree-l2"><a class="reference internal" href="metrics.html">Concepts: Metrics</a></li>
<li class="toctree-l2"><a class="reference internal" href="core_concepts.html">Concepts: RAG Abstractions/Entities</a></li>
<li class="toctree-l2"><a class="reference internal" href="protos.html">  Protos (internal only)</a></li>
<li class="toctree-l2"><a class="reference internal" href="env-setup-infra.html">Setup: Infrastructure</a></li>
<li class="toctree-l2"><a class="reference internal" href="env-setup-dev.html">Setup: Dev environment</a></li>
<li class="toctree-l2"><a class="reference internal" href="regions.html">Region availability</a></li>
</ul>
</li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="January 11, 2024">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
        <li><a href="index.html">Introduction to RAG Studio</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Quick start: Evaluation sets</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="quick-start-evaluation-sets">
<h1>Quick start: Evaluation sets<a class="headerlink" href="#quick-start-evaluation-sets" title="Permalink to this headline"> </a></h1>
<p>In the previous guide, we showed you how to collect assessments and measure metrics using those assessments.  While a logical next step is to jump into creating a new version of the application to fix any issues you identified, Databricks suggests first creating an Evaluation Set, which is a represensative set of questions you expect your users to ask of your application, optionally with ground-truth answers to those questions.</p>
<p>This Evaluation Set will allow you to quickly and quantatively check the quality of a new version of your application before distributing it to stakeholders for their feedback.</p>
<p>See the <a class="reference external" href="#">Evaluation Set</a> conceptual guide for more details.</p>
<p>This guide will walk you through the process of creating an Evaluation Set.</p>
<div class="section" id="step-1-create-an-evaluation-set-with-only-questions">
<h2>Step 1: Create an Evaluation Set with only Questions<a class="headerlink" href="#step-1-create-an-evaluation-set-with-only-questions" title="Permalink to this headline"> </a></h2>
<ol class="arabic">
<li><p>With your business stakeholders, brainstorm a list of commonly asked qeustions.  For this quick start guide, we had a discussion with our team, and generated the below list of questions:</p>
<ul class="simple">
<li><p>How does Spark work?</p></li>
<li><p>What is MLflow?</p></li>
<li><p>What is the difference between pySpark and DB SQL?</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Databricks suggests working with your business stakeholders to generate a set of commonly asked questions.  If this is not possible for your use case, you can <a class="reference external" href="https://mlflow.org/docs/latest/llms/rag/notebooks/question-generation-retrieval-evaluation.html">generate questions based on your chunked documents by prompting a Large Language Model</a>.  When using this approach, Databricks suggest reviewing each generated question for accuracy.</p>
</div>
<p><p><strong>📋 TODO 📋</strong></p>
 Decide if we want to include the above method or not.  If so, we probably need to make it work with our schemas.</p>
</li>
<li><p>Format your list of questions as an array of <a class="reference internal" href="../machine-learning/foundation-models/api-reference.html#chatmessage"><span class="std std-ref">ChatMessages</span></a> and save as a Delta Table.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">questions</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;question 1&#39;</span><span class="p">,</span> <span class="s1">&#39;question 2&#39;</span><span class="p">]</span>
<span class="n">eval_set_delta_table</span> <span class="o">=</span> <span class="s2">&quot;catalog.schema.eval_set_1&quot;</span>
<span class="c1"># TODO: insert sample code for turning `questions` into a compatible Spark DF &amp; saving as a Delta Table</span>
</pre></div>
</div>
<p><p><strong>📋 TODO 📋</strong></p>
 Add this code</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>Why?  To ensure consistency between offline evaluations (such as the evaluation completed in this tutorial) and evaluations with your online traffic (such as <a class="reference external" href="#">Asessments</a> from reviewers or end users), RAG Studio requires that you format your <a class="reference external" href="#">Evaluation Set</a> using the same schema accepted by your application’s Chain.  RAG Studio requires that your Chain accept input as <a class="reference internal" href="../machine-learning/foundation-models/api-reference.html#chatmessage"><span class="std std-ref">OpenAI-formatted ChatMessages</span></a>, and thus, your Evaluation Set must follow the same schema: <a class="reference external" href="#">TOOD add link with more details</a>.</p>
</div>
</li>
</ol>
</div>
<div class="section" id="step-2-use-the-evaluation-set-to-compute-metrics">
<h2>Step 2: Use the evaluation set to compute metrics<a class="headerlink" href="#step-2-use-the-evaluation-set-to-compute-metrics" title="Permalink to this headline"> </a></h2>
<ol class="arabic">
<li><p>Open the RAG application’s local code folder in your console</p>
<ul class="simple">
<li><p>This will be <code class="docutils literal notranslate"><span class="pre">~/rag_studio/rag-sample-app</span></code> if you used the defaults in the <a class="reference internal" href="getting-started-1.html"><span class="doc">first getting started guide</span></a>.</p></li>
</ul>
</li>
<li><p>Run the evaluation set through the application by running the following command in your console.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rag<span class="w"> </span>run-eval<span class="w"> </span>--input<span class="w"> </span>catalog.schema.eval_set_1<span class="w"> </span>--version<span class="w"> </span><span class="m">1</span><span class="w"> </span>--env<span class="w"> </span>dev
</pre></div>
</div>
<p><p><strong>📋 TODO 📋</strong></p>
 Is the above command correct?</p>
<p><strong>What happens behind the scenes?</strong></p>
<p>In the background, the Chain version <code class="docutils literal notranslate"><span class="pre">1</span></code> is run through each row of the <code class="docutils literal notranslate"><span class="pre">catalog.schema.eval_set_1</span></code> using an identical compute environment to how your Chain is served. For each row of <code class="docutils literal notranslate"><span class="pre">catalog.schema.eval_set_1</span></code>, a <a class="reference external" href="#">Trace</a> is written to the <code class="docutils literal notranslate"><span class="pre">request_log_table</span></code> based on that row’s inputs.</p>
<p><p><strong>📋 TODO 📋</strong></p>
 Add link to the full details, more things happen like metrics running, etc - but this is the bare bones things they need to  know.</p>
</li>
<li><p>Similar to the <code class="docutils literal notranslate"><span class="pre">open-eval</span></code> command you <a class="reference internal" href="getting-started-2.html#step-3-view-metrics"><span class="std std-ref">ran in the previous guide</span></a>, this command will open a Notebook to view data and the Metrics.</p></li>
<li><p>For now, we will skip over viewing the metrics, but will come back to this later.</p></li>
</ol>
</div>
<div class="section" id="step-3-optionally---collect-ground-truth-data-for-each-question">
<h2>Step 3: Optionally - collect ground truth data for each question<a class="headerlink" href="#step-3-optionally---collect-ground-truth-data-for-each-question" title="Permalink to this headline"> </a></h2>
<p><p><strong>📋 TODO 📋</strong></p>
 DO we want to talk about ALL data they could add here (retrieved contexts, faithfullness, etc) or just answers?  personally, i think it might be too much to do more than answers in the quick start, but we should link to details about the others.  especially since the only way a user can measure Retrieval metrics in v1 is through a ground-truth set…. :(</p>
<p>Databricks suggests adding ground-truth answers and retrieved contexts to the questions you just created - this will allow you to more accuratly measure the quality of your application.  However, <em>this step is optional</em> and you can still use RAG Studio’s functionality without doing so - the only missing functionality is the computation of a <a class="reference internal" href="metrics.html"><span class="doc">answer correctness metric</span></a> + <a class="reference external" href="#">retrieval metrics</a>.</p>
<p>To add answers to our Evaluation Set, we will use the RAG application’s generated answers as a starting point and ask our expert users to accept or edit these responses.</p>
<p><p><strong>🚧 Roadmap 🚧</strong></p>
 Collect ground truth on the retrieved chunks using the UI.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><p><strong>🚧 Roadmap 🚧</strong></p>
 RAG Studio’s <a class="reference external" href="#">Explorations UI</a> and SDK enable you to quickly load existing <a class="reference external" href="#">Traces</a> for review by expert users.  Until this functionality is available, follow the below steps to manually load <a class="reference external" href="#">Traces</a>.</p>
</div>
<ol class="arabic">
<li><p>Export the <code class="docutils literal notranslate"><span class="pre">request_log_table</span></code> as <code class="docutils literal notranslate"><span class="pre">traces.jsonl</span></code></p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># TODO: Sample code for doing this</span>
</pre></div>
</div>
</li>
<li><p>Create <code class="docutils literal notranslate"><span class="pre">instructions.md</span></code> with the following contents:</p>
<div class="highlight-markdown notranslate"><div class="highlight"><pre><span></span><span class="gh"># insert the instructions here!!!</span>
</pre></div>
</div>
<div class="admonition warning">
<p class="admonition-title">Warning</p>
<p>To ensure high quality and consistant data from your expert users, Databricks strongly suggests writing simple, clear instructions explaining how you expect experts to rate answers.</p>
</div>
</li>
<li><p>Copy <code class="docutils literal notranslate"><span class="pre">instructions.md</span></code> and <code class="docutils literal notranslate"><span class="pre">traces.jsonl</span></code> to your local development environment.</p></li>
<li><p>Open the RAG application’s local code folder in your console</p>
<ul class="simple">
<li><p>This will be <code class="docutils literal notranslate"><span class="pre">~/rag_studio/rag-sample-app</span></code> if you used the defaults in the <a class="reference internal" href="getting-started-1.html"><span class="doc">first getting started guide</span></a>.</p></li>
</ul>
</li>
<li><p>Load the questions/answers to the Review App by running the following command in your console.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rag<span class="w"> </span>start-review<span class="w"> </span>--traces<span class="w"> </span>traces.jsonl<span class="w"> </span>--instructions<span class="w"> </span>instructions.md<span class="w"> </span>--version<span class="w"> </span><span class="m">1</span><span class="w"> </span>--env<span class="w"> </span>dev
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>INSERT<span class="w"> </span>OUTPUT<span class="w"> </span>WITH<span class="w"> </span>THE<span class="w"> </span>REVIEW<span class="w"> </span>URL
http://review.app/sdfdsf
</pre></div>
</div>
<p><p><strong>📋 TODO 📋</strong></p>
 Update this command &amp; output to be accurate.</p>
</li>
<li><p>Go to the Review App URL.  On the left side, you will see the converastions loaded in <code class="docutils literal notranslate"><span class="pre">Chats</span> <span class="pre">to</span> <span class="pre">review</span></code>. Go through each conversation and either press thumbs up to indicate it is correct OR edit the response to be accurate.</p>
<p><p><strong>📋 TODO 📋</strong></p>
 Put in screenshots</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This step would normally be done in partnership with your business stakeholders.  For instructions on how to enable these stakeholders to access the review app, see ADD LINK.</p>
</div>
</li>
<li><p>Use the collected data to update your Evaluation Set with answers.</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># Provide input as ChatMessages format - same as without ground truth</span>
<span class="n">input_messages</span> <span class="o">=</span> <span class="p">[</span>
    <span class="p">{</span>
    <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;user&quot;</span><span class="p">,</span>
    <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;This is a question to ask?&quot;</span>
    <span class="p">}</span>
<span class="p">]</span>

<span class="c1"># Similar to input, RAG Studio requires your outputs to be in the same schema as produced by your Chain.  Since the Chain is required to produce [ChatMessages], you must provide the role=assistant message.</span>
<span class="c1"># Return in https://docs.databricks.com/en/machine-learning/foundation-models/api-reference.html#chat-response format</span>
<span class="n">outputs</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s2">&quot;choices&quot;</span><span class="p">:</span> <span class="p">[</span>
        <span class="p">{</span>
            <span class="s2">&quot;index&quot;</span><span class="p">:</span> <span class="mi">0</span><span class="p">,</span>
            <span class="s2">&quot;message&quot;</span><span class="p">:</span> <span class="p">{</span>
                <span class="s2">&quot;role&quot;</span><span class="p">:</span> <span class="s2">&quot;assistant&quot;</span><span class="p">,</span>
                <span class="s2">&quot;content&quot;</span><span class="p">:</span> <span class="s2">&quot;this is the correct answer&quot;</span><span class="p">,</span>
            <span class="p">},</span>
            <span class="s2">&quot;finish_reason&quot;</span><span class="p">:</span> <span class="s2">&quot;stop&quot;</span><span class="p">,</span>
        <span class="p">}</span>
    <span class="p">],</span>
    <span class="s2">&quot;object&quot;</span><span class="p">:</span> <span class="s2">&quot;chat.completions&quot;</span><span class="p">,</span>
<span class="p">}</span>

<span class="n">retrieved_chunks</span> <span class="o">=</span> <span class="p">[]</span> <span class="c1"># TODO: Add this schema based on our Assessment schema</span>

<span class="c1"># TODO: insert sample code to ETL from Assessments &amp; Traces that exist to an evluation set</span>
</pre></div>
</div>
<p><p><strong>📋 TODO 📋</strong></p>
 Add this sample code.</p>
</li>
<li><p>To help you get started quickly, we have completed the above step for you with an example set of questions and answers.</p>
<p><p><strong>📋 TODO 📋</strong></p>
 Add sample data from QuinnBot golden set formatted in the right format.</p>
</li>
</ol>
</div>
<div class="section" id="step-4-re-run-the-evalution-with-the-complete-ground-truth">
<h2>Step 4: Re-run the evalution with the complete ground truth<a class="headerlink" href="#step-4-re-run-the-evalution-with-the-complete-ground-truth" title="Permalink to this headline"> </a></h2>
<ol class="arabic">
<li><p>Optionally, you can re-run the same command as above, but with your completed evaluation set to see the additional metrics that are computed with the ground-truth data.</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>rag<span class="w"> </span>run-eval<span class="w"> </span>--input<span class="w"> </span>catalog.schema.eval_set_1_complete<span class="w"> </span>--version<span class="w"> </span><span class="m">1</span><span class="w"> </span>--env<span class="w"> </span>dev
</pre></div>
</div>
</li>
</ol>
<div class="section" id="next-steps">
<h3>Next steps<a class="headerlink" href="#next-steps" title="Permalink to this headline"> </a></h3>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>