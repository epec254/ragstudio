

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to use R, SparkR, sparklyr, and dplyr to work with R data.frames, Spark DataFrames, and tables in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Work with DataFrames and tables in R">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Work with DataFrames and tables in R &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/sparkr/dataframes-tables.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/sparkr/dataframes-tables.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/sparkr/dataframes-tables.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/sparkr/dataframes-tables.html" class="notranslate">English</option>
    <option value="../../ja/sparkr/dataframes-tables.html" class="notranslate">日本語</option>
    <option value="../../pt/sparkr/dataframes-tables.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Work with DataFrames and tables in R</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="work-with-dataframes-and-tables-in-r">
<h1>Work with DataFrames and tables in R<a class="headerlink" href="#work-with-dataframes-and-tables-in-r" title="Permalink to this headline"> </a></h1>
<p>This article describes how to use R packages such as <a class="reference internal" href="overview.html"><span class="doc">SparkR</span></a>, <a class="reference internal" href="sparklyr.html"><span class="doc">sparklyr</span></a>, and <a class="reference external" href="https://dplyr.tidyverse.org/">dplyr</a> to work with R <code class="docutils literal notranslate"><span class="pre">data.frame</span></code>s, <a class="reference external" href="https://spark.apache.org/docs/latest/sparkr.html#sparkdataframe">Spark DataFrames</a>, and in-memory tables.</p>
<p>Note that as you work with SparkR, sparklyr, and dplyr, you may find that you can complete a particular operation with all of these packages, and you can use the package that you are most comfortable with. For example, to run a query, you can call functions such as <code class="docutils literal notranslate"><span class="pre">SparkR::sql</span></code>, <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_sql</span></code>, and <code class="docutils literal notranslate"><span class="pre">dplyr::select</span></code>. At other times, you might be able to complete an operation with just one or two of these packages, and the operation you choose depends on your usage scenario. For example, the way you call <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_quantile</span></code> differs slightly from the way you call <code class="docutils literal notranslate"><span class="pre">dplyr::percentile_approx</span></code>, even though both functions calcuate quantiles.</p>
<p>You can use SQL as a bridge between SparkR and sparklyr. For example, you can use <code class="docutils literal notranslate"><span class="pre">SparkR::sql</span></code> to query tables that you create with sparklyr. You can use <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_sql</span></code> to query tables that you create with SparkR. And <code class="docutils literal notranslate"><span class="pre">dplyr</span></code> code always gets translated to SQL in memory before it is run. See also <a class="reference internal" href="sparkr-vs-sparklyr.html#api-interoperability"><span class="std std-ref">API interoperability</span></a> and <a class="reference external" href="https://spark.rstudio.com/guides/dplyr.html#sql-translation">SQL Translation</a>.</p>
<div class="section" id="load-sparkr-sparklyr-and-dplyr">
<h2>Load SparkR, sparklyr, and dplyr<a class="headerlink" href="#load-sparkr-sparklyr-and-dplyr" title="Permalink to this headline"> </a></h2>
<p>The SparkR, sparklyr, and dplyr packages are included in the Databricks Runtime that is installed on Databricks <a class="reference internal" href="../compute/configure.html"><span class="doc">clusters</span></a>. Therefore, you do not need to call the usual <code class="docutils literal notranslate"><span class="pre">install.package</span></code> before you can begin call these packages. However, you must still load these packages with <code class="docutils literal notranslate"><span class="pre">library</span></code> first. For example, from within an R <a class="reference internal" href="../notebooks/notebooks-manage.html#create-a-notebook"><span class="std std-ref">notebook</span></a> in a Databricks workspace, run the following code in a notebook cell to load SparkR, sparklyr, and dplyr:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">sparklyr</span><span class="p">)</span>
<span class="nf">library</span><span class="p">(</span><span class="n">dplyr</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="connect-sparklyr-to-a-cluster">
<h2>Connect sparklyr to a cluster<a class="headerlink" href="#connect-sparklyr-to-a-cluster" title="Permalink to this headline"> </a></h2>
<p>After you load sparklyr, you must call <code class="docutils literal notranslate"><span class="pre">sparklyr::spark_connect</span></code> to connect to the cluster, specifying the <code class="docutils literal notranslate"><span class="pre">databricks</span></code> connection method. For example, run the following code in a notebook cell to connect to the cluster that hosts the notebook:</p>
<div class="highlight-default notranslate"><div class="highlight"><pre><span></span><span class="n">sc</span> <span class="o">&lt;-</span> <span class="n">spark_connect</span><span class="p">(</span><span class="n">method</span> <span class="o">=</span> <span class="s2">&quot;databricks&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>In contrast, a Databricks notebook already establishes a <code class="docutils literal notranslate"><span class="pre">SparkSession</span></code> on the cluster for use with SparkR, so you do not need to call <code class="docutils literal notranslate"><span class="pre">SparkR::sparkR.session</span></code> before you can begin calling SparkR.</p>
</div>
<div class="section" id="upload-a-json-data-file-to-your-workspace">
<h2>Upload a JSON data file to your workspace<a class="headerlink" href="#upload-a-json-data-file-to-your-workspace" title="Permalink to this headline"> </a></h2>
<p>Many of the code examples in this article are based on data in a specific location in your Databricks workspace, with specific column names and data types. The data for this code example originates in a JSON file named <code class="docutils literal notranslate"><span class="pre">book.json</span></code> from within GitHub. To get this file and upload it to your workspace:</p>
<ol class="arabic simple">
<li><p>Go to the <a class="reference external" href="https://github.com/benoitvallon/100-best-books/blob/master/books.json">books.json</a> file on GitHub and use a text editor to copy its contents to a file named <code class="docutils literal notranslate"><span class="pre">books.json</span></code> somewhere on your local machine.</p></li>
<li><p>In your Databricks workspace sidebar, click <strong>Catalog</strong>.</p></li>
<li><p>Click <strong>Create Table</strong>.</p></li>
<li><p>On the <strong>Upload File</strong> tab, drop the <code class="docutils literal notranslate"><span class="pre">books.json</span></code> file from your local machine to the <strong>Drop files to upload</strong> box. Or select <strong>click to browse</strong>, and browse to the <code class="docutils literal notranslate"><span class="pre">books.json</span></code> file from your local machine.</p></li>
</ol>
<p>By default, Databricks uploads your local <code class="docutils literal notranslate"><span class="pre">books.json</span></code> file to the <a class="reference external" href="#">DBFS</a> location in your workspace with the path <code class="docutils literal notranslate"><span class="pre">/FileStore/tables/books.json</span></code>.</p>
<p>Do not click <strong>Create Table with UI</strong> or <strong>Create Table in Notebook</strong>. The code examples in this article use the data in the uploaded <code class="docutils literal notranslate"><span class="pre">books.json</span></code> file in this DBFS location.</p>
</div>
<div class="section" id="read-the-json-data-into-a-dataframe">
<h2>Read the JSON data into a DataFrame<a class="headerlink" href="#read-the-json-data-into-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>Use <code class="docutils literal notranslate"><span class="pre">sparklyr::spark_read_json</span></code> to read the uploaded JSON file into a DataFrame, specifying the connection, the path to the JSON file, and a name for the internal table representation of the data. For this example, you must specify that the <code class="docutils literal notranslate"><span class="pre">book.json</span></code> file contains multiple lines. Specifying the columns’ schema here is optional. Otherwise, sparklyr infers the columns’ schema by default. For example, run the following code in a notebook cell to read the uploaded JSON file’s data into a DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonDF</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">jsonDF</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_read_json</span><span class="p">(</span>
<span class="w">  </span><span class="n">sc</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="n">sc</span><span class="p">,</span>
<span class="w">  </span><span class="n">name</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;jsonTable&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">path</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/FileStore/tables/books.json&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">options</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">list</span><span class="p">(</span><span class="s">&quot;multiLine&quot;</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span><span class="p">),</span>
<span class="w">  </span><span class="n">columns</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span>
<span class="w">    </span><span class="n">author</span><span class="w">    </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">country</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">imageLink</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">language</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">link</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">pages</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;integer&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">title</span><span class="w">     </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;character&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">year</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;integer&quot;</span>
<span class="w">  </span><span class="p">)</span>
<span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="print-the-first-few-rows-of-a-dataframe">
<h2>Print the first few rows of a DataFrame<a class="headerlink" href="#print-the-first-few-rows-of-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can use <code class="docutils literal notranslate"><span class="pre">SparkR::head</span></code>, <code class="docutils literal notranslate"><span class="pre">SparkR::show</span></code>, or <code class="docutils literal notranslate"><span class="pre">sparklyr::collect</span></code> to print the first rows of a DataFrame. By default, <code class="docutils literal notranslate"><span class="pre">head</span></code> prints the first six rows by default. <code class="docutils literal notranslate"><span class="pre">show</span></code> and <code class="docutils literal notranslate"><span class="pre">collect</span></code> print the first 10 rows. For example, run the following code in a notebook cell to print the first rows of the DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonDF</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">head</span><span class="p">(</span><span class="n">jsonDF</span><span class="p">)</span>

<span class="c1"># Source: spark&lt;?&gt; [?? x 8]</span>
<span class="c1">#   author                  country        image…¹ langu…² link  pages title  year</span>
<span class="c1">#   &lt;chr&gt;                   &lt;chr&gt;          &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;</span>
<span class="c1"># 1 Chinua Achebe           Nigeria        images… English &quot;htt…   209 Thin…  1958</span>
<span class="c1"># 2 Hans Christian Andersen Denmark        images… Danish  &quot;htt…   784 Fair…  1836</span>
<span class="c1"># 3 Dante Alighieri         Italy          images… Italian &quot;htt…   928 The …  1315</span>
<span class="c1"># 4 Unknown                 Sumer and Akk… images… Akkadi… &quot;htt…   160 The … -1700</span>
<span class="c1"># 5 Unknown                 Achaemenid Em… images… Hebrew  &quot;htt…   176 The …  -600</span>
<span class="c1"># 6 Unknown                 India/Iran/Ir… images… Arabic  &quot;htt…   288 One …  1200</span>
<span class="c1"># … with abbreviated variable names ¹​imageLink, ²​language</span>

<span class="nf">show</span><span class="p">(</span><span class="n">jsonDF</span><span class="p">)</span>

<span class="c1"># Source: spark&lt;jsonTable&gt; [?? x 8]</span>
<span class="c1">#    author                  country       image…¹ langu…² link  pages title  year</span>
<span class="c1">#    &lt;chr&gt;                   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;</span>
<span class="c1">#  1 Chinua Achebe           Nigeria       images… English &quot;htt…   209 Thin…  1958</span>
<span class="c1">#  2 Hans Christian Andersen Denmark       images… Danish  &quot;htt…   784 Fair…  1836</span>
<span class="c1">#  3 Dante Alighieri         Italy         images… Italian &quot;htt…   928 The …  1315</span>
<span class="c1">#  4 Unknown                 Sumer and Ak… images… Akkadi… &quot;htt…   160 The … -1700</span>
<span class="c1">#  5 Unknown                 Achaemenid E… images… Hebrew  &quot;htt…   176 The …  -600</span>
<span class="c1">#  6 Unknown                 India/Iran/I… images… Arabic  &quot;htt…   288 One …  1200</span>
<span class="c1">#  7 Unknown                 Iceland       images… Old No… &quot;htt…   384 Njál…  1350</span>
<span class="c1">#  8 Jane Austen             United Kingd… images… English &quot;htt…   226 Prid…  1813</span>
<span class="c1">#  9 Honoré de Balzac        France        images… French  &quot;htt…   443 Le P…  1835</span>
<span class="c1"># 10 Samuel Beckett          Republic of … images… French… &quot;htt…   256 Moll…  1952</span>
<span class="c1"># … with more rows, and abbreviated variable names ¹​imageLink, ²​language</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>

<span class="nf">collect</span><span class="p">(</span><span class="n">jsonDF</span><span class="p">)</span>

<span class="c1"># A tibble: 100 × 8</span>
<span class="c1">#    author                  country       image…¹ langu…² link  pages title  year</span>
<span class="c1">#    &lt;chr&gt;                   &lt;chr&gt;         &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt;</span>
<span class="c1">#  1 Chinua Achebe           Nigeria       images… English &quot;htt…   209 Thin…  1958</span>
<span class="c1">#  2 Hans Christian Andersen Denmark       images… Danish  &quot;htt…   784 Fair…  1836</span>
<span class="c1">#  3 Dante Alighieri         Italy         images… Italian &quot;htt…   928 The …  1315</span>
<span class="c1">#  4 Unknown                 Sumer and Ak… images… Akkadi… &quot;htt…   160 The … -1700</span>
<span class="c1">#  5 Unknown                 Achaemenid E… images… Hebrew  &quot;htt…   176 The …  -600</span>
<span class="c1">#  6 Unknown                 India/Iran/I… images… Arabic  &quot;htt…   288 One …  1200</span>
<span class="c1">#  7 Unknown                 Iceland       images… Old No… &quot;htt…   384 Njál…  1350</span>
<span class="c1">#  8 Jane Austen             United Kingd… images… English &quot;htt…   226 Prid…  1813</span>
<span class="c1">#  9 Honoré de Balzac        France        images… French  &quot;htt…   443 Le P…  1835</span>
<span class="c1"># 10 Samuel Beckett          Republic of … images… French… &quot;htt…   256 Moll…  1952</span>
<span class="c1"># … with 90 more rows, and abbreviated variable names ¹​imageLink, ²​language</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
</div>
<div class="section" id="run-sql-queries-and-write-to-and-read-from-a-table">
<h2>Run SQL queries, and write to and read from a table<a class="headerlink" href="#run-sql-queries-and-write-to-and-read-from-a-table" title="Permalink to this headline"> </a></h2>
<p>You can use dplyr functions to run SQL queries on a DataFrame. For example, run the following code in a notebook cell to use <code class="docutils literal notranslate"><span class="pre">dplyr::group_by</span></code> and <code class="docutils literal notranslate"><span class="pre">dployr::count</span></code> to get counts by author from the DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonDF</span></code>. Use <code class="docutils literal notranslate"><span class="pre">dplyr::arrange</span></code> and <code class="docutils literal notranslate"><span class="pre">dplyr::desc</span></code> to sort the result in descending order by counts. Then print the first 10 rows by default.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">group_by</span><span class="p">(</span><span class="n">jsonDF</span><span class="p">,</span><span class="w"> </span><span class="n">author</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">count</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">arrange</span><span class="p">(</span><span class="nf">desc</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>

<span class="c1"># Source:     spark&lt;?&gt; [?? x 2]</span>
<span class="c1"># Ordered by: desc(n)</span>
<span class="c1">#    author                     n</span>
<span class="c1">#    &lt;chr&gt;                  &lt;dbl&gt;</span>
<span class="c1">#  1 Fyodor Dostoevsky          4</span>
<span class="c1">#  2 Unknown                    4</span>
<span class="c1">#  3 Leo Tolstoy                3</span>
<span class="c1">#  4 Franz Kafka                3</span>
<span class="c1">#  5 William Shakespeare        3</span>
<span class="c1">#  6 William Faulkner           2</span>
<span class="c1">#  7 Gustave Flaubert           2</span>
<span class="c1">#  8 Homer                      2</span>
<span class="c1">#  9 Gabriel García Márquez     2</span>
<span class="c1"># 10 Thomas Mann                2</span>
<span class="c1"># … with more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
<p>You could then use <code class="docutils literal notranslate"><span class="pre">sparklyr::spark_write_table</span></code> to write the result to a table in Databricks. For example, run the following code in a notebook cell to rerun the query and then write the result to a table named <code class="docutils literal notranslate"><span class="pre">json_books_agg</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">group_by</span><span class="p">(</span><span class="n">jsonDF</span><span class="p">,</span><span class="w"> </span><span class="n">author</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">count</span><span class="p">()</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">arrange</span><span class="p">(</span><span class="nf">desc</span><span class="p">(</span><span class="n">n</span><span class="p">))</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">spark_write_table</span><span class="p">(</span>
<span class="w">    </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;json_books_agg&quot;</span><span class="p">,</span>
<span class="w">    </span><span class="n">mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;overwrite&quot;</span>
<span class="w">  </span><span class="p">)</span>
</pre></div>
</div>
<p>To verify that the table was created, you could then use <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_sql</span></code> along with <code class="docutils literal notranslate"><span class="pre">SparkR::showDF</span></code> to display the table’s data. For example, run the following code in a notebook cell to query the table into a DataFrame and then use <code class="docutils literal notranslate"><span class="pre">sparklyr::collect</span></code> to print the first 10 rows of the DataFrame by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">collect</span><span class="p">(</span><span class="nf">sdf_sql</span><span class="p">(</span><span class="n">sc</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;SELECT * FROM json_books_agg&quot;</span><span class="p">))</span>

<span class="c1"># A tibble: 82 × 2</span>
<span class="c1">#    author                     n</span>
<span class="c1">#    &lt;chr&gt;                  &lt;dbl&gt;</span>
<span class="c1">#  1 Fyodor Dostoevsky          4</span>
<span class="c1">#  2 Unknown                    4</span>
<span class="c1">#  3 Leo Tolstoy                3</span>
<span class="c1">#  4 Franz Kafka                3</span>
<span class="c1">#  5 William Shakespeare        3</span>
<span class="c1">#  6 William Faulkner           2</span>
<span class="c1">#  7 Homer                      2</span>
<span class="c1">#  8 Gustave Flaubert           2</span>
<span class="c1">#  9 Gabriel García Márquez     2</span>
<span class="c1"># 10 Thomas Mann                2</span>
<span class="c1"># … with 72 more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
<p>You could also use <code class="docutils literal notranslate"><span class="pre">sparklyr::spark_read_table</span></code> to do something similar. For example, run the following code in a notebook cell to query the preceding DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonDF</span></code> into a DataFrame and then use <code class="docutils literal notranslate"><span class="pre">sparklyr::collect</span></code> to print the first 10 rows of the DataFrame by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">fromTable</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">spark_read_table</span><span class="p">(</span>
<span class="w">  </span><span class="n">sc</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="n">sc</span><span class="p">,</span>
<span class="w">  </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;json_books_agg&quot;</span>
<span class="p">)</span>

<span class="nf">collect</span><span class="p">(</span><span class="n">fromTable</span><span class="p">)</span>

<span class="c1"># A tibble: 82 × 2</span>
<span class="c1">#    author                     n</span>
<span class="c1">#    &lt;chr&gt;                  &lt;dbl&gt;</span>
<span class="c1">#  1 Fyodor Dostoevsky          4</span>
<span class="c1">#  2 Unknown                    4</span>
<span class="c1">#  3 Leo Tolstoy                3</span>
<span class="c1">#  4 Franz Kafka                3</span>
<span class="c1">#  5 William Shakespeare        3</span>
<span class="c1">#  6 William Faulkner           2</span>
<span class="c1">#  7 Homer                      2</span>
<span class="c1">#  8 Gustave Flaubert           2</span>
<span class="c1">#  9 Gabriel García Márquez     2</span>
<span class="c1"># 10 Thomas Mann                2</span>
<span class="c1"># … with 72 more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
</div>
<div class="section" id="add-columns-and-compute-column-values-in-a-dataframe">
<h2>Add columns and compute column values in a DataFrame<a class="headerlink" href="#add-columns-and-compute-column-values-in-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can use dplyr functions to add columns to DataFrames and to compute columns’ values.</p>
<p>For example, run the following code in a notebook cell to get the contents of the DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonDF</span></code>. Use <code class="docutils literal notranslate"><span class="pre">dplyr::mutate</span></code> to add a column named <code class="docutils literal notranslate"><span class="pre">today</span></code>, and fill this new column with the current timestamp. Then write these contents to a new DataFrame named <code class="docutils literal notranslate"><span class="pre">withDate</span></code> and use <code class="docutils literal notranslate"><span class="pre">dplyr::collect</span></code> to print the new DataFrame’s first 10 rows by default.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">dplyr::mutate</span></code> only accepts arguments that conform to Hive’s built-in functions (also known as UDFs) and built-in aggregate functions (also known as UDAFs). For general information, see <a class="reference external" href="https://spark.rstudio.com/guides/dplyr.html#hive-functions">Hive Functions</a>. For information about the date-related functions in this section, see <a class="reference external" href="https://cwiki.apache.org/confluence/display/Hive/LanguageManual+UDF#LanguageManualUDF-DateFunctions">Date Functions</a>.</p>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">withDate</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">jsonDF</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">today</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">current_timestamp</span><span class="p">())</span>

<span class="nf">collect</span><span class="p">(</span><span class="n">withDate</span><span class="p">)</span>

<span class="c1"># A tibble: 100 × 9</span>
<span class="c1">#    author    country image…¹ langu…² link  pages title  year today</span>
<span class="c1">#    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;dttm&gt;</span>
<span class="c1">#  1 Chinua A… Nigeria images… English &quot;htt…   209 Thin…  1958 2022-09-27 21:32:59</span>
<span class="c1">#  2 Hans Chr… Denmark images… Danish  &quot;htt…   784 Fair…  1836 2022-09-27 21:32:59</span>
<span class="c1">#  3 Dante Al… Italy   images… Italian &quot;htt…   928 The …  1315 2022-09-27 21:32:59</span>
<span class="c1">#  4 Unknown   Sumer … images… Akkadi… &quot;htt…   160 The … -1700 2022-09-27 21:32:59</span>
<span class="c1">#  5 Unknown   Achaem… images… Hebrew  &quot;htt…   176 The …  -600 2022-09-27 21:32:59</span>
<span class="c1">#  6 Unknown   India/… images… Arabic  &quot;htt…   288 One …  1200 2022-09-27 21:32:59</span>
<span class="c1">#  7 Unknown   Iceland images… Old No… &quot;htt…   384 Njál…  1350 2022-09-27 21:32:59</span>
<span class="c1">#  8 Jane Aus… United… images… English &quot;htt…   226 Prid…  1813 2022-09-27 21:32:59</span>
<span class="c1">#  9 Honoré d… France  images… French  &quot;htt…   443 Le P…  1835 2022-09-27 21:32:59</span>
<span class="c1"># 10 Samuel B… Republ… images… French… &quot;htt…   256 Moll…  1952 2022-09-27 21:32:59</span>
<span class="c1"># … with 90 more rows, and abbreviated variable names ¹​imageLink, ²​language</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
<p>Now use <code class="docutils literal notranslate"><span class="pre">dplyr::mutate</span></code> to add two more columns to the contents of the <code class="docutils literal notranslate"><span class="pre">withDate</span></code> DataFrame. The new <code class="docutils literal notranslate"><span class="pre">month</span></code> and <code class="docutils literal notranslate"><span class="pre">year</span></code> columns contain the numeric month and year from the <code class="docutils literal notranslate"><span class="pre">today</span></code> column. Then write these contents to a new DataFrame named <code class="docutils literal notranslate"><span class="pre">withMMyyyy</span></code>, and use <code class="docutils literal notranslate"><span class="pre">dplyr::select</span></code> along with <code class="docutils literal notranslate"><span class="pre">dplyr::collect</span></code> to print the <code class="docutils literal notranslate"><span class="pre">author</span></code>, <code class="docutils literal notranslate"><span class="pre">title</span></code>, <code class="docutils literal notranslate"><span class="pre">month</span></code> and <code class="docutils literal notranslate"><span class="pre">year</span></code> columns of the new DataFrame’s first ten rows by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">withMMyyyy</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">withDate</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">month</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">month</span><span class="p">(</span><span class="n">today</span><span class="p">),</span>
<span class="w">         </span><span class="n">year</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="nf">year</span><span class="p">(</span><span class="n">today</span><span class="p">))</span>

<span class="nf">collect</span><span class="p">(</span><span class="nf">select</span><span class="p">(</span><span class="n">withMMyyyy</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;author&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;title&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;month&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;year&quot;</span><span class="p">)))</span>

<span class="c1"># A tibble: 100 × 4</span>
<span class="c1">#    author                  title                                     month  year</span>
<span class="c1">#    &lt;chr&gt;                   &lt;chr&gt;                                     &lt;int&gt; &lt;int&gt;</span>
<span class="c1">#  1 Chinua Achebe           Things Fall Apart                             9  2022</span>
<span class="c1">#  2 Hans Christian Andersen Fairy tales                                   9  2022</span>
<span class="c1">#  3 Dante Alighieri         The Divine Comedy                             9  2022</span>
<span class="c1">#  4 Unknown                 The Epic Of Gilgamesh                         9  2022</span>
<span class="c1">#  5 Unknown                 The Book Of Job                               9  2022</span>
<span class="c1">#  6 Unknown                 One Thousand and One Nights                   9  2022</span>
<span class="c1">#  7 Unknown                 Njál&#39;s Saga                                   9  2022</span>
<span class="c1">#  8 Jane Austen             Pride and Prejudice                           9  2022</span>
<span class="c1">#  9 Honoré de Balzac        Le Père Goriot                                9  2022</span>
<span class="c1"># 10 Samuel Beckett          Molloy, Malone Dies, The Unnamable, the …     9  2022</span>
<span class="c1"># … with 90 more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
<p>Now use <code class="docutils literal notranslate"><span class="pre">dplyr::mutate</span></code> to add two more columns to the contents of the <code class="docutils literal notranslate"><span class="pre">withMMyyyy</span></code> DataFrame. The new <code class="docutils literal notranslate"><span class="pre">formatted_date</span></code> columns contains the <code class="docutils literal notranslate"><span class="pre">yyyy-MM-dd</span></code> portion from the <code class="docutils literal notranslate"><span class="pre">today</span></code> column, while the new <code class="docutils literal notranslate"><span class="pre">day</span></code> column contains the numeric day from the new <code class="docutils literal notranslate"><span class="pre">formatted_date</span></code> column. Then write these contents to a new DataFrame named <code class="docutils literal notranslate"><span class="pre">withUnixTimestamp</span></code>, and use <code class="docutils literal notranslate"><span class="pre">dplyr::select</span></code> along with <code class="docutils literal notranslate"><span class="pre">dplyr::collect</span></code> to print the <code class="docutils literal notranslate"><span class="pre">title</span></code>, <code class="docutils literal notranslate"><span class="pre">formatted_date</span></code>, and <code class="docutils literal notranslate"><span class="pre">day</span></code> columns of the new DataFrame’s first ten rows by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">withUnixTimestamp</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">withMMyyyy</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">mutate</span><span class="p">(</span><span class="n">formatted_date</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">date_format</span><span class="p">(</span><span class="n">today</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;yyyy-MM-dd&quot;</span><span class="p">),</span>
<span class="w">         </span><span class="n">day</span><span class="w">            </span><span class="o">=</span><span class="w"> </span><span class="nf">dayofmonth</span><span class="p">(</span><span class="n">formatted_date</span><span class="p">))</span>

<span class="nf">collect</span><span class="p">(</span><span class="nf">select</span><span class="p">(</span><span class="n">withUnixTimestamp</span><span class="p">,</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;title&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;formatted_date&quot;</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;day&quot;</span><span class="p">)))</span>

<span class="c1"># A tibble: 100 × 3</span>
<span class="c1">#    title                                           formatted_date   day</span>
<span class="c1">#    &lt;chr&gt;                                           &lt;chr&gt;          &lt;int&gt;</span>
<span class="c1">#  1 Things Fall Apart                               2022-09-27        27</span>
<span class="c1">#  2 Fairy tales                                     2022-09-27        27</span>
<span class="c1">#  3 The Divine Comedy                               2022-09-27        27</span>
<span class="c1">#  4 The Epic Of Gilgamesh                           2022-09-27        27</span>
<span class="c1">#  5 The Book Of Job                                 2022-09-27        27</span>
<span class="c1">#  6 One Thousand and One Nights                     2022-09-27        27</span>
<span class="c1">#  7 Njál&#39;s Saga                                     2022-09-27        27</span>
<span class="c1">#  8 Pride and Prejudice                             2022-09-27        27</span>
<span class="c1">#  9 Le Père Goriot                                  2022-09-27        27</span>
<span class="c1"># 10 Molloy, Malone Dies, The Unnamable, the trilogy 2022-09-27        27</span>
<span class="c1"># … with 90 more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
</div>
<div class="section" id="create-a-temporary-view">
<h2>Create a temporary view<a class="headerlink" href="#create-a-temporary-view" title="Permalink to this headline"> </a></h2>
<p>You can create named temporary views in memory that are based on existing DataFrames. For example, run the following code in a notebook cell to use <code class="docutils literal notranslate"><span class="pre">SparkR::createOrReplaceTempView</span></code> to get the contents of the preceding DataFrame named <code class="docutils literal notranslate"><span class="pre">jsonTable</span></code> and make a temporary view out of it named <code class="docutils literal notranslate"><span class="pre">timestampTable</span></code>. Then, use <code class="docutils literal notranslate"><span class="pre">sparklyr::spark_read_table</span></code> to read the temporary view’s contents. Use <code class="docutils literal notranslate"><span class="pre">sparklyr::collect</span></code> to print the first 10 rows of the temporary table by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">createOrReplaceTempView</span><span class="p">(</span><span class="n">withTimestampDF</span><span class="p">,</span><span class="w"> </span><span class="n">viewName</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;timestampTable&quot;</span><span class="p">)</span>

<span class="nf">spark_read_table</span><span class="p">(</span>
<span class="w">  </span><span class="n">sc</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">sc</span><span class="p">,</span>
<span class="w">  </span><span class="n">name</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;timestampTable&quot;</span>
<span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span><span class="w"> </span><span class="nf">collect</span><span class="p">()</span>

<span class="c1"># A tibble: 100 × 10</span>
<span class="c1">#    author    country image…¹ langu…² link  pages title  year today</span>
<span class="c1">#    &lt;chr&gt;     &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt;   &lt;chr&gt; &lt;int&gt; &lt;chr&gt; &lt;int&gt; &lt;dttm&gt;</span>
<span class="c1">#  1 Chinua A… Nigeria images… English &quot;htt…   209 Thin…  1958 2022-09-27 21:11:56</span>
<span class="c1">#  2 Hans Chr… Denmark images… Danish  &quot;htt…   784 Fair…  1836 2022-09-27 21:11:56</span>
<span class="c1">#  3 Dante Al… Italy   images… Italian &quot;htt…   928 The …  1315 2022-09-27 21:11:56</span>
<span class="c1">#  4 Unknown   Sumer … images… Akkadi… &quot;htt…   160 The … -1700 2022-09-27 21:11:56</span>
<span class="c1">#  5 Unknown   Achaem… images… Hebrew  &quot;htt…   176 The …  -600 2022-09-27 21:11:56</span>
<span class="c1">#  6 Unknown   India/… images… Arabic  &quot;htt…   288 One …  1200 2022-09-27 21:11:56</span>
<span class="c1">#  7 Unknown   Iceland images… Old No… &quot;htt…   384 Njál…  1350 2022-09-27 21:11:56</span>
<span class="c1">#  8 Jane Aus… United… images… English &quot;htt…   226 Prid…  1813 2022-09-27 21:11:56</span>
<span class="c1">#  9 Honoré d… France  images… French  &quot;htt…   443 Le P…  1835 2022-09-27 21:11:56</span>
<span class="c1"># 10 Samuel B… Republ… images… French… &quot;htt…   256 Moll…  1952 2022-09-27 21:11:56</span>
<span class="c1"># … with 90 more rows, 1 more variable: month &lt;chr&gt;, and abbreviated variable</span>
<span class="c1">#   names ¹​imageLink, ²​language</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows, and `colnames()` to see all variable names</span>
</pre></div>
</div>
</div>
<div class="section" id="perform-statistical-analysis-on-a-dataframe">
<h2>Perform statistical analysis on a DataFrame<a class="headerlink" href="#perform-statistical-analysis-on-a-dataframe" title="Permalink to this headline"> </a></h2>
<p>You can use sparklyr along with dplyr for statistical analyses.</p>
<p>For example, create a DataFrame to run statistics on. To do this, run the following code in a notebook cell to use <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_copy_to</span></code> to write the contents of the <code class="docutils literal notranslate"><span class="pre">iris</span></code> dataset that is built into R to a DataFrame named <code class="docutils literal notranslate"><span class="pre">iris</span></code>. Use <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_collect</span></code> to print the first 10 rows of the temporary table by default:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">irisDF</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sdf_copy_to</span><span class="p">(</span>
<span class="w">  </span><span class="n">sc</span><span class="w">        </span><span class="o">=</span><span class="w"> </span><span class="n">sc</span><span class="p">,</span>
<span class="w">  </span><span class="n">x</span><span class="w">         </span><span class="o">=</span><span class="w"> </span><span class="n">iris</span><span class="p">,</span>
<span class="w">  </span><span class="n">name</span><span class="w">      </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;iris&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">overwrite</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">TRUE</span>
<span class="p">)</span>

<span class="nf">sdf_collect</span><span class="p">(</span><span class="n">irisDF</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;row-wise&quot;</span><span class="p">)</span>

<span class="c1"># A tibble: 150 × 5</span>
<span class="c1">#    Sepal_Length Sepal_Width Petal_Length Petal_Width Species</span>
<span class="c1">#           &lt;dbl&gt;       &lt;dbl&gt;        &lt;dbl&gt;       &lt;dbl&gt; &lt;chr&gt;</span>
<span class="c1">#  1          5.1         3.5          1.4         0.2 setosa</span>
<span class="c1">#  2          4.9         3            1.4         0.2 setosa</span>
<span class="c1">#  3          4.7         3.2          1.3         0.2 setosa</span>
<span class="c1">#  4          4.6         3.1          1.5         0.2 setosa</span>
<span class="c1">#  5          5           3.6          1.4         0.2 setosa</span>
<span class="c1">#  6          5.4         3.9          1.7         0.4 setosa</span>
<span class="c1">#  7          4.6         3.4          1.4         0.3 setosa</span>
<span class="c1">#  8          5           3.4          1.5         0.2 setosa</span>
<span class="c1">#  9          4.4         2.9          1.4         0.2 setosa</span>
<span class="c1"># 10          4.9         3.1          1.5         0.1 setosa</span>
<span class="c1"># … with 140 more rows</span>
<span class="c1"># ℹ Use `print(n = ...)` to see more rows</span>
</pre></div>
</div>
<p>Now use <code class="docutils literal notranslate"><span class="pre">dplyr::group_by</span></code> to group rows by the <code class="docutils literal notranslate"><span class="pre">Species</span></code> column. Use <code class="docutils literal notranslate"><span class="pre">dplyr::summarize</span></code> along with <code class="docutils literal notranslate"><span class="pre">dplyr::percentile_approx</span></code> to calculate summary statistics by the 25th, 50th, 75th, and 100th quantiles of the <code class="docutils literal notranslate"><span class="pre">Sepal_Length</span></code> column by <code class="docutils literal notranslate"><span class="pre">Species</span></code>. Use <code class="docutils literal notranslate"><span class="pre">sparklyr::collect</span></code> a print the results:</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p><code class="docutils literal notranslate"><span class="pre">dplyr::summarize</span></code> only accepts arguments that conform to Hive’s built-in functions (also known as UDFs) and built-in aggregate functions (also known as UDAFs). For general information, see <a class="reference external" href="https://spark.rstudio.com/guides/dplyr.html#hive-functions">Hive Functions</a>. For information about <code class="docutils literal notranslate"><span class="pre">percentile_approx</span></code>, see <a class="reference external" href="https://cwiki.apache.org/confluence/display/hive/languagemanual+udf#LanguageManualUDF-Built-inAggregateFunctions(UDAF">Built-in Aggregate Functions(UDAF)</a>).</p>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">quantileDF</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">irisDF</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">group_by</span><span class="p">(</span><span class="n">Species</span><span class="p">)</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">  </span><span class="nf">summarize</span><span class="p">(</span>
<span class="w">    </span><span class="n">quantile_25th</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">percentile_approx</span><span class="p">(</span>
<span class="w">      </span><span class="n">Sepal_Length</span><span class="p">,</span>
<span class="w">      </span><span class="m">0.25</span>
<span class="w">    </span><span class="p">),</span>
<span class="w">    </span><span class="n">quantile_50th</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">percentile_approx</span><span class="p">(</span>
<span class="w">      </span><span class="n">Sepal_Length</span><span class="p">,</span>
<span class="w">      </span><span class="m">0.50</span>
<span class="w">    </span><span class="p">),</span>
<span class="w">    </span><span class="n">quantile_75th</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">percentile_approx</span><span class="p">(</span>
<span class="w">      </span><span class="n">Sepal_Length</span><span class="p">,</span>
<span class="w">      </span><span class="m">0.75</span>
<span class="w">    </span><span class="p">),</span>
<span class="w">    </span><span class="n">quantile_100th</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">percentile_approx</span><span class="p">(</span>
<span class="w">      </span><span class="n">Sepal_Length</span><span class="p">,</span>
<span class="w">      </span><span class="m">1.0</span>
<span class="w">    </span><span class="p">)</span>
<span class="w">  </span><span class="p">)</span>

<span class="nf">collect</span><span class="p">(</span><span class="n">quantileDF</span><span class="p">)</span>

<span class="c1"># A tibble: 3 × 5</span>
<span class="c1">#   Species    quantile_25th quantile_50th quantile_75th quantile_100th</span>
<span class="c1">#   &lt;chr&gt;              &lt;dbl&gt;         &lt;dbl&gt;         &lt;dbl&gt;          &lt;dbl&gt;</span>
<span class="c1"># 1 virginica            6.2           6.5           6.9            7.9</span>
<span class="c1"># 2 versicolor           5.6           5.9           6.3            7</span>
<span class="c1"># 3 setosa               4.8           5             5.2            5.8</span>
</pre></div>
</div>
<p>Similar results can be calculated, for example, by using <code class="docutils literal notranslate"><span class="pre">sparklyr::sdf_quantile</span></code>:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">print</span><span class="p">(</span><span class="nf">sdf_quantile</span><span class="p">(</span>
<span class="w">  </span><span class="n">x</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">irisDF</span><span class="w"> </span><span class="o">%&gt;%</span>
<span class="w">    </span><span class="nf">filter</span><span class="p">(</span><span class="n">Species</span><span class="w"> </span><span class="o">==</span><span class="w"> </span><span class="s">&quot;virginica&quot;</span><span class="p">),</span>
<span class="w">  </span><span class="n">column</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;Sepal_Length&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">probabilities</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="nf">c</span><span class="p">(</span><span class="m">0.25</span><span class="p">,</span><span class="w"> </span><span class="m">0.5</span><span class="p">,</span><span class="w"> </span><span class="m">0.75</span><span class="p">,</span><span class="w"> </span><span class="m">1.0</span><span class="p">)</span>
<span class="p">))</span>

<span class="c1"># 25%  50%  75% 100%</span>
<span class="c1"># 6.2  6.5  6.9  7.9</span>
</pre></div>
</div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>