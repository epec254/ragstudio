

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn how to work with Apache Spark from R using SparkR in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="SparkR overview">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>SparkR overview &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/sparkr/overview.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/sparkr/overview.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/sparkr/overview.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/sparkr/overview.html" class="notranslate">English</option>
    <option value="../../ja/sparkr/overview.html" class="notranslate">日本語</option>
    <option value="../../pt/sparkr/overview.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>SparkR overview</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="sparkr-overview">
<h1>SparkR overview<a class="headerlink" href="#sparkr-overview" title="Permalink to this headline"> </a></h1>
<p>SparkR is an R package that provides a light-weight frontend to use Apache Spark from R. SparkR also supports distributed machine learning using MLlib.</p>
<div class="section" id="sparkr-function-reference">
<h2>SparkR function reference<a class="headerlink" href="#sparkr-function-reference" title="Permalink to this headline"> </a></h2>
<p>You can find the latest SparkR function reference on
<a class="reference external" href="https://spark.apache.org/docs/latest/api/R/index.html">spark.apache.org</a>.</p>
<p>You can also view function help in R notebooks or RStudio after you import the SparkR
package.</p>
<div class="figure align-default">
<img alt="Embedded R documentation" src="../_images/inline-r-docs.png" />
</div>
</div>
<div class="section" id="sparkr-in-notebooks">
<h2>SparkR in notebooks<a class="headerlink" href="#sparkr-in-notebooks" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p>For Spark 2.0 and above, you do not need to explicitly pass a <code class="docutils literal notranslate"><span class="pre">sqlContext</span></code> object to every function call.</p></li>
<li><p>For Spark 2.2 and above, notebooks no longer import SparkR by default because SparkR functions were conflicting with similarly named functions from other popular packages. To use SparkR you can call <code class="docutils literal notranslate"><span class="pre">library(SparkR)</span></code> in your notebooks. The SparkR session is already configured, and all SparkR functions will talk to your attached cluster using the existing session.</p></li>
</ul>
</div>
<div class="section" id="sparkr-in-spark-submit-jobs">
<h2>SparkR in spark-submit jobs<a class="headerlink" href="#sparkr-in-spark-submit-jobs" title="Permalink to this headline"> </a></h2>
<p>You can run scripts that use SparkR on Databricks as spark-submit jobs, with minor code modifications.</p>
</div>
<div class="section" id="create-sparkr-dataframes">
<h2>Create SparkR DataFrames<a class="headerlink" href="#create-sparkr-dataframes" title="Permalink to this headline"> </a></h2>
<p>You can create a DataFrame from a local R <code class="docutils literal notranslate"><span class="pre">data.frame</span></code>, from a data source, or using a Spark SQL query.</p>
<div class="section" id="from-a-local-r-dataframe">
<h3>From a local R <code class="docutils literal notranslate"><span class="pre">data.frame</span></code><a class="headerlink" href="#from-a-local-r-dataframe" title="Permalink to this headline"> </a></h3>
<p>The simplest way to create a DataFrame is to convert a local R <code class="docutils literal notranslate"><span class="pre">data.frame</span></code> into a
<code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code>. Specifically we can use <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code> and pass in the local R
<code class="docutils literal notranslate"><span class="pre">data.frame</span></code> to create a <code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code>. Like most other SparkR functions, <code class="docutils literal notranslate"><span class="pre">createDataFrame</span></code>
syntax changed in Spark 2.0. You can see examples of this in the code snippet bellow.
For more examples, see <a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/createDataFrame.html">createDataFrame</a>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>
<span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">faithful</span><span class="p">)</span>

<span class="c1"># Displays the content of the DataFrame to stdout</span>
<span class="nf">head</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="section" id="using-the-data-source-api">
<h3>Using the data source API<a class="headerlink" href="#using-the-data-source-api" title="Permalink to this headline"> </a></h3>
<p>The general method for creating a DataFrame from a data source is <code class="docutils literal notranslate"><span class="pre">read.df</span></code>.
This method takes the path for the file to load and the type of data source.
SparkR supports reading CSV, JSON, text, and Parquet files
natively.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">library</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>
<span class="n">diamondsDF</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.df</span><span class="p">(</span><span class="s">&quot;/databricks-datasets/Rdatasets/data-001/csv/ggplot2/diamonds.csv&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;csv&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">header</span><span class="o">=</span><span class="s">&quot;true&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">inferSchema</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;true&quot;</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">diamondsDF</span><span class="p">)</span>
</pre></div>
</div>
<p>SparkR automatically infers the schema from the CSV file.</p>
<div class="section" id="adding-a-data-source-connector-with-spark-packages">
<h4>Adding a data source connector with Spark Packages<a class="headerlink" href="#adding-a-data-source-connector-with-spark-packages" title="Permalink to this headline"> </a></h4>
<p>Through Spark Packages you can find data source connectors
for popular file formats such as Avro. As an example, use the
<a class="reference external" href="https://spark-packages.org/package/databricks/spark-avro">spark-avro package</a>
to load an <a class="reference external" href="https://avro.apache.org/">Avro</a> file. The availability of the spark-avro package depends on your cluster’s <a class="reference internal" href="../release-notes/runtime/index.html"><span class="doc">version</span></a>. See <a class="reference internal" href="../query/formats/avro.html"><span class="doc">Avro file</span></a>.</p>
<p>First take an existing <code class="docutils literal notranslate"><span class="pre">data.frame</span></code>, convert to a Spark DataFrame, and save it as an Avro file.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">require</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>
<span class="n">irisDF</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span>
<span class="nf">write.df</span><span class="p">(</span><span class="n">irisDF</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;com.databricks.spark.avro&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dbfs:/tmp/iris.avro&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">mode</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;overwrite&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>To verify that an Avro file was saved:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span>%<span class="n">fs</span><span class="w"> </span><span class="n">ls</span><span class="w"> </span><span class="o">/</span><span class="n">tmp</span><span class="o">/</span><span class="n">iris.avro</span>
</pre></div>
</div>
<p>Now use the spark-avro package again to read back the data.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="n">irisDF2</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">read.df</span><span class="p">(</span><span class="n">path</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/tmp/iris.avro&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;com.databricks.spark.avro&quot;</span><span class="p">)</span>
<span class="nf">head</span><span class="p">(</span><span class="n">irisDF2</span><span class="p">)</span>
</pre></div>
</div>
<p>The data source API can also be used to save DataFrames into
multiple file formats. For example, you can save the DataFrame from the
previous example to a Parquet file using <code class="docutils literal notranslate"><span class="pre">write.df</span></code>.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">write.df</span><span class="p">(</span><span class="n">irisDF2</span><span class="p">,</span><span class="w"> </span><span class="n">path</span><span class="o">=</span><span class="s">&quot;dbfs:/tmp/iris.parquet&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">source</span><span class="o">=</span><span class="s">&quot;parquet&quot;</span><span class="p">,</span><span class="w"> </span><span class="n">mode</span><span class="o">=</span><span class="s">&quot;overwrite&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%fs<span class="w"> </span>ls<span class="w"> </span>dbfs:/tmp/iris.parquet
</pre></div>
</div>
</div>
</div>
<div class="section" id="from-a-spark-sql-query">
<h3>From a Spark SQL query<a class="headerlink" href="#from-a-spark-sql-query" title="Permalink to this headline"> </a></h3>
<p>You can also create SparkR DataFrames using Spark SQL queries.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Register earlier df as temp view</span>
<span class="nf">createOrReplaceTempView</span><span class="p">(</span><span class="n">irisDF2</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;irisTemp&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create a df consisting of only the &#39;species&#39; column using a Spark SQL query</span>
<span class="n">species</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">sql</span><span class="p">(</span><span class="s">&quot;SELECT species FROM irisTemp&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p><code class="docutils literal notranslate"><span class="pre">species</span></code> is a SparkDataFrame.</p>
</div>
</div>
<div class="section" id="dataframe-operations">
<h2>DataFrame operations<a class="headerlink" href="#dataframe-operations" title="Permalink to this headline"> </a></h2>
<p>Spark DataFrames support a number of functions to do structured data
processing. Here are some basic examples. A complete list can
be found in the <a class="reference external" href="https://spark.apache.org/docs/latest/api/R/">API docs</a>.</p>
<div class="section" id="select-rows-and-columns">
<h3>Select rows and columns<a class="headerlink" href="#select-rows-and-columns" title="Permalink to this headline"> </a></h3>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Import SparkR package if this is a new notebook</span>
<span class="nf">require</span><span class="p">(</span><span class="n">SparkR</span><span class="p">)</span>

<span class="c1"># Create DataFrame</span>
<span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">faithful</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Select only the &quot;eruptions&quot; column</span>
<span class="nf">head</span><span class="p">(</span><span class="nf">select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">eruptions</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># You can also pass in column name as strings</span>
<span class="nf">head</span><span class="p">(</span><span class="nf">select</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="s">&quot;eruptions&quot;</span><span class="p">))</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Filter the DataFrame to only retain rows with wait times shorter than 50 mins</span>
<span class="nf">head</span><span class="p">(</span><span class="nf">filter</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">waiting</span><span class="w"> </span><span class="o">&lt;</span><span class="w"> </span><span class="m">50</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="section" id="grouping-and-aggregation">
<h3>Grouping and aggregation<a class="headerlink" href="#grouping-and-aggregation" title="Permalink to this headline"> </a></h3>
<p>SparkDataFrames support a number of commonly used functions to
aggregate data after grouping. For example you can count the number of
times each waiting time appears in the faithful dataset.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">head</span><span class="p">(</span><span class="nf">count</span><span class="p">(</span><span class="nf">groupBy</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">waiting</span><span class="p">)))</span>
</pre></div>
</div>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># You can also sort the output from the aggregation to get the most common waiting times</span>
<span class="n">waiting_counts</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">count</span><span class="p">(</span><span class="nf">groupBy</span><span class="p">(</span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">waiting</span><span class="p">))</span>
<span class="nf">head</span><span class="p">(</span><span class="nf">arrange</span><span class="p">(</span><span class="n">waiting_counts</span><span class="p">,</span><span class="w"> </span><span class="nf">desc</span><span class="p">(</span><span class="n">waiting_counts</span><span class="o">$</span><span class="n">count</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="section" id="column-operations">
<h3>Column operations<a class="headerlink" href="#column-operations" title="Permalink to this headline"> </a></h3>
<p>SparkR provides a number of functions that can be directly applied to
columns for data processing and aggregation. The following example shows the
use of basic arithmetic functions.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Convert waiting time from hours to seconds.</span>
<span class="c1"># You can assign this to a new column in the same DataFrame</span>
<span class="n">df</span><span class="o">$</span><span class="n">waiting_secs</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="n">df</span><span class="o">$</span><span class="n">waiting</span><span class="w"> </span><span class="o">*</span><span class="w"> </span><span class="m">60</span>
<span class="nf">head</span><span class="p">(</span><span class="n">df</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="section" id="machine-learning">
<span id="r-ml"></span><h2>Machine learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline"> </a></h2>
<p>SparkR exposes most of MLLib algorithms. Under the hood, SparkR
uses MLlib to train the model.</p>
<p>The following example shows how to build a gaussian GLM model using
SparkR. To run linear regression, set family to <code class="docutils literal notranslate"><span class="pre">&quot;gaussian&quot;</span></code>. To run
logistic regression, set family to <code class="docutils literal notranslate"><span class="pre">&quot;binomial&quot;</span></code>. When using SparkML GLM SparkR
automatically performs one-hot encoding of
categorical features so that it does not need to be done manually.
Beyond String and Double type features, it is also possible to fit over
MLlib Vector features, for compatibility with other MLlib components.</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Create the DataFrame</span>
<span class="n">df</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">createDataFrame</span><span class="p">(</span><span class="n">iris</span><span class="p">)</span>

<span class="c1"># Fit a linear model over the dataset.</span>
<span class="n">model</span><span class="w"> </span><span class="o">&lt;-</span><span class="w"> </span><span class="nf">glm</span><span class="p">(</span><span class="n">Sepal_Length</span><span class="w"> </span><span class="o">~</span><span class="w"> </span><span class="n">Sepal_Width</span><span class="w"> </span><span class="o">+</span><span class="w"> </span><span class="n">Species</span><span class="p">,</span><span class="w"> </span><span class="n">data</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="n">df</span><span class="p">,</span><span class="w"> </span><span class="n">family</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;gaussian&quot;</span><span class="p">)</span>

<span class="c1"># Model coefficients are returned in a similar format to R&#39;s native glm().</span>
<span class="nf">summary</span><span class="p">(</span><span class="n">model</span><span class="p">)</span>
</pre></div>
</div>
<p>For tutorials, see <a class="reference internal" href="glm-tutorial.html"><span class="doc">Tutorial: Analyze data with glm</span></a>.</p>
<p>For additional examples, see <a class="reference internal" href="dataframes-tables.html"><span class="doc">Work with DataFrames and tables in R</span></a>.</p>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>