

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Databricks for R developers" name="title" />
<meta content="Learn how to work with Apache Spark from R using SparkR, sparklyr, and RStudio in Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Databricks for R developers">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Databricks for R developers &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/sparkr/index.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/sparkr/index.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/sparkr/index.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/sparkr/index.html" class="notranslate">English</option>
    <option value="../../ja/sparkr/index.html" class="notranslate">日本語</option>
    <option value="../../pt/sparkr/index.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Databricks for R developers</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="databricks-for-r-developers">
<h1>Databricks for R developers<a class="headerlink" href="#databricks-for-r-developers" title="Permalink to this headline"> </a></h1>
<p>This section provides a guide to developing notebooks and jobs in Databricks using the R language.</p>
<p>A basic workflow for getting started is:</p>
<ol class="arabic simple">
<li><p><a class="reference internal" href="#manage-code-with-notebooks-and-databricks-repos"><span class="std std-ref">Import code</span></a>: Either import your own code from files or Git repos or try a tutorial listed below. Databricks recommends learning using interactive Databricks notebooks.</p></li>
<li><p><a class="reference internal" href="#clusters"><span class="std std-ref">Run your code on a cluster</span></a>: Either create a cluster of your own, or ensure you have permissions to use a shared cluster. Attach your notebook to the cluster, and run the notebook.</p></li>
</ol>
<p>Beyond this, you can branch out into more specific topics:</p>
<ul class="simple">
<li><p><a class="reference internal" href="#reference"><span class="std std-ref">Work with larger data sets</span></a> using Apache Spark</p></li>
<li><p><a class="reference internal" href="#visualizations"><span class="std std-ref">Add visualizations</span></a></p></li>
<li><p><a class="reference internal" href="#jobs"><span class="std std-ref">Automate your workload</span></a> as a job</p></li>
<li><p><a class="reference internal" href="#machine-learning"><span class="std std-ref">Use machine learning</span></a> to analyze your data</p></li>
<li><p><a class="reference internal" href="#r-developer-tools"><span class="std std-ref">Use R developer tools</span></a></p></li>
</ul>
<div class="section" id="tutorials">
<h2>Tutorials<a class="headerlink" href="#tutorials" title="Permalink to this headline"> </a></h2>
<p>The following tutorials provide example code and notebooks to learn about common workflows. See <a class="reference internal" href="../notebooks/notebook-export-import.html#import-notebook"><span class="std std-ref">Import a notebook</span></a> for instructions on importing notebook examples into your workspace.</p>
<ul class="simple">
<li><p><a class="reference internal" href="glm-tutorial.html"><span class="doc">Tutorial: Analyze data with glm</span></a></p></li>
<li><p><a class="reference internal" href="../mlflow/quick-start-r.html"><span class="doc">MLflow quickstart R notebook</span></a></p></li>
<li><p><a class="reference internal" href="../delta/tutorial.html"><span class="doc">Tutorial: Delta Lake</span></a></p></li>
</ul>
</div>
<div class="section" id="reference">
<h2>Reference<a class="headerlink" href="#reference" title="Permalink to this headline"> </a></h2>
<p>The following subsections list key features and tips to help you begin developing in Databricks with R.</p>
<p>Databricks supports two APIs that provide an R interface to Apache Spark: <a class="reference external" href="https://spark.apache.org/docs/latest/sparkr.html">SparkR</a> and <a class="reference external" href="https://spark.rstudio.com/">sparklyr</a>.</p>
<div class="section" id="sparkr">
<h3>SparkR<a class="headerlink" href="#sparkr" title="Permalink to this headline"> </a></h3>
<p>These articles provide an introduction and reference for <a class="reference external" href="https://spark.apache.org/docs/latest/sparkr.html">SparkR</a>. SparkR is an R interface to Apache Spark that provides a distributed data frame implementation. SparkR supports operations like selection, filtering, and aggregation (similar to R data frames) but on large datasets.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="overview.html">SparkR overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="glm-tutorial.html">Tutorial: Analyze data with glm</a></li>
</ul>
</div>
</div>
<div class="section" id="sparklyr">
<h3>sparklyr<a class="headerlink" href="#sparklyr" title="Permalink to this headline"> </a></h3>
<p>This article provides an introduction to <a class="reference external" href="https://rdocumentation.org/packages/sparklyr">sparklyr</a>. sparklyr is an R interface to Apache Spark that provides functionality similar to <a class="reference external" href="https://spark.rstudio.com/guides/dplyr.html">dplyr</a>, <code class="docutils literal notranslate"><span class="pre">broom</span></code>, and <a class="reference external" href="https://spark.rstudio.com/get-started/prepare-data.html#using-sql">DBI</a>.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sparklyr.html">sparklyr</a></li>
</ul>
</div>
</div>
<div class="section" id="comparing-sparkr-and-sparklyr">
<h3>Comparing SparkR and sparklyr<a class="headerlink" href="#comparing-sparkr-and-sparklyr" title="Permalink to this headline"> </a></h3>
<p>This article explains key similarities and differences between SparkR and sparklyr.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="sparkr-vs-sparklyr.html">Comparing SparkR and sparklyr</a></li>
</ul>
</div>
</div>
<div class="section" id="work-with-dataframes-and-tables-with-sparkr-and-sparklyr">
<h3>Work with DataFrames and tables with SparkR and sparklyr<a class="headerlink" href="#work-with-dataframes-and-tables-with-sparkr-and-sparklyr" title="Permalink to this headline"> </a></h3>
<p>This article describes how to use R, SparkR, sparklyr, and dplyr to work with R data.frames, Spark DataFrames, and Spark tables in Databricks.</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="dataframes-tables.html">Work with DataFrames and tables in R</a></li>
</ul>
</div>
</div>
<div class="section" id="manage-code-with-notebooks-and-databricks-repos">
<h3>Manage code with notebooks and Databricks Repos<a class="headerlink" href="#manage-code-with-notebooks-and-databricks-repos" title="Permalink to this headline"> </a></h3>
<p>Databricks <a class="reference internal" href="../notebooks/index.html"><span class="doc">notebooks</span></a> support R. These notebooks provide functionality similar to that of Jupyter, but with additions such as built-in visualizations using big data, Apache Spark integrations for debugging and performance monitoring, and MLflow integrations for tracking machine learning experiments. Get started by <a class="reference internal" href="../notebooks/notebook-export-import.html#import-notebook"><span class="std std-ref">importing a notebook</span></a>. Once you have access to a cluster, you can <a class="reference internal" href="../notebooks/notebook-ui.html#attach"><span class="std std-ref">attach a notebook</span></a> to the cluster and <a class="reference internal" href="../notebooks/run-notebook.html"><span class="doc">run the notebook</span></a>.</p>
<p>Databricks <a class="reference internal" href="../repos/index.html"><span class="doc">Repos</span></a> allows users to synchronize notebooks and other files with Git repositories. Databricks Repos helps with code versioning and collaboration, and it can simplify importing a full repository of code into Databricks, viewing past notebook versions, and integrating with IDE development. Get started by <a class="reference internal" href="../repos/git-operations-with-repos.html"><span class="doc">cloning a remote Git repository</span></a>. You can then open or create notebooks with the repository clone, <a class="reference internal" href="../notebooks/notebook-ui.html#attach"><span class="std std-ref">attach the notebook</span></a> to a cluster, and <a class="reference internal" href="../notebooks/run-notebook.html"><span class="doc">run the notebook</span></a>.</p>
</div>
<div class="section" id="clusters">
<h3>Clusters<a class="headerlink" href="#clusters" title="Permalink to this headline"> </a></h3>
<p>Databricks <a class="reference internal" href="../compute/index.html"><span class="doc">Compute</span></a> provide compute management for both single nodes and large clusters. You can customize cluster hardware and libraries according to your needs. Data scientists will generally begin work either by <a class="reference internal" href="../compute/configure.html"><span class="doc">creating a cluster</span></a> or using an existing <a class="reference internal" href="../compute/clusters-manage.html#control-access-to-clusters"><span class="std std-ref">shared cluster</span></a>. Once you have access to a cluster, you can <a class="reference internal" href="../notebooks/notebook-ui.html#attach"><span class="std std-ref">attach a notebook</span></a> to the cluster or <a class="reference internal" href="../workflows/jobs/create-run-jobs.html#create-a-job"><span class="std std-ref">run a job</span></a> on the cluster.</p>
<ul class="simple">
<li><p>For small workloads which only require single nodes, data scientists can use <a class="reference internal" href="../compute/single-node.html"><span class="doc">Single node compute</span></a> for cost savings.</p></li>
<li><p>For detailed tips, see <a class="reference internal" href="../compute/cluster-config-best-practices.html"><span class="doc">Best practices: Cluster configuration</span></a>.</p></li>
<li><p>Administrators can set up <a class="reference internal" href="../administration-guide/clusters/policies.html"><span class="doc">cluster policies</span></a> to simplify and guide cluster creation.</p></li>
</ul>
<div class="section" id="single-node-r-and-distributed-r">
<h4>Single node R and distributed R<a class="headerlink" href="#single-node-r-and-distributed-r" title="Permalink to this headline"> </a></h4>
<p>Databricks clusters consist of an Apache Spark <em>driver</em> node and zero or more Spark <em>worker</em> (also known as <em>executor</em>) nodes. The driver node maintains attached notebook state, maintains the <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code>, interprets notebook and library commands, and runs the Spark master that coordinates with Spark executors. Worker nodes run the Spark executors, one Spark executor per worker node.</p>
<p>A <em>single node</em> cluster has one driver node and no worker nodes, with Spark running in local mode to support access to tables managed by Databricks. Single node clusters support RStudio, notebooks, libraries, and DBFS, and are useful for R projects that don’t depend on Spark for big data or parallel processing.  See <a class="reference internal" href="../compute/single-node.html"><span class="doc">Single node compute</span></a>.</p>
<p>For data sizes that R struggles to process (many gigabytes or petabytes), you should use multiple-node or <em>distributed</em> clusters instead. Distributed clusters have one driver node and one or more worker nodes. Distributed clusters support not only RStudio, notebooks, libraries, and DBFS, but R packages such as SparkR and sparklyr are uniquely designed to use distributed clusters through the <code class="docutils literal notranslate"><span class="pre">SparkContext</span></code>.  These packages provide familiar SQL and DataFrame APIs, which enable assigning and running various Spark tasks and commands in parallel across worker nodes. To learn more about sparklyr and SparkR, see <a class="reference internal" href="sparkr-vs-sparklyr.html"><span class="doc">Comparing SparkR and sparklyr</span></a>.</p>
<p>Some SparkR and sparklyr functions that take particular advantage of distributing related work across worker nodes include the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://spark.rstudio.com/guides/distributed-r.html">sparklyr::spark_apply</a>: Runs arbitrary R code at scale within a cluster. This is especially useful for using functionality that is available only in R, or R packages that are not available in Apache Spark nor other Spark packages.</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/dapply.html">SparkR::dapply</a>: Applies the specified function to each partition of a <code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code>.</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/dapplyCollect.html">SparkR::dapplyCollect</a>: Applies the specified function to each partition of a <code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code> and collects the results back to R as a <code class="docutils literal notranslate"><span class="pre">data.frame</span></code>.</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/gapply.html">SparkR::gapply</a>: Groups a <code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code> by using the specified columns and applies the specified R function to each group.</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/gapplyCollect.html">SparkR::gapplyCollect</a>: Groups a <code class="docutils literal notranslate"><span class="pre">SparkDataFrame</span></code> by using the specified columns, applies the specified R function to each group, and collects the result back to R as a <code class="docutils literal notranslate"><span class="pre">data.frame</span></code>.</p></li>
<li><p><a class="reference external" href="https://spark.apache.org/docs/latest/api/R/reference/spark.lapply.html">SparkR::spark.lapply</a>: Runs the specified function over a list of elements, distributing the computations with Spark.</p></li>
</ul>
<p>For examples, see the notebook <a class="reference external" href="https://www.databricks.com/notebooks/gallery/DistributedRUserDefinedFunctions.html">Distributed R: User Defined Functions in Spark</a>.</p>
</div>
<div class="section" id="databricks-container-services">
<span id="single-node-r-and-distributed-r"></span><h4>Databricks Container Services<a class="headerlink" href="#databricks-container-services" title="Permalink to this headline"> </a></h4>
<p><a class="reference internal" href="../compute/custom-containers.html"><span class="doc">Databricks Container Services</span></a> lets you specify a Docker image when you create a cluster. Databricks provides the <a class="reference external" href="https://hub.docker.com/r/databricksruntime/rbase">databricksruntime/rbase</a> base image on Docker Hub as an example to launch a Databricks Container Services cluster with R support. See also the <a class="reference external" href="https://github.com/databricks/containers/blob/master/ubuntu/R/Dockerfile">Dockerfile</a> that is used to generate this base image.</p>
</div>
</div>
<div class="section" id="libraries">
<h3>Libraries<a class="headerlink" href="#libraries" title="Permalink to this headline"> </a></h3>
<p>Databricks clusters use the Databricks Runtime, which provides many popular libraries out-of-the-box, including Apache Spark, Delta Lake, and more. You can also install additional third-party or custom R packages into libraries to use with notebooks and jobs.</p>
<p>Start with the default libraries in the <a class="reference internal" href="../release-notes/runtime/index.html"><span class="doc">Databricks Runtime release notes versions and compatibility</span></a>. Use <a class="reference internal" href="../machine-learning/index.html"><span class="doc">Databricks Runtime for Machine Learning</span></a> for machine learning workloads. For full lists of pre-installed libraries, see the “Installed R libraries” section for the target Databricks Runtime in <a class="reference internal" href="../release-notes/runtime/index.html"><span class="doc">Databricks Runtime release notes versions and compatibility</span></a>.</p>
<p>You can customize your environment by using <a class="reference internal" href="../libraries/notebooks-r-libraries.html"><span class="doc">Notebook-scoped R libraries</span></a>, which allow you to modify your notebook or job environment with libraries from CRAN or other repositories. To do this, you can use the familiar <a class="reference external" href="https://www.rdocumentation.org/packages/utils/versions/3.6.2/topics/install.packages">install.packages</a> function from <code class="docutils literal notranslate"><span class="pre">utils</span></code>. The following example installs the <a class="reference external" href="https://arrow.apache.org/docs/r/">Arrow R package</a> from the default CRAN repository:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span><span class="s">&quot;arrow&quot;</span><span class="p">)</span>
</pre></div>
</div>
<p>If you need an older version than what is included in the Databricks Runtime, you can use a notebook to run <a class="reference external" href="https://www.rdocumentation.org/packages/devtools/versions/1.13.6/topics/install_version">install_version</a> function from <code class="docutils literal notranslate"><span class="pre">devtools</span></code>. The following example installs <a class="reference external" href="https://dplyr.tidyverse.org/">dplyr</a> version 0.7.4 from CRAN:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">require</span><span class="p">(</span><span class="n">devtools</span><span class="p">)</span>

<span class="nf">install_version</span><span class="p">(</span>
<span class="w">  </span><span class="n">package</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;dplyr&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">version</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;0.7.4&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">repos</span><span class="w">   </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;http://cran.r-project.org&quot;</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Packages installed this way are available across a cluster. They are scoped to the user who installs them. This enables you to install multiple versions of the same package on the same compute without creating package conflicts.</p>
<p>You can install other libraries as <a class="reference internal" href="../libraries/cluster-libraries.html"><span class="doc">Cluster libraries</span></a> as needed, for example from CRAN. To do this, in the cluster user interface, click <strong>Libraries &gt; Install new &gt; CRAN</strong> and specify the library’s name. This approach is especially important for when you want to call user-defined functions with SparkR or sparklyr.</p>
<p>For more details, see <a class="reference internal" href="../libraries/index.html"><span class="doc">Libraries</span></a>.</p>
<p>To install a <a class="reference external" href="https://r-pkgs.org/">custom package</a> into a library:</p>
<ol class="arabic">
<li><p>Build your custom package from the command line or by using <a class="reference external" href="https://support.rstudio.com/hc/en-us/articles/200486488-Developing-Packages-with-the-RStudio-IDE">RStudio</a>.</p></li>
<li><p>Use the <a class="reference internal" href="../archive/dev-tools/cli/index.html"><span class="doc">Databricks CLI (legacy)</span></a> to copy the custom package file from your development machine over to <a class="reference internal" href="../dbfs/index.html"><span class="doc">DBFS</span></a> for your Databricks workspace.</p>
<p>For example:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>databricks<span class="w"> </span>fs<span class="w"> </span>cp<span class="w"> </span>/local/path/to/package/&lt;custom-package&gt;.tar.gz<span class="w"> </span>dbfs:/path/to/tar/file/
</pre></div>
</div>
<p>The preceding example applies to Databricks CLI versions 0.205 and above.</p>
</li>
<li><p>Install the custom package into a library by running <code class="docutils literal notranslate"><span class="pre">install.packages</span></code>.</p>
<p>For example, from a notebook in your workspace:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="nf">install.packages</span><span class="p">(</span>
<span class="w">  </span><span class="n">pkgs</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;/dbfs/path/to/tar/file/&lt;custom-package&gt;.tar.gz&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">type</span><span class="w">  </span><span class="o">=</span><span class="w"> </span><span class="s">&quot;source&quot;</span><span class="p">,</span>
<span class="w">  </span><span class="n">repos</span><span class="w"> </span><span class="o">=</span><span class="w"> </span><span class="kc">NULL</span>
<span class="p">)</span>
</pre></div>
</div>
<p>Or:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh
R<span class="w"> </span>CMD<span class="w"> </span>INSTALL<span class="w"> </span>/dbfs/path/to/tar/file/&lt;custom-package&gt;.tar.gz
</pre></div>
</div>
</li>
</ol>
<p>After you install a custom package into a library in DBFS, you can add the library to the search path and then load the library with a single command.</p>
<p>For example:</p>
<div class="highlight-r notranslate"><div class="highlight"><pre><span></span><span class="c1"># Add the library to the search path one time.</span>
<span class="nf">.libPaths</span><span class="p">(</span><span class="nf">c</span><span class="p">(</span><span class="s">&quot;/dbfs/path/to/tar/file/&quot;</span><span class="p">,</span><span class="w"> </span><span class="nf">.libPaths</span><span class="p">()))</span>

<span class="c1"># Load the library. You do not need to add the library to the search path again.</span>
<span class="nf">library</span><span class="p">(</span><span class="o">&lt;</span><span class="n">custom</span><span class="o">-</span><span class="n">package</span><span class="o">&gt;</span><span class="p">)</span>
</pre></div>
</div>
<p>To install a custom package as a library on <em>each</em> node in a cluster, you must use <a class="reference internal" href="../init-scripts/index.html"><span class="doc">What are init scripts?</span></a>.</p>
</div>
<div class="section" id="visualizations">
<h3>Visualizations<a class="headerlink" href="#visualizations" title="Permalink to this headline"> </a></h3>
<p>Databricks R notebooks support various types of visualizations using the <code class="docutils literal notranslate"><span class="pre">display</span></code> function.</p>
<ul class="simple">
<li><p><a class="reference internal" href="../visualizations/legacy-visualizations.html#visualizations-in-r"><span class="std std-ref">Visualizations in R</span></a></p></li>
</ul>
</div>
<div class="section" id="jobs">
<h3>Jobs<a class="headerlink" href="#jobs" title="Permalink to this headline"> </a></h3>
<p>You can automate R workloads as scheduled or triggered notebook <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">Create and run Databricks Jobs</span></a> in Databricks.</p>
<ul class="simple">
<li><p>For details on creating a job via the UI, see <a class="reference internal" href="../workflows/jobs/create-run-jobs.html#create-a-job"><span class="std std-ref">Create a job</span></a>.</p></li>
<li><p>The <a class="reference external" href="https://docs.databricks.com/api/workspace/jobs">Jobs API</a> allows you to create, edit, and delete jobs.</p></li>
<li><p>The <a class="reference internal" href="../dev-tools/cli/index.html"><span class="doc">Databricks CLI</span></a> provides a convenient command line interface for calling the Jobs API.</p></li>
</ul>
</div>
<div class="section" id="machine-learning">
<h3>Machine learning<a class="headerlink" href="#machine-learning" title="Permalink to this headline"> </a></h3>
<p>Databricks supports a wide variety of machine learning (ML) workloads, including traditional ML on tabular data, deep learning for computer vision and natural language processing, recommendation systems, graph analytics, and more. For general information about machine learning on Databricks, see <a class="reference internal" href="../machine-learning/index.html"><span class="doc">Databricks Runtime for Machine Learning</span></a>.</p>
<p>For ML algorithms, you can use pre-installed libraries in <a class="reference internal" href="../machine-learning/index.html"><span class="doc">Databricks Runtime for Machine Learning</span></a>. You can also <a class="reference internal" href="../libraries/index.html"><span class="doc">install custom libraries</span></a>.</p>
<p>For machine learning operations (MLOps), Databricks provides a managed service for the open source library MLflow. <a class="reference internal" href="../mlflow/tracking.html"><span class="doc">MLflow Tracking</span></a> lets you record model development and save models in reusable formats; the <a class="reference internal" href="../mlflow/model-registry.html"><span class="doc">MLflow Model Registry</span></a> lets you manage and automate the promotion of models towards production; and <a class="reference internal" href="../workflows/jobs/create-run-jobs.html"><span class="doc">Jobs</span></a> and <a class="reference internal" href="../machine-learning/model-serving/index.html"><span class="doc">Model Serving</span></a>, allow hosting models as batch and streaming jobs as REST endpoints. For more information and examples, see the <a class="reference internal" href="../mlflow/index.html"><span class="doc">MLflow guide</span></a> or the <a class="reference external" href="https://mlflow.org/docs/latest/R-api.html">MLflow R API docs</a>.</p>
</div>
<div class="section" id="r-developer-tools">
<h3>R developer tools<a class="headerlink" href="#r-developer-tools" title="Permalink to this headline"> </a></h3>
<p>In addition to Databricks notebooks, you can also use the following R developer tools:</p>
<div class="toctree-wrapper compound">
<ul>
<li class="toctree-l1"><a class="reference internal" href="rstudio.html">RStudio on Databricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="shiny.html">Shiny on Databricks</a></li>
<li class="toctree-l1"><a class="reference internal" href="renv.html"><code class="docutils literal notranslate"><span class="pre">renv</span></code> on Databricks</a></li>
</ul>
</div>
<ul class="simple">
<li><p>Use SparkR and RStudio Desktop with <a class="reference internal" href="../dev-tools/databricks-connect/index.html"><span class="doc">Databricks Connect</span></a>.</p></li>
<li><p>Use sparklyr and RStudio Desktop with <a class="reference internal" href="../dev-tools/databricks-connect/index.html"><span class="doc">Databricks Connect</span></a>.</p></li>
</ul>
</div>
<div class="section" id="r-session-customization">
<h3>R session customization<a class="headerlink" href="#r-session-customization" title="Permalink to this headline"> </a></h3>
<p>In Databricks Runtime 12.0 and above, R sessions can be customized by using site-wide profile (<code class="docutils literal notranslate"><span class="pre">.Rprofile</span></code>) files. R notebooks will source the file as R code during startup. To modify the file, find the value of <code class="docutils literal notranslate"><span class="pre">R_HOME</span></code> and modify <code class="docutils literal notranslate"><span class="pre">$R_HOME/etc/Rprofile.site</span></code>. Note that Databricks has added configuration in the file to ensure proper functionality for hosted <a class="reference internal" href="rstudio.html"><span class="doc">RStudio on Databricks</span></a>. Removing any of it may cause RStudio to not work as expected.</p>
<p>In Databricks Runtime 11.3 and below, this behavior can be enabled by setting the environment variable <code class="docutils literal notranslate"><span class="pre">DATABRICKS_ENABLE_RPROFILE=true</span></code>.</p>
</div>
</div>
<div class="section" id="additional-resources">
<h2>Additional resources<a class="headerlink" href="#additional-resources" title="Permalink to this headline"> </a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://kb.databricks.com/r-aws.html">Knowledge Base</a></p></li>
</ul>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>