

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en-US" > <![endif]-->
<!--[if gt IE 8]><!-->
<html class="no-js" lang="en-US"> <!--<![endif]-->

<head>
  <!-- cookie consent -->
  
    <!-- Combined Onetrust and Rudderstack Implementation Scripts -->
    <!-- Onetrust Initialization -->
    <script type="text/javascript" src="https://cdn.cookielaw.org/consent/92466579-1717-44d3-809d-a05fb02843ed-test/OtAutoBlock.js"></script>
    <script src="https://cdn.cookielaw.org/scripttemplates/otSDKStub.js" data-document-language="true" type="text/javascript" charset="UTF-8" data-domain-script="92466579-1717-44d3-809d-a05fb02843ed-test"></script>
    <link rel="stylesheet" id="db-onetrust-style" href="https://www.databricks.com/wp-content/uploads/db_onetrust.css" media="all" />
    <!-- Setting Rudderstack Write Key -->
    <script>window.rudderstackKey = "2SOR9fvSr5Fi6tN2ihPbVHnX1SZ" </script>
    <!-- Rudderstack Initialization + Onetrust Integration + Rudderstack Custom Events -->
    <script type="text/javascript" src="https://www.databricks.com/sites/default/files/rudderstack/v1/db-rudderstack-events.js"></script>

  <!-- cookie consent -->

  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta http-equiv="X-UA-Compatible" content="IE=9" />
  <meta content="Learn about options for working with files on Databricks." name="description" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no" />
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1, user-scalable=0">
  <meta property="og:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta property="og:image:type" content="image/png">
  <meta property="og:title" content="Work with files on Databricks">
  <meta property="og:image:width" content="1200">
  <meta property="og:image:height" content="630">
  <meta property="og:type" content="website">
  <meta property="og:url" content="https://docs.databricks.com">
  <meta property="og:description" content="" id="og-description">
  <meta name="twitter:image" content="https://www.databricks.com/wp-content/uploads/2020/04/og-databricks.png">
  <meta name="twitter:site" content="@databricks">
  <meta name="twitter:creator" content="@databricks">
  <meta property="twitter:description" content="">
  
  <title>Work with files on Databricks &#124; Databricks on AWS</title>
  
  
  <link rel="canonical" href="https://docs.databricks.com/en/files/index.html">
  <!-- Start hreflang tag -->
  <link rel="alternate" hreflang="en" href="https://docs.databricks.com/en/files/index.html" />
<link rel="alternate" hreflang="x-default" href="https://docs.databricks.com/en/files/index.html" />
  <!-- End hreflang tag -->
  
  
  <link rel="shortcut icon" href="../_static/favicon.ico" />
  

  

  

  <!-- Google Tag Manager -->
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-T85FQ33');</script>
  <script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':
new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],
j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src=
'https://www.googletagmanager.com/gtm.js?id='+i+dl;
j.setAttributeNode(d.createAttribute('data-ot-ignore'));
f.parentNode.insertBefore(j,f);
})(window,document,'script','dataLayer','GTM-TWTKQQ');</script>
    
  <!-- End Google Tag Manager -->


  <!-- MaxMind / GEO IP -->
  <script src="//js.maxmind.com/js/apis/geoip2/v2.1/geoip2.js" type="text/javascript"></script>
  <!-- End MaxMind / GEO IP -->

  
  
  <link href="https://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600&display=swap" rel="stylesheet">
  <link rel="preload" href="../_static/fonts/DMSans-Bold.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMSans-Regular.ttf" as="font">
  <link rel="preload" href="../_static/fonts/DMMono-Regular.ttf" as="font">
  <link rel="stylesheet" href="../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/custom.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/cloud-provider-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/translation-selector.css" type="text/css" />
  <link rel="stylesheet" href="../_static/css/searchunify/main.css" type="text/css" />

  
  <link rel="index" title="Index" href="../genindex.html" />
  <link rel="search" title="Search" href="../search.html" />
  <link rel="top" title="Databricks on AWS" href="../index.html" /> 
</head>

<body class="wy-body-for-nav" role="document">

  <!-- Google Tag Manager (noscript) -->
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-T85FQ33"
height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <noscript><iframe src="https://www.googletagmanager.com/ns.html?id=GTM-TWTKQQ"
    height="0" width="0" style="display:none;visibility:hidden"></iframe></noscript>
  <!-- End Google Tag Manager (noscript) -->

  
  <nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
    
<nav class="wy-nav-top header su_header" role="navigation" aria-label="top navigation">
  <div class="container-logo">
    <ul class="mobile-menu-toggle">
        <li class="menu-toggle">
            <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
            
            <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
              alt="Databricks" /></a>   
               
              </li>
    </ul>
    <ul class="su_nav-menu">
      <li class="menu-toggle">
        <i data-toggle="wy-nav-top" class="wy-nav-top-menu-button db-icon db-icon-menu pull-left"></i>
        
          
        
        <a href="https://www.databricks.com/" class="wy-nav-top-logo"><img src="../_static/small-scale-lockup-full-color-rgb.svg" width="137" height="21"
            alt="Databricks" /></a></li>
        <!-- 
<li><a href="https://help.databricks.com/s/">Help Center</a></li>
<li class="active"><a href="https://docs.databricks.com/en/">Documentation</a></li>
<li><a href="https://kb.databricks.com/">Knowledge Base</a></li>
 -->
    </ul>
  </div>
  <div class="su_nav-right">
    <ul class="su_link-mobile">
  <!-- Mobile header code can go here -->
</ul>
<ul class="right-try-list">
   
</ul>
  </div>
</nav>
  </nav>

  <div class="su_sub-header">
    <div class="container">
      <div class="su_sub-header-inner">
        <!-- <div class="su_subnav-menu-right">
  <div id="auto" style="width: 100%;">
    <div ng-controller="SearchautoController">
      <div bind-html-compile="autocompleteHtml">
        <form class="su__search-box-1" disabled="disabled">
          <input class="su__search-input" type="search" name="Search box" id="su__search-b" placeholder="Search Documentation" disabled="disabled"/>
          <button class="su__search-button" type="submit" class="button button-success" disabled="disabled">
            <svg width="24" height="24" viewBox="0 0 24 24">
              <path
                d="M15.5 14h-.79l-.28-.27C15.41 12.59 16 11.11 16 9.5 16 5.91 13.09 3 9.5 3S3 5.91 3 9.5 5.91 16 9.5 16c1.61 0 3.09-.59 4.23-1.57l.27.28v.79l5 4.99L20.49 19l-4.99-5zm-6 0C7.01 14 5 11.99 5 9.5S7.01 5 9.5 5 14 7.01 14 9.5 11.99 14 9.5 14z"
                fill="#333"></path>
            </svg>
          </button>
        </form>
      </div>
    </div>
  </div>
</div> -->
        <div class="search-lng-gap"></div>
        <div style="margin-left: 16px; margin-right: 16px;">
          <!-- <select name="lng selector" id="lng-selector">
    <option value="../../en/files/index.html" class="notranslate">English</option>
    <option value="../../ja/files/index.html" class="notranslate">日本語</option>
    <option value="../../pt/files/index.html" class="notranslate">Português (Brasil)</option>
</select> -->
        </div>
        <div class="cloud-selector-container">
          <!-- <select name="cloud provider selector" id="cloud-provider-selector">
    <option value="aws" selected class="notranslate">
        Amazon Web Services
    </option>
    <option value="azure"  class="notranslate">
        Microsoft Azure
    </option>
    <option value="gcp"  class="notranslate">
        Google Cloud Platform
    </option>
</select> -->
        </div>
      </div>
    </div>
  </div>
  <page class="js-page-container">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side su_nav-side">
<div class="wy-side-scroll">
  <div class="wy-side-nav-search">
    

    

    

    
  </div>

  <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
    
      <a href="../index.html" class="main-navigation-home">Databricks on AWS</a>
    

    
      

      
        <p class="caption"><span class="caption-text">Load &amp; manage data</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../rag-temp/index.html">RAG Studio</a></li>
</ul>

      
    
  </div>

  <div role="contentinfo">
    
  <p class="build_info notranslate"data-last-edit="December 23, 2023">
    Updated Jan 11, 2024
  </p>
<script>
  window.addEventListener('DOMContentLoaded',function(){
    var h1=document.querySelector('h1');
    var bi=document.querySelector('[data-last-edit]');
    if(h1 && bi){
      var ver = document.createElement('p');
      ver.className = 'version_info';
      ver.textContent = bi.getAttribute('data-last-edit');
      h1.parentElement.insertBefore(ver, h1.nextElementSibling);
    }
  });
</script>

    <p>
      
        <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
      
    </p>
  </div>
</div>
</nav>
    
    
<main class="wy-grid-for-nav su_nav-grid">
  <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">
    <div class="wy-nav-content su__nav_content">
      <div class="rst-content">
        





<div role="navigation" aria-label="breadcrumbs navigation" class="wy-breadcrumbs-wrapper">
  <ul class="wy-breadcrumbs">
    <li><a href="../index.html">Documentation</a> <span class="db-icon db-icon-chevron-right"></span></li>
    
    
      <li>Work with files on Databricks</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
      </li>
    
  </ul>
</div>
        
        <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
          <div itemprop="articleBody">
            
    
  <div class="section" id="work-with-files-on-databricks">
<h1>Work with files on Databricks<a class="headerlink" href="#work-with-files-on-databricks" title="Permalink to this headline"> </a></h1>
<p>Databricks provides multiple utilities and APIs for interacting with files in the following locations:</p>
<ul class="simple">
<li><p>Unity Catalog volumes.</p></li>
<li><p>Workspace files.</p></li>
<li><p>Cloud object storage.</p></li>
<li><p>DBFS mounts and DBFS root.</p></li>
<li><p>Ephemeral storage attached to the driver node of the cluster.</p></li>
</ul>
<p>This article provides examples for interacting with files in these locations for the following tools:</p>
<ul class="simple">
<li><p>Apache Spark.</p></li>
<li><p>Spark SQL and Databricks SQL.</p></li>
<li><p>Databricks file system utitlities (<code class="docutils literal notranslate"><span class="pre">dbutils.fs</span></code> or <code class="docutils literal notranslate"><span class="pre">%fs</span></code>).</p></li>
<li><p>Databricks CLI.</p></li>
<li><p>Databricks REST API.</p></li>
<li><p>Bash shell commands (<code class="docutils literal notranslate"><span class="pre">%sh</span></code>).</p></li>
<li><p>Notebook-scoped library installs using <code class="docutils literal notranslate"><span class="pre">%pip</span></code>.</p></li>
<li><p>Pandas.</p></li>
<li><p>OSS Python file management and processing utilities.</p></li>
</ul>
<div class="admonition important">
<p class="admonition-title">Important</p>
<p>File operations that require FUSE access to data cannot directly access cloud object storage using URIs. Databricks recommends using Unity Catalog volumes to configure access to these locations for FUSE.</p>
<p>Scala does not support FUSE for Unity Catalog volumes or workspace files on compute configured with single user access mode or clusters without Unity Catalog. Scala supports FUSE for Unity Catalog volumes and workspace files on compute configured with Unity Catalog and shared access mode.</p>
</div>
<div class="toctree-wrapper compound">
</div>
<div class="section" id="do-i-need-to-provide-a-uri-scheme-to-access-data">
<h2>Do I need to provide a URI scheme to access data?<a class="headerlink" href="#do-i-need-to-provide-a-uri-scheme-to-access-data" title="Permalink to this headline"> </a></h2>
<p>Data access paths in Databricks follow one of the following standards:</p>
<ul>
<li><p><strong>URI-style paths</strong> include a URI scheme. For Databricks-native data access solutions, URI schemes are optional for most use cases. When you directly access data in cloud object storage, you must provide the correct URI scheme for the storage type.</p>
<div class="figure align-default">
<img alt="URI paths diagram" src="../_images/uri-paths-aws.png" />
</div>
</li>
<li><p><strong>POSIX-style paths</strong> provide data access relative to the driver root (<code class="docutils literal notranslate"><span class="pre">/</span></code>). POSIX-style paths never require a scheme. You can use Unity Catalog volumes or DBFS mounts to provide POSIX-style access to data in cloud object storage. Many ML frameworks and other OSS Python modules require FUSE and can only use POSIX-style paths.</p>
<div class="figure align-default">
<img alt="POSIX paths diagram" src="../_images/posix-paths.png" />
</div>
</li>
</ul>
</div>
<div class="section" id="work-with-files-in-unity-catalog-volumes">
<span id="work-with-files-in-uc-volumes"></span><h2>Work with files in Unity Catalog volumes<a class="headerlink" href="#work-with-files-in-unity-catalog-volumes" title="Permalink to this headline"> </a></h2>
<p>Databricks recommends using Unity Catalog volumes to configure access to non-tabular data files stored in cloud object storage. See <a class="reference internal" href="../connect/unity-catalog/volumes.html"><span class="doc">Create and work with volumes</span></a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 20%" />
<col style="width: 80%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Apache Spark</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">spark.read.format(&quot;json&quot;).load(&quot;/Volumes/my_catalog/my_schema/my_volume/data.json&quot;).show()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Spark SQL and Databricks SQL</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">csv.`/Volumes/my_catalog/my_schema/my_volume/data.csv`;</span></code> 
<code class="docutils literal notranslate"><span class="pre">LIST</span> <span class="pre">'/Volumes/my_catalog/my_schema/my_volume/';</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks file system utilities</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">dbutils.fs.ls(&quot;/Volumes/my_catalog/my_schema/my_volume/&quot;)</span></code> 
<code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">ls</span> <span class="pre">/Volumes/my_catalog/my_schema/my_volume/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Databricks CLI</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">fs</span> <span class="pre">cp</span> <span class="pre">/path/to/local/file</span> <span class="pre">dbfs:/Volumes/my_catalog/my_schema/my_volume/</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks REST API</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">https://&lt;databricks-instance&gt;/api/2.1/jobs/create</span></code> 
<code class="docutils literal notranslate"><span class="pre">{&quot;name&quot;:</span> <span class="pre">&quot;A</span> <span class="pre">multitask</span> <span class="pre">job&quot;,</span> <span class="pre">&quot;tasks&quot;:</span> <span class="pre">[{...&quot;libraries&quot;:</span> <span class="pre">[{&quot;jar&quot;:</span> <span class="pre">&quot;/Volumes/dev/environment/libraries/logging/Logging.jar&quot;}],},...]}</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Bash shell commands</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%sh</span> <span class="pre">curl</span> <span class="pre">http://&lt;address&gt;/text.zip</span> <span class="pre">-o</span> <span class="pre">/Volumes/my_catalog/my_schema/my_volume/tmp/text.zip</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Library installs</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">/Volumes/my_catalog/my_schema/my_volume/my_library.whl</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Pandas</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">=</span> <span class="pre">pd.read_csv('/Volumes/my_catalog/my_schema/my_volume/data.csv')</span></code></p></td>
</tr>
<tr class="row-even"><td><p> OSS Python</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">os.listdir('/Volumes/my_catalog/my_schema/my_volume/path/to/directory')</span></code></p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dbfs:/</span></code> schema is required when working with the Databricks CLI.</p>
</div>
</div>
<div class="section" id="work-with-workspace-files">
<h2>Work with workspace files<a class="headerlink" href="#work-with-workspace-files" title="Permalink to this headline"> </a></h2>
<p>You can use workspace files to store and access data and other files saved alongside notebooks and other workspace assets. Because workspace files have size restrictions, Databricks recommends only storing small data files here primarily for development and testing.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 27%" />
<col style="width: 73%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Apache Spark</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">spark.read.format(&quot;json&quot;).load(&quot;file:/Workspace/Users/&lt;user-folder&gt;/data.json&quot;).show()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Spark SQL and Databricks SQL</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">json.`file:/Workspace/Users/&lt;user-folder&gt;/file.json`;</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks file system utilities</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">dbutils.fs.ls(&quot;file:/Workspace/Users/&lt;user-folder&gt;/&quot;)</span></code> 
<code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">ls</span> <span class="pre">file:/Workspace/Users/&lt;user-folder&gt;/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Databricks CLI</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">workspace</span> <span class="pre">list</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks REST API</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">https://&lt;databricks-instance&gt;/api/2.0/workspace/delete</span></code> 
<code class="docutils literal notranslate"><span class="pre">{&quot;path&quot;:</span> <span class="pre">&quot;/Workspace/Shared/code.py&quot;,</span> <span class="pre">&quot;recursive&quot;:</span> <span class="pre">&quot;false&quot;}</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Bash shell commands</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%sh</span> <span class="pre">curl</span> <span class="pre">http://&lt;address&gt;/text.zip</span> <span class="pre">-o</span> <span class="pre">/Workspace/Users/&lt;user-folder&gt;/text.zip</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Library installs</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">/Workspace/Users/&lt;user-folder&gt;/my_library.whl</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Pandas</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">=</span> <span class="pre">pd.read_csv('/Workspace/Users/&lt;user-folder&gt;/data.csv')</span></code></p></td>
</tr>
<tr class="row-even"><td><p> OSS Python</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">os.listdir('/Workspace/Users/&lt;user-folder&gt;/path/to/directory')</span></code></p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">file:/</span></code> schema is required when working with Databricks Utilities, Apache Spark, or SQL.</p>
<p>You cannot use Apache Spark to read or write to workspace files on cluster configured with shared access mode.</p>
</div>
</div>
<div class="section" id="work-with-files-in-cloud-object-storage">
<h2>Work with files in cloud object storage<a class="headerlink" href="#work-with-files-in-cloud-object-storage" title="Permalink to this headline"> </a></h2>
<p>Databricks recommends using Unity Catalog volumes to configure secure access to files in cloud object storage. If you choose to directly access data in cloud object storage using URIs, you must configure permissions. See <a class="reference internal" href="../data-governance/unity-catalog/best-practices.html#manage-external"><span class="std std-ref">Manage external locations, external tables, and external volumes</span></a>.</p>
<p>The following examples use URIs to access data in cloud object storage:</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 70%" />
<col style="width: 30%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Apache Spark</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">spark.read.format(&quot;json&quot;).load(&quot;s3://&lt;bucket&gt;/path/file.json&quot;).show()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Spark SQL and Databricks SQL</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">csv.`s3://&lt;bucket&gt;/path/file.json`;</span></code> <code class="docutils literal notranslate"><span class="pre">LIST</span> <span class="pre">'s3://&lt;bucket&gt;/path';</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks file system utilities</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">dbutils.fs.ls(&quot;s3://&lt;bucket&gt;/path/&quot;)</span></code> <code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">ls</span> <span class="pre">s3://&lt;bucket&gt;/path/</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Databricks CLI</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-even"><td><p> Databricks REST API</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-odd"><td><p> Bash shell commands</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-even"><td><p> Library installs</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">s3://bucket-name/path/to/library.whl</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Pandas</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-even"><td><p> OSS Python</p></td>
<td><p> Not supported</p></td>
</tr>
</tbody>
</table>
</div>
<div class="section" id="work-with-files-in-dbfs-mounts-and-dbfs-root">
<h2>Work with files in DBFS mounts and DBFS root<a class="headerlink" href="#work-with-files-in-dbfs-mounts-and-dbfs-root" title="Permalink to this headline"> </a></h2>
<p>DBFS mounts are not securable using Unity Catalog and are no longer recommended by Databricks. Data stored in the DBFS root is accessible by all users in the workspace. Databricks recommends against storing any sensitive or production code or data in the DBFS root. See <a class="reference internal" href="../dbfs/index.html"><span class="doc">What is the Databricks File System (DBFS)?</span></a>.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 28%" />
<col style="width: 72%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Apache Spark</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">spark.read.format(&quot;json&quot;).load(&quot;/mnt/path/to/data.json&quot;).show()</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Spark SQL and Databricks SQL</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">SELECT</span> <span class="pre">*</span> <span class="pre">FROM</span> <span class="pre">json.`/mnt/path/to/data.json`;</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks file system utilities</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">dbutils.fs.ls(&quot;/mnt/path&quot;)</span></code> 
<code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">ls</span> <span class="pre">/mnt/path</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Databricks CLI</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">databricks</span> <span class="pre">fs</span> <span class="pre">cp</span> <span class="pre">dbfs:/mnt/path/to/remote/file</span> <span class="pre">/path/to/local/file</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Databricks REST API</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">POST</span> <span class="pre">https://&lt;host&gt;/api/2.0/dbfs/delete</span> <span class="pre">--data</span> <span class="pre">'{</span> <span class="pre">&quot;path&quot;:</span> <span class="pre">&quot;/tmp/HelloWorld.txt&quot;</span> <span class="pre">}'</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Bash shell commands</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%sh</span> <span class="pre">curl</span> <span class="pre">http://&lt;address&gt;/text.zip</span> <span class="pre">&gt;</span> <span class="pre">/dbfs/mnt/tmp/text.zip</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Library installs</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%pip</span> <span class="pre">install</span> <span class="pre">/dbfs/mnt/path/to/my_library.whl</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Pandas</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">=</span> <span class="pre">pd.read_csv('/dbfs/mnt/path/to/data.csv')</span></code></p></td>
</tr>
<tr class="row-even"><td><p> OSS Python</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">os.listdir('/dbfs/mnt/path/to/directory')</span></code></p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">dbfs:/</span></code> schema is required when working with the Databricks CLI.</p>
</div>
</div>
<div class="section" id="work-with-files-in-ephemeral-storage-attached-to-the-driver-node">
<span id="driver"></span><h2>Work with files in ephemeral storage attached to the driver node<a class="headerlink" href="#work-with-files-in-ephemeral-storage-attached-to-the-driver-node" title="Permalink to this headline"> </a></h2>
<p>The ephermal storage attached to the drive node is block storage with native POSIX-based path access. Any data stored in this location disappears when a cluster terminates or restarts.</p>
<table class="docutils align-default">
<colgroup>
<col style="width: 38%" />
<col style="width: 62%" />
</colgroup>
<thead>
<tr class="row-odd"><th class="head"><p>Tool</p></th>
<th class="head"><p>Example</p></th>
</tr>
</thead>
<tbody>
<tr class="row-even"><td><p> Apache Spark</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-odd"><td><p> Spark SQL and Databricks SQL</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-even"><td><p> Databricks file system utilities</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">dbutils.fs.ls(&quot;file:/path&quot;)</span></code> 
<code class="docutils literal notranslate"><span class="pre">%fs</span> <span class="pre">ls</span> <span class="pre">file:/path</span></code></p></td>
</tr>
<tr class="row-odd"><td><p> Databricks CLI</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-even"><td><p> Databricks REST API</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-odd"><td><p> Bash shell commands</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">%sh</span> <span class="pre">curl</span> <span class="pre">http://&lt;address&gt;/text.zip</span> <span class="pre">&gt;</span> <span class="pre">/tmp/text.zip</span></code></p></td>
</tr>
<tr class="row-even"><td><p> Library installs</p></td>
<td><p> Not supported</p></td>
</tr>
<tr class="row-odd"><td><p> Pandas</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">df</span> <span class="pre">=</span> <span class="pre">pd.read_csv('/path/to/data.csv')</span></code></p></td>
</tr>
<tr class="row-even"><td><p> OSS Python</p></td>
<td><p> <code class="docutils literal notranslate"><span class="pre">os.listdir('/path/to/directory')</span></code></p></td>
</tr>
</tbody>
</table>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>The <code class="docutils literal notranslate"><span class="pre">file:/</span></code> schema is required when working with Databricks Utilities.</p>
</div>
</div>
<div class="section" id="move-data-from-ephemeral-storage-to-volumes">
<span id="move-ephemeral"></span><h2>Move data from ephemeral storage to volumes<a class="headerlink" href="#move-data-from-ephemeral-storage-to-volumes" title="Permalink to this headline"> </a></h2>
<p>You might want to access data downloaded or saved to ephemeral storage using Apache Spark. Because ephemeral storage is attached to the driver and Spark is a distributed processing engine, not all operations can directly access data here. If you need to move data from the driver filesystem to Unity Catalog volumes, you can copy files using magic commands or the Databricks utilities, as in the following examples</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="n">dbutils</span><span class="o">.</span><span class="n">fs</span><span class="o">.</span><span class="n">cp</span> <span class="p">(</span><span class="s2">&quot;file:/&lt;path&gt;&quot;</span><span class="p">,</span> <span class="s2">&quot;/Volumes/&lt;catalog&gt;/&lt;schema&gt;/&lt;volume&gt;/&lt;path&gt;&quot;</span><span class="p">)</span>
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%sh<span class="w"> </span>cp<span class="w"> </span>/&lt;path&gt;<span class="w"> </span>/Volumes/&lt;catalog&gt;/&lt;schema&gt;/&lt;volume&gt;/&lt;path&gt;
</pre></div>
</div>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>%fs<span class="w"> </span>cp<span class="w"> </span>file:/&lt;path&gt;<span class="w"> </span>/Volumes/&lt;catalog&gt;/&lt;schema&gt;/&lt;volume&gt;/&lt;path&gt;
</pre></div>
</div>
</div>
<div class="section" id="where-do-deleted-files-go">
<h2>Where do deleted files go?<a class="headerlink" href="#where-do-deleted-files-go" title="Permalink to this headline"> </a></h2>
<p>Deleting a workspace file sends it to the trash. You can either recover or permanently delete files from the trash using the UI.</p>
<p>See <a class="reference internal" href="../workspace/workspace-objects.html#delete-object"><span class="std std-ref">Delete an object</span></a>.</p>
</div>
<div class="section" id="local-file-api-limitations">
<span id="local-limitations"></span><h2>Local file API limitations<a class="headerlink" href="#local-file-api-limitations" title="Permalink to this headline"> </a></h2>
<p>The following lists the limitations on local file API usage with cloud object storage in Databricks Runtime.</p>
<ul class="simple">
<li><p>Does not support Amazon S3 mounts with client-side encryption enabled.</p></li>
</ul>
<ul>
<li><p>No direct append operations.</p>
<p>Since the underlying storage does not support append, Databricks would have to download the data, run the append, and reupload the data in order to support the command. This works for small files, but quickly becomes an issue as file size increases.</p>
</li>
<li><p>No non-sequential (random) writes, such as writing Zip and Excel files.</p>
<p>For direct append or random write workloads, perform the operations on local disk first and then copy the result to Unity Catalog volumes. For example:</p>
<div class="highlight-python notranslate"><div class="highlight"><pre><span></span><span class="c1"># python</span>
<span class="kn">import</span> <span class="nn">xlsxwriter</span>
<span class="kn">from</span> <span class="nn">shutil</span> <span class="kn">import</span> <span class="n">copyfile</span>

<span class="n">workbook</span> <span class="o">=</span> <span class="n">xlsxwriter</span><span class="o">.</span><span class="n">Workbook</span><span class="p">(</span><span class="s1">&#39;/local_disk0/tmp/excel.xlsx&#39;</span><span class="p">)</span>
<span class="n">worksheet</span> <span class="o">=</span> <span class="n">workbook</span><span class="o">.</span><span class="n">add_worksheet</span><span class="p">()</span>
<span class="n">worksheet</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="s2">&quot;Key&quot;</span><span class="p">)</span>
<span class="n">worksheet</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="s2">&quot;Value&quot;</span><span class="p">)</span>
<span class="n">workbook</span><span class="o">.</span><span class="n">close</span><span class="p">()</span>

<span class="n">copyfile</span><span class="p">(</span><span class="s1">&#39;/local_disk0/tmp/excel.xlsx&#39;</span><span class="p">,</span> <span class="s1">&#39;/Volumes/my_catalog/my_schema/my_volume/excel.xlsx&#39;</span><span class="p">)</span>
</pre></div>
</div>
</li>
<li><p>No sparse files. To copy sparse files, use <code class="docutils literal notranslate"><span class="pre">cp</span> <span class="pre">--sparse=never</span></code>:</p>
<div class="highlight-bash notranslate"><div class="highlight"><pre><span></span>$<span class="w"> </span>cp<span class="w"> </span>sparse.file<span class="w"> </span>/Volumes/my_catalog/my_schema/my_volume/sparse.file
error<span class="w"> </span>writing<span class="w"> </span><span class="s1">&#39;/dbfs/sparse.file&#39;</span>:<span class="w"> </span>Operation<span class="w"> </span>not<span class="w"> </span>supported
$<span class="w"> </span>cp<span class="w"> </span>--sparse<span class="o">=</span>never<span class="w"> </span>sparse.file<span class="w"> </span>/Volumes/my_catalog/my_schema/my_volume/sparse.file
</pre></div>
</div>
</li>
<li><p>Executors cannot write to workspace files.</p></li>
<li><p>Workspace file size is limited to 200MB. Operations that attempt to download or create files larger than this limit fail.</p></li>
<li><p>You cannot use <code class="docutils literal notranslate"><span class="pre">git</span></code> commands when you save to workspace files. The creation of <code class="docutils literal notranslate"><span class="pre">.git</span></code> directories is not allowed in workspace files.</p></li>
<li><p>No symlinks.</p></li>
</ul>
</div>
<div class="section" id="enable-workspace-files">
<span id="enable-files"></span><h2>Enable workspace files<a class="headerlink" href="#enable-workspace-files" title="Permalink to this headline"> </a></h2>
<p>Databricks workspace files are the set of files in a workspace that are not notebooks. To enable support for non-notebook files in your Databricks workspace, call the <a class="reference external" href="https://docs.databricks.com/api/workspace/workspaceconf/setstatus">/api/2.0/workspace-conf</a> REST API from a notebook or other environment with access to your Databricks workspace. Workspace files are <strong>enabled</strong> by default.</p>
<p>To enable or re-enable support for non-notebook files in your Databricks workspace, call the <code class="docutils literal notranslate"><span class="pre">/api/2.0/workspace-conf</span></code> and get the value of the <code class="docutils literal notranslate"><span class="pre">enableWorkspaceFileSystem</span></code> key. If it is set to <code class="docutils literal notranslate"><span class="pre">true</span></code>, non-notebook files are already enabled for your workspace.</p>
<p>The following example demonstrates how you can call this API from a notebook to check if workspace files are disabled and if so, re-enable them. To disable workspace files, set <code class="docutils literal notranslate"><span class="pre">enableWorkspaceFilesystem</span></code> to <code class="docutils literal notranslate"><span class="pre">false</span></code> with the <code class="docutils literal notranslate"><span class="pre">/api/2.0/workspace-conf</span></code> API.</p>
<div class="embedded-notebook-section section" id="example-notebook-for-re-enabling-databricks-workspace-file-support">
<span id="turn-on-files"></span><h3>Example: Notebook for re-enabling Databricks workspace file support<a class="headerlink" href="#example-notebook-for-re-enabling-databricks-workspace-file-support" title="Permalink to this headline"> </a></h3>
<div class="embedded-notebook">
    <p class="notebook-import-help">
        <a href="/_extras/notebooks/source/files/turn-on-files.html"            target="_blank">Open notebook in new tab</a>
        <button class="embedded-notebook-copy-to-clipboard"                copy-path-to-clipboard-on-click="/_extras/notebooks/source/files/turn-on-files.html">            <img src="/_static/clippy.svg"                alt="Copy to clipboard">            Copy link for import        </button>    <div class="embedded-notebook-container">        <div class="loading-spinner"></div>        <iframe data-src="/_extras/notebooks/source/files/turn-on-files.html"            id="43b2c438fef518f3dc6809911ef397c5ba48b41befe3b68dac05a716b8dafc0a" height="1000px" width="100%"            style="overflow-y:hidden;" scrolling="no"></iframe>    </div></div></div>
</div>
</div>


    
          </div>
        </div>
        <div  class="suapp-rating">
  <div id="suPageRateApp">
     <su-app></su-app>
   </div> 
 </div>
<hr> 
<footer>
  <div role="contentinfo">
      <p class="copyright">
          &copy; Databricks 2023. All rights reserved. Apache, Apache Spark, Spark, and the Spark logo are trademarks of the <a href="http://www.apache.org/">Apache Software Foundation</a>.
      </p>
      <p> 
        
          <a id='feedbacklink' href="mailto:doc-feedback@databricks.com?subject=Documentation Feedback">Send us feedback</a>
        
     | <a href="https://databricks.com/privacy-policy">Privacy Policy</a> | <a href="https://databricks.com/terms-of-use">Terms of Use</a></p>

  </div> 

</footer>
      </div>
    </div>
  </section>
</main>

  </page>
  
  <script type="text/javascript">
    var DOCUMENTATION_OPTIONS = {
      URL_ROOT: '../',
      VERSION: '1.0',
      COLLAPSE_INDEX: false,
      FILE_SUFFIX: '.html',
      HAS_SOURCE: 'false'
    };
  </script>
  <script type="text/javascript" src="../_static/jquery.js"></script>
  <script type="text/javascript" src="../_static/underscore.js"></script>
  <script type="text/javascript" src="../_static/doctools.js"></script>
  <script type="text/javascript" src="../_static/language_data.js"></script>
  

  <script type="text/javascript" src="../_static/js/clipboard.min.js"></script>
  <script type="text/javascript" src="../_static/js/jquery.waypoints.min.js"></script>

  <!-- Select2 (https://select2.org/) -->
  <link href="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/css/select2.min.css" rel="stylesheet" />
  <script src="https://cdn.jsdelivr.net/npm/select2@4.1.0-rc.0/dist/js/select2.min.js"></script>
  <!-- End Select2 -->

  
  
  <script type="text/javascript" src="../_static/js/localized.js"></script>
  <script type="text/javascript" src="../_static/js/custom.js"></script>
  

  
  
  <script type="text/javascript">
    jQuery(function () {
      SphinxRtdTheme.StickyNav.enable();
    });

  </script>
  
 



  <script>
  window.__searchunifyLoaderConfig = JSON.parse('{"clients": {"en": "02c2e804-27e9-11ee-aefb-0242ac120011", "ja": "6a42c3f2-2820-11ee-aefb-0242ac120011", "pt": "6a86badd-2821-11ee-aefb-0242ac120011"}}')
</script>
<script type="text/javascript" src="../_static/js/search-loader.js"></script>
</body>
<script type='text/javascript'>
  window.onload = function () {
    var description = document.querySelector('meta[name="description"]').getAttribute("content");
    let titleText = document.querySelector('h1').textContent;
    document.querySelector('meta[property="og:title"]').setAttribute("content", titleText);
    document.querySelector('meta[property="og:description"]').setAttribute("content", description);
    document.querySelector('meta[property="twitter:description"]').setAttribute("content", description);
  };
</script>

</html>